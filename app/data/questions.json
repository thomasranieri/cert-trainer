[
  {
    "taskStatement": "1.1",
    "stem": "Which data format is typically most efficient for analytic queries on large datasets in AWS?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "CSV",
      "B": "Apache Parquet",
      "C": "JSON",
      "D": "Plain text"
    },
    "explanation": "Apache Parquet is a columnar storage format optimized for analytical queries, generally providing faster query performance and reduced storage cost compared to row-based formats like CSV."
  },
  {
    "taskStatement": "1.1",
    "stem": "What AWS service would you primarily use to ingest real-time streaming data for machine learning workflows?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon S3",
      "B": "Amazon RDS",
      "C": "Amazon Kinesis",
      "D": "Amazon Redshift"
    },
    "explanation": "Amazon Kinesis is designed to collect, process, and analyze real-time streaming data, making it ideal for streaming ingestion in machine learning pipelines."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which AWS storage option is best suited for low-latency access to machine learning training data in a shared file system?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon EFS",
      "B": "Amazon S3",
      "C": "Amazon Glacier",
      "D": "Amazon RDS"
    },
    "explanation": "Amazon EFS provides a scalable, low-latency, shared file system accessible by multiple instances, suitable for training ML models requiring concurrent access."
  },
  {
    "taskStatement": "1.1",
    "stem": "When ingesting data into Amazon SageMaker Feature Store, which data source types can be used directly?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon DynamoDB and JSON files only",
      "B": "Only CSV files on Amazon S3",
      "C": "Streaming data sources only",
      "D": "Amazon S3, streaming data, and batch data"
    },
    "explanation": "Amazon SageMaker Feature Store supports ingestion from multiple sources including Amazon S3 (batch), streaming data, and direct API calls, enabling flexible feature ingestion."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which AWS service can merge data from multiple sources such as Amazon S3 and Amazon Redshift for data preparation?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon Kinesis",
      "B": "AWS Glue",
      "C": "Amazon SageMaker",
      "D": "AWS Snowball"
    },
    "explanation": "AWS Glue is a fully managed extract, transform, and load (ETL) service that can crawl and transform data from multiple sources including S3 and Redshift."
  },
  {
    "taskStatement": "1.1",
    "stem": "What is the purpose of Amazon S3 Transfer Acceleration?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "To transfer files between S3 buckets",
      "B": "To automatically replicate data in S3",
      "C": "To speed up upload and download of data to and from S3 from worldwide locations",
      "D": "To encrypt data stored in S3"
    },
    "explanation": "Amazon S3 Transfer Acceleration accelerates transfers of data over long distances between clients and S3, improving throughput and reducing latency."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which Apache data format is optimized for row-based data storage and streaming consumption?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Apache Parquet",
      "B": "Apache ORC",
      "C": "Apache Avro",
      "D": "CSV"
    },
    "explanation": "Apache Avro is a row-based data serialization system often used in streaming and messaging systems due to its compact binary format and schema evolution support."
  },
  {
    "taskStatement": "1.1",
    "stem": "When selecting a data format for ML ingestion with frequent column retrieval, which format should be preferred?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Columnar formats (e.g., Parquet, ORC)",
      "B": "Row-based formats (e.g., JSON, CSV)",
      "C": "Compressed text formats",
      "D": "XML"
    },
    "explanation": "Columnar formats like Parquet and ORC allow efficient access to specific columns without scanning entire rows, which is beneficial for many ML workloads."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which AWS storage options can be configured to meet high IOPS and low latency needs for ML training data storage?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon S3 with Transfer Acceleration",
      "B": "Amazon Glacier",
      "C": "Amazon FSx for Lustre",
      "D": "Amazon EBS Provisioned IOPS SSD volumes"
    },
    "explanation": "Amazon EBS Provisioned IOPS SSD volumes provide high throughput, consistent, and low-latency block storage ideal for demanding ML training workloads."
  },
  {
    "taskStatement": "1.1",
    "stem": "In a data pipeline, if you must process streaming data and maintain stateful transformations, which AWS streaming service is recommended?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon Kinesis Data Streams only",
      "B": "Apache Flink on Amazon Kinesis Data Analytics",
      "C": "AWS Lambda triggered by Kinesis streams",
      "D": "Amazon S3 event notifications"
    },
    "explanation": "Apache Flink supports stateful stream processing and integrates with Kinesis Data Analytics, enabling complex event processing on streaming data."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which AWS service provides serverless ETL capabilities for data transformation before ML ingestion?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon EMR",
      "B": "AWS Glue",
      "C": "Amazon SageMaker",
      "D": "AWS Lambda"
    },
    "explanation": "AWS Glue is a serverless ETL service designed to prepare and transform data for analytics and machine learning workflows without managing infrastructure."
  },
  {
    "taskStatement": "1.1",
    "stem": "When ingesting large datasets into Amazon SageMaker Data Wrangler, which storage source is natively supported?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon EBS volumes",
      "B": "Amazon RDS directly",
      "C": "Amazon DynamoDB only",
      "D": "Amazon S3"
    },
    "explanation": "Amazon SageMaker Data Wrangler natively supports data ingestion from Amazon S3, allowing users to explore and transform datasets easily."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which of the following best describes Apache ORC compared to Apache Parquet?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "ORC is row-based while Parquet is columnar",
      "B": "ORC is optimized for JSON data ingestion",
      "C": "Both ORC and Parquet are columnar formats optimized for big data workloads with slightly different serialization implementations",
      "D": "Parquet supports complex nested data, ORC does not"
    },
    "explanation": "Apache ORC and Apache Parquet are both columnar storage formats designed for big data processing with efficient compression and encoding but differ in details of implementation."
  },
  {
    "taskStatement": "1.1",
    "stem": "If you need to merge a large volume of disparate data sources quickly for ML, which AWS tool provides scalable, serverless ETL capabilities?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon Athena",
      "B": "AWS Glue",
      "C": "Amazon SageMaker Pipelines",
      "D": "Amazon EMR clusters managed manually"
    },
    "explanation": "AWS Glue is a managed ETL service that simplifies the process of extracting, transforming, and loading data at scale."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which Amazon storage service provides a hierarchical file system interface with high throughput and low latency, suitable for shared ML datasets?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon FSx for NetApp ONTAP",
      "B": "Amazon S3 Glacier",
      "C": "Amazon Elastic Block Store (EBS)",
      "D": "Amazon DynamoDB"
    },
    "explanation": "Amazon FSx for NetApp ONTAP offers enterprise-grade network file storage with a hierarchical structure and supports standard SMB/NFS protocols, ideal for shared ML workloads."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which data ingestion challenge is most likely to cause capacity issues when storing large volumes of streaming data for ML?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Using data formats too compact for easy retrieval",
      "B": "Using batch ingestion instead of streaming",
      "C": "Selecting appropriate AWS region for geographic proximity",
      "D": "Provisioning insufficient throughput and storage capacity for the storage solution"
    },
    "explanation": "Insufficient storage throughput or capacity can cause bottlenecks and failures during ingestion of high-volume streaming data, affecting ML data pipelines."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which data storage option offers the highest durability and availability for ML datasets in AWS?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon EFS",
      "B": "Amazon S3 Standard",
      "C": "Amazon FSx",
      "D": "Amazon EBS"
    },
    "explanation": "Amazon S3 Standard storage class provides eleven 9's (99.999999999%) of durability and high availability, making it a reliable choice for ML data storage."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which of these ingestion mechanisms provides the lowest latency for real-time ML data pipelines on AWS?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon Kinesis Data Streams",
      "B": "Amazon S3 batch upload",
      "C": "AWS Glue ETL jobs",
      "D": "Amazon RDS snapshots"
    },
    "explanation": "Amazon Kinesis Data Streams supports real-time streaming data ingestion with low latency, suitable for immediate ML model inference or processing."
  },
  {
    "taskStatement": "1.1",
    "stem": "What are typical tradeoffs when selecting AWS storage options for ML data ingestion?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Availability versus encryption",
      "B": "User interface simplicity versus compute power",
      "C": "Cost, performance (throughput/latency), and data structure compatibility",
      "D": "File size versus file name length"
    },
    "explanation": "Choosing AWS storage requires balancing cost, performance metrics like throughput and latency, and compatibility with data formats and access patterns."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which AWS service can be used to automate troubleshooting and debugging of data ingestion issues related to capacity and scalability in ML pipelines?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS CloudFormation",
      "B": "Amazon CloudWatch",
      "C": "AWS CodePipeline",
      "D": "Amazon QuickSight"
    },
    "explanation": "Amazon CloudWatch monitors metrics and logs that can help identify bottlenecks, capacity constraints, and failures in data ingestion workflows."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which AWS service is commonly used to ingest and process large-scale IoT sensor data streams for ML training purposes?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon Kinesis Data Streams",
      "B": "Amazon S3 Glacier",
      "C": "Amazon EMR",
      "D": "AWS Step Functions"
    },
    "explanation": "Amazon Kinesis Data Streams is designed for ingesting massive, continuous streams of IoT data for real-time processing and ML applications."
  },
  {
    "taskStatement": "1.1",
    "stem": "What is the main advantage of using columnar formats like Parquet and ORC over row-based formats in ML data preparation?",
    "correct": "C",
    "difficulty": "EASY",
    "answers": {
      "A": "Simpler schema definitions",
      "B": "Better exploitation of nested data",
      "C": "Faster analytics queries by reading only relevant columns",
      "D": "Lower data compression ratios"
    },
    "explanation": "Columnar formats are optimized for analytics by scanning only necessary columns, which reduces disk I/O and speeds up queries."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which method is best to merge datasets from multiple S3 buckets with different data formats for ML ingestion?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use AWS Glue ETL jobs to convert and merge data into a common format",
      "B": "Manually download and merge datasets locally",
      "C": "Use Amazon SageMaker directly on multiple sources without transformation",
      "D": "Use Amazon Athena to join data without transformation"
    },
    "explanation": "AWS Glue ETL enables scalable, automated data preparation including merging and format conversion suited for ML ingestion."
  },
  {
    "taskStatement": "1.1",
    "stem": "For training ML models with data stored on Amazon S3, what is a key factor when choosing a data format to optimize training performance?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Simplicity of the format",
      "B": "Ease of human readability",
      "C": "Format popularity",
      "D": "Compatibility with distributed processing frameworks and columnar compression"
    },
    "explanation": "Columnar, compressed data formats like Parquet are optimized for distributed ML training frameworks, reducing IO and improving performance."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which AWS storage service supports storing petabytes of unstructured data accessible via REST APIs?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon EFS",
      "B": "Amazon Elastic Block Store (EBS)",
      "C": "Amazon S3",
      "D": "Amazon FSx for Windows File Server"
    },
    "explanation": "Amazon S3 is an object storage service designed for massive scalability accessible via RESTful APIs."
  },
  {
    "taskStatement": "1.1",
    "stem": "When ingesting data for ML, why might you choose JSON over CSV format?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "JSON files are smaller in size than CSV",
      "B": "JSON supports nested and hierarchical data structures",
      "C": "JSON is easier to read for humans",
      "D": "CSV supports nested structures better"
    },
    "explanation": "JSON supports complex nested and hierarchical data which cannot be represented in flat CSV files, useful for certain ML datasets."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which AWS service provides a scalable, serverless, managed Apache Spark environment for data processing and ingestion?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Glue DataBrew",
      "B": "Amazon EMR with manual provisioning",
      "C": "AWS Glue",
      "D": "Amazon SageMaker Studio"
    },
    "explanation": "AWS Glue offers serverless Spark environments with automatic scaling for ETL workloads, including data ingestion and transformation."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which AWS storage solution provides native encryption at rest and in transit with automatic key management suitable for sensitive ML data?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon EBS without encryption",
      "B": "Amazon S3 with AWS KMS integration",
      "C": "Local instance storage on EC2",
      "D": "Amazon EFS without encryption"
    },
    "explanation": "Amazon S3 integrates with AWS KMS for encryption at rest with automatic key management and supports encryption in transit with HTTPS."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which AWS service integrates with Apache Kafka to ingest streaming data for ML workflows?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon S3",
      "B": "AWS Glue",
      "C": "Amazon EMR",
      "D": "Amazon Managed Streaming for Apache Kafka (MSK)"
    },
    "explanation": "Amazon MSK is a fully managed service for Apache Kafka, facilitating streaming data ingestion into ML pipelines."
  },
  {
    "taskStatement": "1.1",
    "stem": "What is the primary benefit of using Amazon S3 Storage Class Analysis when planning data storage for ML workflows?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Identify data access patterns to optimize cost and performance",
      "B": "Encrypt data automatically",
      "C": "Automatically categorize data by content type",
      "D": "Convert data formats to Parquet"
    },
    "explanation": "S3 Storage Class Analysis helps analyze how frequently data is accessed to recommend cost-effective storage classes without compromising performance."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which of these data ingestion scenarios is best suited for Amazon EBS over Amazon S3?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Storing large volumes of unstructured data for archival",
      "B": "High-throughput block storage with low latency for training datasets attached to EC2 instances",
      "C": "Serving static website content",
      "D": "Long-term immutable backups"
    },
    "explanation": "Amazon EBS offers persistent block storage with low latency suitable for ML training data requiring fast I/O attached directly to EC2."
  },
  {
    "taskStatement": "1.1",
    "stem": "When storing machine learning data that requires compliance with data residency laws, which AWS feature should be considered first?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Using Amazon Glacier for archival",
      "B": "Encrypting data at rest",
      "C": "Selecting AWS Regions to ensure data does not leave jurisdiction",
      "D": "Using public S3 buckets"
    },
    "explanation": "Data residency compliance relates to where data physically resides; choosing AWS regions accordingly ensures legal requirements are met."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which AWS storage type supports hierarchical namespace and is used for big data workloads requiring Hadoop compatibility?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon S3 Standard",
      "B": "Amazon EFS",
      "C": "Amazon DynamoDB",
      "D": "Amazon EMR File System (EMRFS) backed by Amazon S3"
    },
    "explanation": "EMRFS extends Amazon S3 with Hadoop-compatible features like support for hierarchical namespace, making it suitable for big data workloads."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which factor is critical when choosing between Amazon S3 and Amazon EFS for storing machine learning datasets?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Cost differences only",
      "B": "Access patterns and need for shared file system semantics",
      "C": "Supported file formats",
      "D": "Encryption capabilities"
    },
    "explanation": "Amazon EFS provides a POSIX-compliant shared file system for concurrent access by multiple clients, while S3 is object storage optimized for scalability but lacks shared filesystem semantics."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which AWS options help reduce latency when accessing data stored in Amazon S3 from geographically distant locations?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon S3 Transfer Acceleration",
      "B": "Amazon Glacier Deep Archive",
      "C": "Increasing S3 read timeout settings",
      "D": "Using Amazon Macie"
    },
    "explanation": "S3 Transfer Acceleration leverages Amazon CloudFront\u2019s edge locations to provide fast and secure transfers over long distances."
  },
  {
    "taskStatement": "1.1",
    "stem": "When ingesting large datasets into ML pipelines, how does using Apache Parquet help reduce storage costs?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Its row format stores data redundantly to improve speed",
      "B": "Its columnar format enables compression and reduces I/O",
      "C": "It automatically deletes unused data",
      "D": "It moves data to cheaper storage classes"
    },
    "explanation": "Apache Parquet\u2019s columnar format enables better compression and reduces read I/O by storing similar data types together."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which tool would you use to move large datasets from on-premises environments to Amazon S3 for ML training?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Glue DataBrew",
      "B": "Amazon Kinesis Data Streams",
      "C": "AWS DataSync",
      "D": "Amazon SageMaker Studio"
    },
    "explanation": "AWS DataSync securely and efficiently transfers large volumes of data from on-premises storage to AWS storage services like Amazon S3."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which data ingestion method should be used when high throughput and low-latency batch ingestion is required for ML workloads?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Uploading JSON files manually",
      "B": "Using Amazon DynamoDB streams",
      "C": "Streaming via AWS Lambda triggers",
      "D": "Parallel multipart upload to Amazon S3 using Transfer Acceleration"
    },
    "explanation": "Multipart upload with Transfer Acceleration allows efficient, low latency batch data ingestion to Amazon S3."
  },
  {
    "taskStatement": "1.1",
    "stem": "In a multi-tenant ML environment, which AWS service helps securely segregate training data within the same Amazon S3 bucket?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Glue DataBrew",
      "B": "Amazon SageMaker Ground Truth",
      "C": "S3 bucket policies and IAM policies",
      "D": "Amazon EMR security groups"
    },
    "explanation": "S3 bucket policies combined with IAM policies can restrict access to specific prefixes or objects to enforce tenant data isolation."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which of the following is NOT a key consideration when making initial storage decisions for ML raw data in AWS?",
    "correct": "D",
    "difficulty": "EASY",
    "answers": {
      "A": "Cost of storage",
      "B": "Performance / latency requirements",
      "C": "Data structure and access patterns",
      "D": "Color of the AWS console"
    },
    "explanation": "The color of the AWS console is irrelevant; key considerations include cost, performance, and data format compatibility."
  },
  {
    "taskStatement": "1.1",
    "stem": "Which AWS service can ingest streaming data and apply simple transformations before feeding into ML pipelines?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon S3 Glacier Deep Archive",
      "B": "AWS Lambda triggered by Kinesis streams",
      "C": "Amazon SageMaker Model Monitor",
      "D": "AWS Glue Data Quality"
    },
    "explanation": "AWS Lambda can be triggered by Kinesis streaming data to perform lightweight, real-time transformations before ingestion into ML pipelines."
  },
  {
    "taskStatement": "1.2",
    "stem": "Which AWS service is most suitable for visually exploring, cleaning, and transforming tabular data before training a machine learning model?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Glue Data Quality",
      "B": "Amazon SageMaker Data Wrangler",
      "C": "Amazon Kinesis Data Streams",
      "D": "AWS Lambda"
    },
    "explanation": "Amazon SageMaker Data Wrangler provides an integrated visual interface designed specifically to explore, clean, and transform data interactively, making it ideal for feature engineering before ML training. AWS Glue Data Quality focuses on data validation, Kinesis is for streaming ingestion, and Lambda is for serverless compute rather than data transformation."
  },
  {
    "taskStatement": "1.2",
    "stem": "What is the primary benefit of using Amazon SageMaker Feature Store in the context of feature engineering?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "It automatically selects the best features for model training.",
      "B": "It merges data from multiple unstructured sources.",
      "C": "It provides a centralized repository for storing, retrieving, and sharing engineered features across teams and models.",
      "D": "It performs real-time data encryption for sensitive features."
    },
    "explanation": "SageMaker Feature Store acts as a centralized feature repository that enables consistent use, sharing, and reusability of features across different models and teams, ensuring reliability and reducing duplication in feature engineering workflows."
  },
  {
    "taskStatement": "1.2",
    "stem": "In feature engineering, why might one use binning (discretization) of continuous variables before training a model?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "To reduce the effect of outliers and create categorical groupings that may improve model interpretability.",
      "B": "To increase the dimensionality of the dataset for complex models.",
      "C": "To normalize data distribution to a Gaussian form.",
      "D": "To encode categorical features into numerical format."
    },
    "explanation": "Binning converts continuous features into categorical bins, which helps reduce the impact of outliers and can enhance model interpretability by grouping ranges into categories."
  },
  {
    "taskStatement": "1.2",
    "stem": "Which encoding technique is most appropriate to represent an ordinal categorical variable for a machine learning model?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "One-hot encoding",
      "B": "Tokenization",
      "C": "Binary encoding",
      "D": "Label encoding"
    },
    "explanation": "Label encoding assigns an integer value to each category preserving the order of ordinal variables. One-hot encoding removes order information, which is crucial for ordinal variables."
  },
  {
    "taskStatement": "1.2",
    "stem": "When using SageMaker Data Wrangler to perform feature scaling, which method would be most appropriate to standardize features to have zero mean and unit variance?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Min-max normalization",
      "B": "Standardization (Z-score normalization)",
      "C": "Log transformation",
      "D": "Binning"
    },
    "explanation": "Standardization subtracts the mean and divides by the standard deviation, resulting in features with zero mean and unit variance, which is helpful for many ML algorithms."
  },
  {
    "taskStatement": "1.2",
    "stem": "Which AWS service can be used to generate synthetic labeled datasets by combining annotation with human review to ensure high-quality labels?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon SageMaker Data Wrangler",
      "B": "AWS Glue DataBrew",
      "C": "Amazon SageMaker Ground Truth",
      "D": "AWS Glue"
    },
    "explanation": "Amazon SageMaker Ground Truth is designed to create labeled datasets, often combining machine learning and human annotation workflows to ensure quality."
  },
  {
    "taskStatement": "1.2",
    "stem": "When transforming streaming data for feature engineering, which combination of AWS services is best suited for real-time data transformation in an ML pipeline?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Glue and Amazon Redshift",
      "B": "AWS Lambda and AWS Glue DataBrew",
      "C": "Amazon EMR and Amazon SageMaker Studio",
      "D": "AWS Lambda and Apache Spark on Amazon EMR"
    },
    "explanation": "AWS Lambda enables real-time event-driven processing, and Apache Spark on Amazon EMR can perform scalable stream transformations making this combination effective for streaming data transformation."
  },
  {
    "taskStatement": "1.2",
    "stem": "What kind of data transformation is performed when applying a log transformation on positively skewed continuous data during feature engineering?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "To increase the value range of data",
      "B": "To convert categorical data into numerical",
      "C": "To reduce skewness and make the distribution more symmetric",
      "D": "To one-hot encode categorical variables"
    },
    "explanation": "Log transformation compresses the range of positively skewed data and helps in reducing skewness making the distribution more normal-like."
  },
  {
    "taskStatement": "1.2",
    "stem": "In deduplication, which of the following best describes how AWS Glue or Apache Spark techniques help ensure data quality before model training?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Identify and eliminate duplicate records based on key attributes to prevent bias and overfitting.",
      "B": "Encrypt duplicate records to ensure security compliance.",
      "C": "Automatically merge all duplicate records into one feature vector.",
      "D": "Flag duplicates but retain all for model diversity."
    },
    "explanation": "Removing duplicate records avoids data leakage and bias, reducing overfitting and improving model generalization."
  },
  {
    "taskStatement": "1.2",
    "stem": "Which feature engineering technique is best when you want to reduce the effect of outliers and create robust models by rescaling feature ranges without assuming a Gaussian distribution?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Z-score standardization",
      "B": "Min-max scaling",
      "C": "Logarithmic transformation",
      "D": "Robust scaling using median and interquartile range"
    },
    "explanation": "Robust scaling uses median and interquartile range, making it resistant to outliers as it does not assume normal distribution."
  },
  {
    "taskStatement": "1.2",
    "stem": "When merging multiple datasets for feature engineering, what is a key consideration to avoid data leakage that can compromise model performance?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Ensure all datasets have the same number of rows",
      "B": "Join datasets only on training data features that will be available during inference",
      "C": "Merge datasets without regard to time or sequence",
      "D": "Use all available columns regardless of availability at inference"
    },
    "explanation": "Joining data on features that won\u2019t be known during inference causes data leakage and leads to overly optimistic model performance."
  },
  {
    "taskStatement": "1.2",
    "stem": "What is the effect of tokenization as an encoding technique in the context of text feature engineering for ML models?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Transforms numerical categories to ordinal labels",
      "B": "Converts categorical variables to binary form",
      "C": "Splits text into smaller units such as words or subwords for numeric representation",
      "D": "Creates continuous numerical features from categorical ones"
    },
    "explanation": "Tokenization breaks down text into meaningful segments such as words or subwords, which can then be converted into numeric vectors suitable for modeling."
  },
  {
    "taskStatement": "1.2",
    "stem": "How can using AWS Glue DataBrew assist in the data cleaning step of feature engineering?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "By providing a visual interface to profile data, identify anomalies, and perform transformations without coding",
      "B": "By running large-scale distributed training of machine learning models",
      "C": "By providing GPU-accelerated model deployment",
      "D": "By streaming real-time data ingestion"
    },
    "explanation": "AWS Glue DataBrew offers a no-code experience for data cleaning and transformation by profiling data and detecting anomalies visually, easing the feature engineering process."
  },
  {
    "taskStatement": "1.2",
    "stem": "Which is a drawback of one-hot encoding for high-cardinality categorical features when used in ML models?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "It reduces model interpretability significantly",
      "B": "It introduces unwanted ordinal relationships",
      "C": "It cannot be applied to categorical variables",
      "D": "It significantly increases dimensionality leading to computational inefficiency"
    },
    "explanation": "One-hot encoding transforms categories into sparse binary vectors, which can cause very high dimensionality for high-cardinality features, increasing computational cost."
  },
  {
    "taskStatement": "1.2",
    "stem": "What approach should you take to combine features from multiple sources for training datasets using AWS Glue or Apache Spark?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Randomly join all data without keys to maximize data volume",
      "B": "Use appropriate join keys reflecting relationships and apply transformation logic for schema alignment",
      "C": "Manually concatenate CSV files before ingestion",
      "D": "Merge data only at inference time"
    },
    "explanation": "Using meaningful join keys and aligning schemas ensures data integrity and suitable feature generation necessary for reliable model training."
  },
  {
    "taskStatement": "1.2",
    "stem": "Which feature engineering method helps reduce multicollinearity by combining multiple correlated features into a single or fewer features?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Binning",
      "B": "One-hot encoding",
      "C": "Principal Component Analysis (PCA)",
      "D": "Label encoding"
    },
    "explanation": "PCA transforms correlated features into fewer uncorrelated principal components, reducing multicollinearity and simplifying the feature space."
  },
  {
    "taskStatement": "1.2",
    "stem": "Which AWS tool can you use to identify outliers during the data transformation process?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "SageMaker Model Monitor",
      "B": "SageMaker Data Wrangler",
      "C": "AWS Kinesis Data Streams",
      "D": "Amazon EMR"
    },
    "explanation": "SageMaker Data Wrangler provides built-in visualizations and data profiling features that assist in detecting outliers during transformation."
  },
  {
    "taskStatement": "1.2",
    "stem": "Regarding feature transformation for text data, which AWS service allows semi-automated labeling combined with human review to produce quality labeled datasets efficiently?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon SageMaker Feature Store",
      "B": "AWS Glue DataBrew",
      "C": "Amazon Mechanical Turk alone",
      "D": "Amazon SageMaker Ground Truth"
    },
    "explanation": "SageMaker Ground Truth combines machine learning labeling and human review workflows to create high-quality labeled datasets efficiently."
  },
  {
    "taskStatement": "1.2",
    "stem": "What is a common use case for applying the log transformation technique in feature engineering on numeric data?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Handle skewed distributions to stabilize variance and make data more Gaussian-like.",
      "B": "Convert categorical variables into numeric format.",
      "C": "Normalize data between 0 and 1.",
      "D": "Reduce dimensionality of features."
    },
    "explanation": "Log transformation is used primarily to reduce positive skewness in data, stabilizing variance and meeting assumptions of many modeling algorithms."
  },
  {
    "taskStatement": "1.2",
    "stem": "Which encoding technique preserves the relationship between categories when the values have a natural order?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "One-hot encoding",
      "B": "Binary encoding",
      "C": "Tokenization",
      "D": "Label encoding"
    },
    "explanation": "Label encoding assigns ordered integer labels to categories, preserving ordinal relationships needed for ordinal variables."
  },
  {
    "taskStatement": "1.2",
    "stem": "When preparing features for streaming ML workloads, what is one benefit of using AWS Lambda with streaming data sources like Amazon Kinesis?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Batch processing at fixed intervals only",
      "B": "Real-time, event-driven transformation and filtering of streaming records",
      "C": "Providing GPU-accelerated transformations in real time",
      "D": "Long-running ETL orchestration for large static datasets"
    },
    "explanation": "AWS Lambda can process Kinesis streams with real-time, event-driven functions enabling on-the-fly data transformation and filtering for streaming ML applications."
  },
  {
    "taskStatement": "1.2",
    "stem": "Which of the following is a key skill when using Apache Spark in Amazon EMR for feature engineering?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Developing custom SageMaker algorithms",
      "B": "Visualizing data in SageMaker Studio notebooks",
      "C": "Writing distributed data transformation and aggregation jobs handling large-scale datasets efficiently",
      "D": "Configuring AWS Identity and Access Management (IAM) roles"
    },
    "explanation": "Apache Spark enables distributed processing of large datasets, so writing efficient transformations and aggregations is vital for scalable feature engineering."
  },
  {
    "taskStatement": "1.2",
    "stem": "What is one reason to use AWS Glue Data Quality during feature engineering?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "To validate data quality metrics and detect anomalies before transformation",
      "B": "To handle real-time streaming data processing",
      "C": "To host feature stores for models",
      "D": "To automate hyperparameter tuning"
    },
    "explanation": "AWS Glue Data Quality helps profile and validate datasets by monitoring data quality metrics and detecting anomalies early in the pipeline."
  },
  {
    "taskStatement": "1.2",
    "stem": "Which AWS service lets you orchestrate and automate feature engineering workflows including transformation and labeling?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon Athena",
      "B": "AWS Glue DataBrew",
      "C": "Amazon SageMaker Feature Store",
      "D": "Amazon SageMaker Pipelines"
    },
    "explanation": "Amazon SageMaker Pipelines supports automation and orchestration of ML workflows, including data preparation, feature transformation, and labeling."
  },
  {
    "taskStatement": "1.2",
    "stem": "How does one-hot encoding represent categorical variables in a numerical format suitable for ML models?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "By creating binary vectors where each category is represented by a separate feature with values 0 or 1",
      "B": "By assigning integers in range 0 to N to categories",
      "C": "By splitting text into tokens",
      "D": "By calculating logarithmic values of numerical categories"
    },
    "explanation": "One-hot encoding creates a binary vector per category, representing presence or absence, commonly used to encode nominal categorical data."
  },
  {
    "taskStatement": "1.2",
    "stem": "Which is an advantage of using SageMaker Data Wrangler over traditional coding approaches during feature engineering?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "It removes the need for model retraining",
      "B": "Provides an integrated visual and code-based environment for fast, interactive data exploration and transformation",
      "C": "Automatically tunes hyperparameters during feature creation",
      "D": "Provides real-time streaming analytics capabilities"
    },
    "explanation": "Data Wrangler offers both visual UI and code interfaces to speed up data preparation with integrated transformations and quick feature engineering iterations."
  },
  {
    "taskStatement": "1.2",
    "stem": "What type of feature engineering can mitigate missing data issues in your dataset before training ML models?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Imputation techniques like mean/mode substitution or more advanced algorithms",
      "B": "One-hot encoding",
      "C": "Tokenization",
      "D": "Min-max scaling"
    },
    "explanation": "Imputation fills missing values with appropriate estimates to prevent loss of information and improve model robustness."
  },
  {
    "taskStatement": "1.2",
    "stem": "Why is it important to validate quality and consistency of engineered features using tools like SageMaker Data Wrangler before training a model?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "To increase model training speed drastically",
      "B": "To create complex tree-based models automatically",
      "C": "To ensure that incorrect or skewed features do not negatively impact model accuracy and bias",
      "D": "To reduce the number of data points in training"
    },
    "explanation": "Validation ensures feature distributions are correct and consistent, preventing model inaccuracies or bias caused by flawed input features."
  },
  {
    "taskStatement": "1.2",
    "stem": "Which AWS service offers SDKs and APIs to manage and query feature data for ML efficiently across training and inference pipelines?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Glue DataBrew",
      "B": "Amazon Athena",
      "C": "Amazon SageMaker Feature Store",
      "D": "AWS Lambda"
    },
    "explanation": "SageMaker Feature Store provides APIs and SDKs for storing, retrieving, and sharing features, bridging feature engineering between training and inference."
  },
  {
    "taskStatement": "1.2",
    "stem": "You have categorical features with high cardinality. Which encoding technique would balance dimensionality and preserve information better than one-hot encoding?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Label encoding",
      "B": "Binary encoding",
      "C": "Tokenization",
      "D": "Binning"
    },
    "explanation": "Binary encoding converts categories into binary digits, reducing dimensionality compared to one-hot encoding while preserving category information better than label encoding."
  },
  {
    "taskStatement": "1.2",
    "stem": "When performing feature engineering on time series data, which AWS tool is most suitable for scalable batch transformations on large datasets?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "SageMaker Ground Truth",
      "B": "AWS Lambda",
      "C": "Apache Spark on Amazon EMR",
      "D": "SageMaker Feature Store"
    },
    "explanation": "Apache Spark on Amazon EMR provides scalable cluster computing for batch transformations on huge datasets, which is common in time series data preparation."
  },
  {
    "taskStatement": "1.2",
    "stem": "How does feature scaling like normalization impact ML model training and convergence?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "It brings all features to a common scale, improving convergence speed and preventing features with large values from dominating",
      "B": "It encrypts data for security",
      "C": "It increases dimensionality for richer features",
      "D": "It identifies outliers"
    },
    "explanation": "Scaling features to similar ranges helps gradient-based optimizers converge faster and prevents features with large magnitude from biasing the model."
  },
  {
    "taskStatement": "1.2",
    "stem": "If a dataset has missing values that cannot be imputed reasonably, which action should be taken before model training?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Apply one-hot encoding to missing values",
      "B": "Transform missing values into zeros",
      "C": "Remove records with missing values if they are a small percentage or consider feature removal",
      "D": "Use log transformation"
    },
    "explanation": "If imputation is not suitable and missing data points are few, removing those records or features helps maintain data quality."
  },
  {
    "taskStatement": "1.2",
    "stem": "Which AWS feature engineering tool includes support for applying complex user-defined transformations on datasets via custom scripting?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon SageMaker Data Wrangler (supporting Python scripts)",
      "B": "AWS Glue Data Quality",
      "C": "AWS Lambda",
      "D": "Amazon Athena"
    },
    "explanation": "SageMaker Data Wrangler supports applying custom code transformations using Python scripts within its visual dataflow environment."
  },
  {
    "taskStatement": "1.2",
    "stem": "When you perform feature splitting during feature engineering, what is an example of this technique?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Normalizing feature values between 0 and 1",
      "B": "Extracting day, month, year from a timestamp into separate features",
      "C": "Combining features into a single composite feature",
      "D": "One-hot encoding categorical variables"
    },
    "explanation": "Feature splitting breaks complex features into multiple simpler features, such as decomposing a timestamp into date components."
  },
  {
    "taskStatement": "1.2",
    "stem": "What is a recommended approach to handle noisy or erroneous data during feature transformation?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Detect and treat outliers through techniques such as trimming, winsorization, or imputation",
      "B": "Remove all missing values regardless of volume",
      "C": "Use one-hot encoding on noisy features",
      "D": "Ignore noise as models inherently handle it"
    },
    "explanation": "Treating outliers and noisy data through detection and appropriate techniques helps prevent model bias and instability."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which AWS service can be used specifically to detect and mitigate selection and measurement bias in datasets prior to model training?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Glue DataBrew",
      "B": "Amazon SageMaker Model Monitor",
      "C": "Amazon SageMaker Clarify",
      "D": "Amazon Athena"
    },
    "explanation": "Amazon SageMaker Clarify provides functionalities to identify and mitigate bias such as selection and measurement bias in datasets before model training, unlike AWS Glue DataBrew which focuses on cleaning and transforming data."
  },
  {
    "taskStatement": "1.3",
    "stem": "When preparing data to reduce prediction bias in model training, which of the following techniques is LEAST effective?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Shuffling the dataset before splitting",
      "B": "Dataset splitting ensuring balanced representation of classes",
      "C": "Synthetic data augmentation for underrepresented classes",
      "D": "Encrypting the dataset prior to training"
    },
    "explanation": "Encrypting data protects privacy and confidentiality but does not reduce prediction bias directly; techniques like shuffling and augmentation are more effective in addressing bias."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which technique is most appropriate to identify data quality issues that might violate compliance requirements such as PII or PHI in a dataset?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Using Amazon SageMaker Ground Truth to label data",
      "B": "Implementing AWS Glue Data Quality rules",
      "C": "One-hot encoding categorical variables",
      "D": "Applying log transformation on numerical features"
    },
    "explanation": "AWS Glue Data Quality allows defining and running rules that validate data integrity and flag issues related to compliance data, including presence of sensitive information."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which of the following is a recommended practice to address class imbalance (CI) in numeric datasets prior to training?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Perform resampling techniques such as oversampling minority classes",
      "B": "Apply label encoding to class labels",
      "C": "Encrypt sensitive numeric features",
      "D": "Deploy models on serverless endpoints"
    },
    "explanation": "Resampling, like oversampling minority classes, is a common technique to mitigate class imbalance before training models."
  },
  {
    "taskStatement": "1.3",
    "stem": "What is a valid approach to comply with data residency regulations when preparing datasets for ML modeling in AWS?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Store data globally in Amazon S3 buckets in any region",
      "B": "Use Amazon S3 bucket policies to restrict access based on region",
      "C": "Apply one-hot encoding to sensitive attributes",
      "D": "Enable automatic hyperparameter tuning"
    },
    "explanation": "Using S3 bucket policies and replication controls, data residency requirements can be enforced by restricting data storage and access to specific AWS regions."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which encryption technique is best suited to protect sensitive data at rest while maintaining compatibility with SageMaker model training?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Key Management Service (KMS) to encrypt Amazon S3 data",
      "B": "Custom symmetric encryption before uploading to S3",
      "C": "Encrypt data only in transit using SSL/TLS",
      "D": "Obfuscate data by tokenization only"
    },
    "explanation": "AWS KMS integrates seamlessly with S3 and SageMaker enabling encryption at rest without affecting downstream ML workflows."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which AWS service combination helps automate validation of data quality and detect data drift in datasets to ensure data integrity over time?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Lambda and Amazon Athena",
      "B": "Amazon S3 and AWS Glue DataBrew",
      "C": "Amazon SageMaker Ground Truth and Amazon Kinesis",
      "D": "AWS Glue Data Quality and SageMaker Model Monitor"
    },
    "explanation": "AWS Glue Data Quality validates data quality proactively, while SageMaker Model Monitor detects drift during inference, together securing data integrity."
  },
  {
    "taskStatement": "1.3",
    "stem": "In the context of ML data preparation, what does the metric 'Difference in Proportions of Labels (DPL)' signify?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "The fraction of missing values in numerical features",
      "B": "The accuracy difference between training and test sets",
      "C": "A pre-training bias metric quantifying label distribution disparities between groups",
      "D": "The number of epochs needed for convergence"
    },
    "explanation": "DPL measures distributional differences of labels between sensitive groups to quantify bias before model training."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which data preparation step is critical to reduce prediction bias due to dataset imbalance in text classification tasks?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Perform dimensionality reduction using PCA",
      "B": "Use resampling or synthetic data generation for underrepresented classes",
      "C": "Avoid tokenization to preserve original text",
      "D": "Encrypt training data with asymmetric keys"
    },
    "explanation": "In text classification, addressing class imbalance through resampling or synthetic generation reduces prediction bias."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which AWS service can help in anonymizing sensitive fields in datasets to meet compliance requirements before training?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon Macie for discovering and protecting sensitive data",
      "B": "Amazon SageMaker Model Monitor",
      "C": "AWS CodePipeline",
      "D": "Amazon Kinesis Data Firehose"
    },
    "explanation": "Amazon Macie automatically discovers, classifies, and protects sensitive data enabling proper anonymization and compliance."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which method is effective to ensure data integrity when merging datasets from multiple sources for ML modeling?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use only JSON format for all source files",
      "B": "Perform one-hot encoding before merging",
      "C": "Validate schema consistency and apply deduplication techniques",
      "D": "Encrypt data in transit only"
    },
    "explanation": "Validating schemas and removing duplicated records ensures data integrity when merging heterogeneous sources."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which of the following is an example of a technique to treat outliers to maintain data integrity before training a machine learning model?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Shuffling dataset records randomly",
      "B": "Capping or removing values that exceed a certain percentile threshold",
      "C": "Encrypting data records for privacy",
      "D": "Label encoding all categorical features"
    },
    "explanation": "Outlier capping limits extreme values to reduce their distortive effects on model training."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which AWS tool is best suited to perform initial storage capacity planning with regards to cost, performance, and data structure for ML datasets?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon SageMaker Clarify",
      "B": "AWS Cost Explorer",
      "C": "Amazon EMR",
      "D": "AWS Glue DataBrew"
    },
    "explanation": "AWS Glue DataBrew helps profile data to understand structure and patterns informing storage decisions with cost-performance tradeoffs."
  },
  {
    "taskStatement": "1.3",
    "stem": "When encrypting data used for training, which AWS capability ensures fine-grained key management and auditing of cryptographic operations?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Key Management Service (KMS)",
      "B": "AWS Secrets Manager",
      "C": "Amazon Macie",
      "D": "AWS CloudTrail"
    },
    "explanation": "AWS KMS provides managed encryption keys with audit capabilities to secure data in AWS ML workflows."
  },
  {
    "taskStatement": "1.3",
    "stem": "What is a primary risk of neglecting to validate data quality and bias prior to training an ML model on sensitive datasets?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Faster training epochs",
      "B": "Deployment of a biased model that causes unfair outcomes",
      "C": "Increased storage costs",
      "D": "Reduced compliance requirements"
    },
    "explanation": "Bias in data can propagate into models causing unethical or illegal biased decisions if not mitigated."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which of the following is NOT an example of a pre-training bias metric applicable for image datasets?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Class imbalance (CI)",
      "B": "Difference in proportions of labels (DPL)",
      "C": "Disparate impact ratio",
      "D": "Root Mean Square Error (RMSE)"
    },
    "explanation": "RMSE measures regression error and is not a bias metric for image dataset distributions."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which AWS service should be used to create high-quality labeled datasets with human-in-the-loop annotation to improve data quality for ML training?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon Athena",
      "B": "Amazon Kinesis Data Streams",
      "C": "Amazon SageMaker Ground Truth",
      "D": "AWS Glue Data Quality"
    },
    "explanation": "SageMaker Ground Truth enables human annotation to generate accurate labels and reduce noise in training datasets."
  },
  {
    "taskStatement": "1.3",
    "stem": "What is an appropriate measure to handle missing values in numeric datasets prior to ML modeling to maintain data integrity?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "Imputation using mean, median, or model-based approaches",
      "B": "Encrypting missing values with KMS",
      "C": "Discarding all records with missing values regardless of percentage",
      "D": "One-hot encoding missing values"
    },
    "explanation": "Imputation helps fill missing data with reasonable estimates to improve model learning rather than outright data loss."
  },
  {
    "taskStatement": "1.3",
    "stem": "How does SageMaker Clarify assist in maintaining data integrity with respect to compliance in ML workflows?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "By automatically encrypting data with AWS KMS",
      "B": "By providing metrics to detect bias and explainability issues in data and models",
      "C": "By provisioning secured VPC endpoints for SageMaker",
      "D": "By creating anonymized datasets automatically"
    },
    "explanation": "Clarify analyzes data and models for bias and interpretability to ensure fair and compliant ML practices."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which is a cost-effective and scalable storage option for large training datasets that require encryption and compliance with data residency requirements?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon Elastic File System (EFS) with no encryption",
      "B": "Amazon S3 Glacier",
      "C": "Amazon S3 with KMS encryption and region scoping",
      "D": "AWS Storage Gateway with local caching"
    },
    "explanation": "Amazon S3 supports data encryption and regional restrictions, fitting cost-effective large dataset storage with compliance."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which method is suitable for validating the quality of streaming data before it is ingested into SageMaker pipelines to prevent biased model predictions?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Using AWS Lambda functions with embedded data validation logic",
      "B": "Deploying models on Amazon EC2 instances",
      "C": "Manually reviewing streaming records",
      "D": "Encrypting streaming data only after ingestion"
    },
    "explanation": "AWS Lambda can automatically validate and transform streaming data in real time before it reaches ML workflows."
  },
  {
    "taskStatement": "1.3",
    "stem": "In the context of model fairness, which practice directly helps reduce measurement bias in datasets?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Increasing batch size during model training",
      "B": "Applying one-hot encoding to categorical variables",
      "C": "Limiting training to only numeric features",
      "D": "Ensuring consistent and accurate data collection procedures"
    },
    "explanation": "Measurement bias arises from inconsistencies/errors in data collection; standardizing collection reduces such bias."
  },
  {
    "taskStatement": "1.3",
    "stem": "To meet HIPAA compliance for protected health information (PHI) when preparing data for ML, which action is essential?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Encrypt the training data with symmetric keys only",
      "B": "Classify, anonymize, or mask PHI before training",
      "C": "Store all data in public S3 buckets for accessibility",
      "D": "Use only open-source libraries during training"
    },
    "explanation": "Anonymizing or masking PHI mitigates privacy risks and complies with regulations such as HIPAA."
  },
  {
    "taskStatement": "1.3",
    "stem": "During data preparation, what is the effect of overfitting the training dataset by failing to manage class imbalance properly?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "It improves generalization on new data",
      "B": "It reduces the model's complexity",
      "C": "It causes the model to perform poorly on minority classes",
      "D": "It shortens training duration"
    },
    "explanation": "Class imbalance leads to models biased toward majority classes, resulting in poor minority class performance."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which AWS service assists with maintaining audit trails to ensure continued compliance during ML data processing?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon SageMaker Batch Transform",
      "B": "AWS Shield",
      "C": "Amazon SageMaker Debugger",
      "D": "AWS CloudTrail"
    },
    "explanation": "AWS CloudTrail logs API activity and user actions providing trails necessary for audits and compliance."
  },
  {
    "taskStatement": "1.3",
    "stem": "What type of bias occurs when datasets exclude certain groups leading to underrepresentation in training data?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Selection bias",
      "B": "Measurement bias",
      "C": "Overfitting",
      "D": "Data leakage"
    },
    "explanation": "Selection bias arises when certain demographic or data groups are excluded, undermining model fairness."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which AWS feature allows the secure loading of data into training resources such as Amazon FSx or Amazon EFS ensuring data integrity?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Budgets for cost tracking",
      "B": "AWS Lambda for data transformation",
      "C": "Network configuration with VPC and IAM roles",
      "D": "Amazon CodeBuild for CI/CD"
    },
    "explanation": "Configuring proper IAM roles and VPC networking secures data ingress ensuring integrity and authorized access."
  },
  {
    "taskStatement": "1.3",
    "stem": "To mitigate bias in data labels, which process is preferred before model training?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Rely exclusively on automated labeling",
      "B": "Human-in-the-loop data review and correction",
      "C": "Remove all data points with ambiguous labels",
      "D": "Encrypt label data"
    },
    "explanation": "Human-in-the-loop processes ensure label accuracy and fairness versus fully automated noisy labeling."
  },
  {
    "taskStatement": "1.3",
    "stem": "In ML data preparation, what is the outcome of dataset shuffling combined with stratified splitting?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Both randomized and balanced subsets preserving class proportions",
      "B": "Entirely random splits ignoring class balance",
      "C": "Complete removal of duplicate records",
      "D": "Ensured chronological order of time series data"
    },
    "explanation": "Shuffling randomizes data order, and stratified splitting preserves class distribution improving fairness and evaluation."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which compliance implication requires masking or anonymizing data prior to ML training?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Mitigating overfitting",
      "B": "Improving model interpretability",
      "C": "Protecting personally identifiable information (PII)",
      "D": "Increasing training speed"
    },
    "explanation": "PII protection demands masking or anonymizing sensitive data to comply with privacy regulations."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which approach is most suitable to address measurement bias introduced by inconsistent feature extraction processes?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Discard features prone to encoding",
      "B": "Standardize feature extraction pipelines and logging",
      "C": "Use encryption to mask feature values",
      "D": "Increase the model complexity"
    },
    "explanation": "Standardizing extraction processes reduces inconsistencies causing measurement bias."
  },
  {
    "taskStatement": "1.3",
    "stem": "What is the purpose of using SageMaker Feature Store in the context of data integrity and preparation?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "To encrypt datasets automatically",
      "B": "To annotate data with labels only",
      "C": "To perform unsupervised feature learning",
      "D": "To create, store, and retrieve curated ML features reliably"
    },
    "explanation": "SageMaker Feature Store manages consistent feature repositories ensuring data and feature integrity."
  },
  {
    "taskStatement": "1.3",
    "stem": "Why is it important to detect and correct bias in the training data prior to model deployment in regulated industries?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "To reduce overall training time",
      "B": "To prevent discriminatory outcomes and ensure regulatory compliance",
      "C": "To improve data storage efficiency",
      "D": "To facilitate model compression"
    },
    "explanation": "Bias correction is critical to avoid unfair decisions and legal repercussions in regulated sectors."
  },
  {
    "taskStatement": "1.3",
    "stem": "How does higher class imbalance influence prediction bias in numeric ML datasets without mitigation?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Skewed predictions favoring majority classes",
      "B": "Even distribution of errors across classes",
      "C": "Increased training speed",
      "D": "Improved minority class recall"
    },
    "explanation": "Imbalanced classes cause models to bias predictions towards majority, harming fairness and accuracy."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which AWS service helps identify and mask sensitive data elements in datasets to comply with GDPR or similar data protection laws?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon Macie",
      "B": "AWS CloudTrail",
      "C": "Amazon S3 Transfer Acceleration",
      "D": "Amazon EMR"
    },
    "explanation": "Amazon Macie automatically discovers and protects sensitive data such as PII to aid compliance."
  },
  {
    "taskStatement": "1.3",
    "stem": "What data preparation strategy reduces variance in training data to improve model stability without significantly affecting bias?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Random undersampling",
      "B": "Removing entire feature columns",
      "C": "Data normalization and standardization",
      "D": "Encrypting dataset"
    },
    "explanation": "Normalization scales numeric features to reduce variance improving learning while retaining overall data integrity."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which compliance-related consideration must be addressed when migrating ML datasets across geographic AWS regions?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Scaling compute resources automatically",
      "B": "Ensuring data residency and sovereignty requirements are met",
      "C": "Encrypting all model hyperparameters",
      "D": "Applying one-hot encoding globally"
    },
    "explanation": "Data residency laws mandate storage and processing in approved regions, requiring compliance during migration."
  },
  {
    "taskStatement": "1.3",
    "stem": "Which feature of AWS Glue DataBrew is specifically useful to detect anomalies or inconsistencies affecting data integrity before training?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Serverless processing",
      "B": "Integration with SageMaker pipelines",
      "C": "Data lineage tracking",
      "D": "Built-in data profiling and validation rules"
    },
    "explanation": "DataBrew offers data profiling and validation to pinpoint anomalies impacting quality."
  },
  {
    "taskStatement": "2.1",
    "stem": "You need to select an ML algorithm to predict customer churn for a subscription service. The dataset is large, tabular, and has both numerical and categorical features. The business requires explainability for compliance. Which modeling approach best meets these criteria?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use a deep learning model like a multilayer perceptron to capture complex patterns.",
      "B": "Use a tree-based ensemble algorithm like XGBoost with feature importance for explainability.",
      "C": "Apply k-means clustering to segment customers and infer churn risk.",
      "D": "Use a pretrained transformer-based model designed for text to handle categorical features."
    },
    "explanation": "Tree-based ensemble methods like XGBoost provide strong predictive power for tabular data and offer explainability through feature importance, meeting both accuracy and compliance requirements. Deep learning models often lack interpretability, clustering is unsupervised, and transformer models are better suited for text data."
  },
  {
    "taskStatement": "2.1",
    "stem": "An ML engineer needs to choose an AWS SageMaker built-in algorithm for binary classification on a sparse dataset with high-dimensional categorical data. Which SageMaker algorithm is the most appropriate?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "XGBoost with default settings.",
      "B": "Linear Learner with regression objectives.",
      "C": "BlazingText for supervised text classification.",
      "D": "SageMaker Linear Learner optimized for classification with sparse datasets."
    },
    "explanation": "SageMaker Linear Learner supports classification and performs well on sparse, high-dimensional categorical data. XGBoost can be used but may require extensive feature engineering. BlazingText is for text data, and linear regression is for continuous targets."
  },
  {
    "taskStatement": "2.1",
    "stem": "You must select a model to automate image tagging in a highly diverse photo library. Which AWS approach is recommended for minimal training effort and optimal accuracy?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Train a convolutional neural network from scratch on the photo dataset.",
      "B": "Use SageMaker built-in linear regression algorithm with image embeddings.",
      "C": "Fine-tune a pretrained computer vision foundation model from Amazon Bedrock.",
      "D": "Perform clustering on image features using k-means in SageMaker."
    },
    "explanation": "Fine-tuning pretrained foundation models provides high accuracy with less training data and effort for computer vision tasks. Training from scratch is resource-intensive, linear regression is not suited for classification, and clustering does not provide tagging."
  },
  {
    "taskStatement": "2.1",
    "stem": "For a real-time fraud detection system requiring low latency and high accuracy, which SageMaker model deployment approach and model selection strategy should be prioritized?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy an ensemble of complex models on CPU instances to reduce operational cost.",
      "B": "Choose a high-performance gradient boosting model and deploy on GPU-based endpoints.",
      "C": "Use a deep reinforcement learning model with batch inference for fraud detection.",
      "D": "Deploy pretrained language models using asynchronous endpoints."
    },
    "explanation": "Gradient boosting models provide strong accuracy for tabular data, and GPU-based real-time endpoints ensure low inference latency, fulfilling fraud detection needs. Batch inference is too slow, CPU might be too slow, and language models are irrelevant here."
  },
  {
    "taskStatement": "2.1",
    "stem": "You are tasked with deploying a multi-class classification model for text sentiment analysis. Which SageMaker built-in algorithm should you choose to balance performance and cost?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "BlazingText supervised mode for text classification.",
      "B": "XGBoost with one-hot-encoded text inputs.",
      "C": "SageMaker Linear Learner configured for multi-class classification.",
      "D": "Use custom RNN model on SageMaker script mode."
    },
    "explanation": "BlazingText supervised mode is optimized for large-scale text classification with excellent performance and low cost. XGBoost and Linear Learner require extensive preprocessing. Custom RNNs need more development and compute resources."
  },
  {
    "taskStatement": "2.1",
    "stem": "When selecting a modeling approach to forecast hourly energy demand with time-series data, which method aligns best with SageMaker capabilities and typical practices?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use SageMaker built-in linear regression on raw time stamps without feature engineering.",
      "B": "Apply SageMaker BlazingText to convert time stamps to embeddings for forecasting.",
      "C": "Deploy SageMaker image classification algorithms on time-series graphs.",
      "D": "Feature engineer time components and train SageMaker XGBoost or DeepAR model for time-series forecasting."
    },
    "explanation": "SageMaker DeepAR is a built-in algorithm specifically designed for time-series forecasting; XGBoost can also be effective with proper feature engineering. Linear regression without features, BlazingText, and image classification algorithms are unsuitable for time-series forecasting."
  },
  {
    "taskStatement": "2.1",
    "stem": "You want to choose an AWS AI service to add automatic language translation to your application with minimal ML operational overhead. Which service do you select?",
    "correct": "C",
    "difficulty": "EASY",
    "answers": {
      "A": "Train a custom sequence-to-sequence translation model on SageMaker.",
      "B": "Use SageMaker built-in Seq2Seq algorithm for translation tasks.",
      "C": "Use Amazon Translate for scalable managed language translation.",
      "D": "Develop and deploy a transformer model in SageMaker script mode."
    },
    "explanation": "Amazon Translate is a fully managed AWS AI service providing scalable, real-time language translation with minimal operational burden. Custom models require extensive development and maintenance."
  },
  {
    "taskStatement": "2.1",
    "stem": "Your team must train a model to detect defective products in a manufacturing line. The image dataset is moderately sized but labeling is costly. Which approach reduces labeling effort while maintaining accuracy?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Train a convolutional neural network from scratch with full labeling.",
      "B": "Use Amazon SageMaker Ground Truth for active learning-driven labeling and train a SageMaker JumpStart model.",
      "C": "Label all images manually and apply SageMaker built-in linear learner.",
      "D": "Use Amazon Mechanical Turk for labeling without active learning."
    },
    "explanation": "SageMaker Ground Truth's active learning reduces labeling costs by selecting informative samples for annotation. Coupled with JumpStart models, this approach maintains accuracy efficiently. Manual labeling is costly; linear learner on images is suboptimal."
  },
  {
    "taskStatement": "2.1",
    "stem": "How should you select a SageMaker built-in algorithm if the model interpretability is critical for a healthcare prediction use case?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Choose the algorithm with the highest accuracy regardless of interpretability.",
      "B": "Select deep learning models trained via script mode for flexibility.",
      "C": "Pick the foundation model from Amazon Bedrock with no interpretability tools.",
      "D": "Choose algorithms with explainability features such as Linear Learner or XGBoost with SHAP explanations."
    },
    "explanation": "Algorithms like Linear Learner and XGBoost combined with SHAP (SHapley Additive exPlanations) allow interpretability, critical in healthcare for compliance and trust. Deep learning and foundation models often lack transparency."
  },
  {
    "taskStatement": "2.1",
    "stem": "You want to use SageMaker built-in algorithms to classify streaming streaming data from IoT devices where data arrives continuously. Which approach best handles this scenario?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Train a batch model and retrain daily on historical data only.",
      "B": "Deploy a static model without updates to minimize latency.",
      "C": "Implement incremental training with built-in algorithms compatible with streaming data and retraining pipelines.",
      "D": "Use Amazon Kinesis Data Analytics alone to perform classification."
    },
    "explanation": "Incremental training and retraining pipelines support continuous data learning and model updates essential for streaming data. Static models or batch-only retraining fail to adapt promptly. Kinesis Analytics is not a modeling service."
  },
  {
    "taskStatement": "2.1",
    "stem": "During model selection for a recommendation system, you need to choose between collaborative filtering and content-based approaches in SageMaker. Which is a key factor influencing your choice?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Collaborative filtering is preferred if cold start is a main concern.",
      "B": "Content-based filtering is effective when detailed item metadata are available and user interactions are sparse.",
      "C": "Content-based filtering requires large user-to-user interactions datasets.",
      "D": "Collaborative filtering works best with sparse metadata and no historical interactions."
    },
    "explanation": "Content-based filtering relies heavily on item features and metadata, making it appropriate when user interaction data is limited. Collaborative filtering depends on user-item interactions and may struggle with the cold start problem."
  },
  {
    "taskStatement": "2.1",
    "stem": "A retail business wants to deploy an AWS AI service to categorize product images uploaded by users without building models. Which AWS AI service is most suitable?",
    "correct": "D",
    "difficulty": "EASY",
    "answers": {
      "A": "Train a computer vision model on SageMaker from scratch.",
      "B": "Use SageMaker built-in Image Classification algorithm with custom training.",
      "C": "Use Amazon Rekognition Custom Labels after manual labeling.",
      "D": "Use Amazon Rekognition's pre-trained image moderation and object detection capabilities."
    },
    "explanation": "Amazon Rekognition offers pre-trained capabilities to categorize images without requiring custom training, suitable for minimal development. Custom training or labeling increases complexity and cost."
  },
  {
    "taskStatement": "2.1",
    "stem": "When deciding if to use a SageMaker built-in algorithm or a custom algorithm for text classification, which consideration is critical?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Whether built-in algorithms meet accuracy and customization needs for the specific text domain.",
      "B": "Whether custom algorithms lack monitoring capabilities.",
      "C": "If built-in algorithms support GPU-based training only.",
      "D": "If custom algorithms can be deployed only using batch endpoints."
    },
    "explanation": "The key decision factor is whether built-in algorithms provide sufficient accuracy and customization for the specific use case. Custom algorithms offer flexibility but at added cost and management burden."
  },
  {
    "taskStatement": "2.1",
    "stem": "You want to select a modeling approach using SageMaker JumpStart foundation models to accelerate development of a chatbot in multiple languages. Which deployment method enables the quickest iteration?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Fine-tune and deploy JumpStart foundation models with SageMaker endpoints for real-time inference.",
      "B": "Package the foundation model into containers and deploy on Amazon ECS with manual scaling.",
      "C": "Deploy the model using batch transform jobs periodically for conversational inference.",
      "D": "Use Amazon Polly voice services alone for chatbot logic."
    },
    "explanation": "JumpStart foundation models can be fine-tuned and deployed on SageMaker endpoints allowing real-time inference enabling fast iteration and user interaction for chatbots. Batch transforms are not real-time; ECS requires more setup."
  },
  {
    "taskStatement": "2.1",
    "stem": "For a tabular dataset with class imbalance, which modeling approach using SageMaker built-in algorithms best addresses prediction bias?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Train a deep neural network from scratch on imbalanced data.",
      "B": "Use built-in XGBoost algorithm applying techniques such as balanced class weighting or re-sampling.",
      "C": "Apply clustering to balance classes before supervised training.",
      "D": "Use BlazingText to model tabular data for balanced classification."
    },
    "explanation": "XGBoost with balanced class weighting or re-sampling can effectively handle class imbalance in tabular datasets. Deep neural networks may overfit minority classes without mitigation."
  },
  {
    "taskStatement": "2.1",
    "stem": "Which SageMaker built-in algorithm is optimized for large-scale distributed training on sparse feature datasets such as clickstream data?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "DeepAR probabilistic forecasting algorithm.",
      "B": "Semantic Segmentation for image labeling.",
      "C": "BlazingText in unsupervised mode.",
      "D": "SageMaker Factorization Machines algorithm."
    },
    "explanation": "Factorization Machines model sparse interaction data efficiently and support large-scale distributed training. It's ideal for clickstream and recommendation datasets."
  },
  {
    "taskStatement": "2.1",
    "stem": "You must select an AWS AI service to perform entity recognition in documents containing sensitive personal information. Which solution ensures compliance and minimal custom ML development?",
    "correct": "C",
    "difficulty": "EASY",
    "answers": {
      "A": "Train custom NER models in SageMaker from scratch using labeled data.",
      "B": "Use SageMaker built-in linear learner for entity recognition.",
      "C": "Use Amazon Comprehend Medical or Amazon Comprehend with PII detection features.",
      "D": "Apply Amazon Mechanical Turk for manual annotation with human review only."
    },
    "explanation": "Amazon Comprehend and Comprehend Medical are managed services with built-in NER specialized for PII and PHI, supporting compliance with minimal custom development."
  },
  {
    "taskStatement": "2.1",
    "stem": "An ML engineer wants to select a SageMaker built-in algorithm for regression prediction of real-valued targets on high-dimensional numeric data. Which is most suitable?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "BlazingText supervised mode.",
      "B": "SageMaker Linear Learner configured for regression tasks.",
      "C": "Image Classification algorithm with transfer learning.",
      "D": "SageMaker Object Detection algorithm."
    },
    "explanation": "Linear Learner supports regression efficiently on high-dimensional numeric data. BlazingText and image-based algorithms focus on classification and images, not numeric regression."
  },
  {
    "taskStatement": "2.1",
    "stem": "In a scenario requiring minimal training time with acceptable accuracy for tabular classification, which SageMaker built-in algorithm offers the best trade-off?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "SageMaker Linear Learner with optimized hyperparameters.",
      "B": "Training deep convolutional neural networks from scratch.",
      "C": "Custom transformer models in script mode.",
      "D": "Using SageMaker JumpStart foundation models for tabular data."
    },
    "explanation": "Linear Learner is fast to train on tabular data and can reach acceptable accuracy quickly. Deep CNNs and transformers are slower and overkill for tabular data."
  },
  {
    "taskStatement": "2.1",
    "stem": "Which metric should influence your model or algorithm choice in SageMaker when the cost of false negatives is substantially higher than false positives?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Overall accuracy without class weighting.",
      "B": "Mean squared error (MSE).",
      "C": "Recall (sensitivity) prioritizing detection of positive cases.",
      "D": "Precision (positive predictive value)."
    },
    "explanation": "When false negatives carry a higher cost, maximizing recall reduces missed positive cases, guiding model and algorithm selection."
  },
  {
    "taskStatement": "2.1",
    "stem": "An ML engineer considers Amazon Bedrock foundation models for a recommendation system. What critical factor should influence this decision?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Foundation models require expansive labeled data for training from scratch.",
      "B": "Foundation models can be fine-tuned or accessed via APIs for fast development but may incur higher inference costs.",
      "C": "Bedrock services are only for image recognition tasks.",
      "D": "Foundation models do not support integration with SageMaker pipelines."
    },
    "explanation": "Amazon Bedrock foundation models accelerate application building via APIs, with fine-tuning options, but inference costs and API latencies can be higher; this trade-off impacts deployment decisions."
  },
  {
    "taskStatement": "2.1",
    "stem": "When solving a multi-label image classification task with imbalanced classes, which SageMaker built-in algorithm should you consider?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "SageMaker Linear Learner for binary classification.",
      "B": "XGBoost multi-class classification in one-vs-all mode.",
      "C": "SageMaker Object Detection algorithm with multi-label support.",
      "D": "BlazingText supervised mode."
    },
    "explanation": "SageMaker Object Detection supports multi-label classification in images and can be adapted for imbalanced data, unlike linear models or text-specific algorithms."
  },
  {
    "taskStatement": "2.1",
    "stem": "You plan to use SageMaker built-in algorithms to predict equipment failure with sensor data containing both time-series and categorical features. What is the best approach?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use BlazingText to encode categorical and sensor data.",
      "B": "Train XGBoost only on raw sensor data ignoring time-series dependencies.",
      "C": "Apply object detection algorithm to sensor logs.",
      "D": "Engineer features from time-series data, encode categorical variables, then train XGBoost or Linear Learner."
    },
    "explanation": "Feature engineering to capture time-series patterns and categorical encodings with versatile algorithms like XGBoost or Linear Learner is typical best practice, as built-in algorithms do not directly model sequences."
  },
  {
    "taskStatement": "2.1",
    "stem": "Which SageMaker modeling approach facilitates version control, auditability, and governance across ML lifecycle stages?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use SageMaker Model Registry to manage model versions and metadata systematically.",
      "B": "Maintain versions manually in separate S3 buckets without registry.",
      "C": "Deploy models directly without version tracking.",
      "D": "Use external Git repositories for model binaries only."
    },
    "explanation": "SageMaker Model Registry is designed for versioning, auditing, and governance, offering integrated model lifecycle management."
  },
  {
    "taskStatement": "2.1",
    "stem": "For a classification problem with a requirement to generate confidence intervals on predictions, which SageMaker built-in algorithm or approach is best?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "SageMaker Linear Learner without uncertainty estimation.",
      "B": "XGBoost standard classifier with deterministic outputs.",
      "C": "BlazingText supervised mode.",
      "D": "Use SageMaker built-in DeepAR probabilistic forecasting model or Bayesian methods for uncertainty estimates."
    },
    "explanation": "DeepAR supports probabilistic forecasting providing uncertainty estimates; standard classifiers like Linear Learner or XGBoost provide point predictions without confidence intervals."
  },
  {
    "taskStatement": "2.1",
    "stem": "You want to accelerate training for a model handling large image datasets using SageMaker built-in algorithms. Which strategy optimizes training time?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Train on a single CPU instance with full dataset.",
      "B": "Use SageMaker script mode with custom PyTorch model only.",
      "C": "Use SageMaker built-in image classification algorithm with multi-GPU distributed training.",
      "D": "Use BlazingText for image data preprocessing."
    },
    "explanation": "The SageMaker built-in image classification algorithm supports multi-GPU distributed training, accelerating training on large image datasets."
  },
  {
    "taskStatement": "2.1",
    "stem": "Which of the following considerations is fundamental when deciding between deploying a SageMaker built-in algorithm versus Amazon Bedrock foundation models?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Built-in algorithms have higher inference latencies by design.",
      "B": "Bedrock foundation models provide pre-trained generalizable capabilities with less custom training.",
      "C": "Built-in algorithms are only for image data.",
      "D": "Bedrock models do not support NLP tasks."
    },
    "explanation": "Bedrock foundation models come pre-trained with broad capabilities, reducing training efforts for many use cases, contrasted with built-in algorithms requiring training on prepared data."
  },
  {
    "taskStatement": "2.1",
    "stem": "You are designing an ML model for a medical imaging classification where interpretability is vital, and dataset size is limited. Which modeling approach aligns best?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use SageMaker built-in linear algorithms with handcrafted features and feature importance analysis.",
      "B": "Train deep CNN models from scratch on raw images.",
      "C": "Use black-box foundation models without explanation tools.",
      "D": "Apply unsupervised clustering to detect anomalies."
    },
    "explanation": "Linear models with engineered features provide interpretability; deep CNNs require large datasets and are less explainable, unsuitable with limited data and explainability needs."
  },
  {
    "taskStatement": "2.2",
    "stem": "An ML engineer is training a deep learning model using SageMaker script mode with PyTorch. After several epochs, the training loss plateaus and the model shows signs of overfitting on the validation data. Which strategies would be MOST effective to reduce overfitting and improve generalization?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Increase the learning rate to speed up training convergence.",
      "B": "Remove dropout layers to allow full network capacity.",
      "C": "Apply regularization techniques like dropout and weight decay, and consider early stopping.",
      "D": "Increase the batch size significantly to stabilize gradients."
    },
    "explanation": "Overfitting occurs when a model learns noise in training data. Regularization methods such as dropout and weight decay help prevent this by reducing model complexity. Early stopping halts training before overfitting intensifies. Increasing learning rate or batch size alone may not address overfitting and can sometimes worsen it."
  },
  {
    "taskStatement": "2.2",
    "stem": "During hyperparameter tuning of a SageMaker training job, an ML engineer wants to efficiently explore a high-dimensional search space and minimize the total training time. Which hyperparameter tuning strategy should they choose?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Grid search with exhaustive combinations of parameters.",
      "B": "Bayesian optimization to intelligently select promising hyperparameters.",
      "C": "Random search with uniformly distributed sampling.",
      "D": "Manual tuning based on trial-and-error experiments."
    },
    "explanation": "Bayesian optimization is an advanced hyperparameter tuning method that models the objective function and selects hyperparameters based on expected improvement, making it more efficient than grid or random search, especially in high-dimensional spaces."
  },
  {
    "taskStatement": "2.2",
    "stem": "While training a large NLP model using SageMaker's built-in algorithms, the training times are exceeding expected limits. Which method can MOST effectively reduce training time without sacrificing model accuracy?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Reduce the size of the training dataset to speed up training.",
      "B": "Use only CPU instances without GPU acceleration to lower costs.",
      "C": "Increase the batch size beyond the recommended limits to process more data per step.",
      "D": "Enable distributed training across multiple GPU instances and use early stopping."
    },
    "explanation": "Distributed training splits the workload across multiple GPUs, reducing training time. Early stopping halts training when no improvement is observed, avoiding redundant epochs. Simply reducing data or disabling GPUs can hurt model quality or increase time."
  },
  {
    "taskStatement": "2.2",
    "stem": "An ML engineer wants to fine-tune a foundation model from SageMaker JumpStart with a custom dataset. What are the BEST practices to achieve efficient fine-tuning and maintain model performance?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use transfer learning by freezing early layers and only training higher layers, and prepare data to match expected input formats.",
      "B": "Train all model layers from scratch without initializing pretrained weights.",
      "C": "Use an unrelated dataset to increase model diversity during fine-tuning.",
      "D": "Increase learning rate dramatically to speed fine-tuning convergence."
    },
    "explanation": "Freezing early layers preserves learned features and reduces overfitting during fine-tuning. Preparing data to match expected formats avoids training errors. Training all layers from scratch wastes resources, unrelated data reduces effectiveness, and high learning rates can destabilize training."
  },
  {
    "taskStatement": "2.2",
    "stem": "SageMaker automatic model tuning (AMT) is used for hyperparameter optimization. Which factors MOST affect the efficiency and success of an AMT job?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Number of epochs and training batch size only.",
      "B": "Dataset size and ML algorithm choice only.",
      "C": "Choice of hyperparameters to tune, search space ranges, and objective metric definition.",
      "D": "Compute instance type and network bandwidth."
    },
    "explanation": "AMT efficiency depends on tuning relevant hyperparameters within meaningful ranges and accurately defining the objective metric. While dataset and compute resources influence training, the tuning process's design is critical for success."
  },
  {
    "taskStatement": "2.2",
    "stem": "An ML engineer notices the model trained in SageMaker is suffering from catastrophic forgetting during incremental learning. What techniques can help mitigate this issue?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use higher learning rates and larger batch sizes.",
      "B": "Apply regularization strategies such as elastic weight consolidation and rehearsal methods.",
      "C": "Train from scratch for each new dataset without retaining old weights.",
      "D": "Reduce dataset size to focus on new tasks only."
    },
    "explanation": "Catastrophic forgetting happens when a model loses prior knowledge while learning new tasks. Regularization methods like elastic weight consolidation preserve important weights, and rehearsal methods retrain on prior data to retain knowledge. Retraining from scratch is resource-intensive, and reducing data ignores prior information."
  },
  {
    "taskStatement": "2.2",
    "stem": "When combining multiple models to improve performance, which ensembling techniques can an ML engineer apply in SageMaker training pipelines?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Bagging, boosting, stacking, and blending ensembles.",
      "B": "Only boosting methods such as AdaBoost and Gradient Boosting.",
      "C": "Training multiple models on the same data and choosing the single best model.",
      "D": "Merging models by averaging weights without retraining."
    },
    "explanation": "Bagging reduces variance, boosting reduces bias, stacking and blending combine different model outputs to improve accuracy. Simply picking one model or averaging weights without retraining may not yield gains."
  },
  {
    "taskStatement": "2.2",
    "stem": "An ML engineer must reduce the size of a large trained model to deploy it on edge devices with limited memory. What are BEST approaches to reduce model size to meet constraints?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Increase training epochs and model depth for better accuracy.",
      "B": "Convert datatype from float32 to float64 to improve precision.",
      "C": "Add more layers to expand capacity and prune later if needed.",
      "D": "Use model quantization, pruning, and update feature selection to reduce parameters and storage."
    },
    "explanation": "Model quantization reduces numeric precision to lower size, pruning removes non-essential weights, and updating feature selection removes unused inputs, all effectively shrinking model size without retraining from scratch. Increasing model depth or precision increases size."
  },
  {
    "taskStatement": "2.2",
    "stem": "In SageMaker, how can an ML engineer integrate models built outside the SageMaker environment into their training and deployment workflows?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Retrain the model from scratch using SageMaker built-in algorithms.",
      "B": "Use SageMaker containers or BYOC (Bring Your Own Container) to deploy the external model.",
      "C": "Convert the model to a different framework unsupported by SageMaker.",
      "D": "Export the model only as a Pickle file and deploy it directly on AWS Lambda."
    },
    "explanation": "SageMaker supports external models via Bring Your Own Container, allowing custom environments for training and deployment. Retraining may be unnecessary. Unsupported frameworks or direct Lambda deployment often lack scalability or proper infrastructure."
  },
  {
    "taskStatement": "2.2",
    "stem": "Which SageMaker feature helps manage and control multiple versions of ML models during iterative training and tuning?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "SageMaker Data Wrangler",
      "B": "SageMaker Ground Truth",
      "C": "SageMaker Model Registry",
      "D": "SageMaker Pipelines"
    },
    "explanation": "SageMaker Model Registry provides version control and governance for models, enabling stages like testing, approval, and deployment, facilitating collaboration and repeatability."
  },
  {
    "taskStatement": "2.2",
    "stem": "When performing hyperparameter tuning with SageMaker's automatic model tuning, what metric should be chosen and why?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Training loss, because it reflects model fitting speed.",
      "B": "A relevant validation metric (e.g., accuracy, F1 score) to optimize generalization.",
      "C": "Resource utilization metrics to reduce cost.",
      "D": "Batch size to increase throughput."
    },
    "explanation": "Optimizing validation metrics prevents overfitting and ensures model generalization to new data, which is the primary goal in hyperparameter tuning."
  },
  {
    "taskStatement": "2.2",
    "stem": "An ML engineer uses SageMaker script mode to train an image classification model but sees unstable training and divergence after several epochs. Which adjustments could MOST improve training stability?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Reduce the learning rate and apply gradient clipping.",
      "B": "Increase batch size indefinitely without changing other parameters.",
      "C": "Remove batch normalization layers to simplify the model.",
      "D": "Disable regularization to allow the model to fit better."
    },
    "explanation": "Reducing the learning rate helps more stable convergence, and gradient clipping prevents exploding gradients. Simply increasing batch size or removing batch normalization can harm convergence."
  },
  {
    "taskStatement": "2.2",
    "stem": "How does the choice of batch size influence training time and model convergence in SageMaker training jobs?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Larger batch sizes always speed up convergence and reduce training time.",
      "B": "Smaller batch sizes cause training to take less time but with lower accuracy.",
      "C": "Batch size has no real effect on training dynamics or time.",
      "D": "Larger batch sizes improve training throughput but may require adjusting learning rates to maintain convergence."
    },
    "explanation": "Larger batch sizes enable more parallelism and throughput but can require tuning learning rates and may cause poorer generalization if too large. Smaller batches provide noisier gradients, potentially better generalization but slower throughput."
  },
  {
    "taskStatement": "2.2",
    "stem": "During model training, an ML engineer wants to prevent overfitting by stopping training at the optimal time automatically. Which SageMaker capability should be employed?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "Tune instance types to improve training speed.",
      "B": "Enable early stopping with proper training job termination criteria.",
      "C": "Use batch normalization layers only.",
      "D": "Increase the training dataset size artificially."
    },
    "explanation": "Early stopping monitors validation metrics and stops training when no improvement is detected, preventing overfitting and unnecessary compute."
  },
  {
    "taskStatement": "2.2",
    "stem": "An ML engineer seeks to combine multiple trained models to enhance predictive accuracy. What should be considered when selecting models for stacking ensemble methods?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Choose models with the same architecture to simplify blending.",
      "B": "Select only the top-performing model to avoid complexity.",
      "C": "Include diverse models with complementary errors to maximize ensemble gains.",
      "D": "Select models trained on identical random seeds and hyperparameters."
    },
    "explanation": "Stacking benefits from combining models that make different errors, improving overall accuracy by exploiting diversity."
  },
  {
    "taskStatement": "2.2",
    "stem": "Which SageMaker feature provides integration for automated hyperparameter optimization that supports exploration of complex search spaces during model training?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "SageMaker Automatic Model Tuning (AMT)",
      "B": "SageMaker Ground Truth",
      "C": "SageMaker Model Monitor",
      "D": "SageMaker Data Wrangler"
    },
    "explanation": "SageMaker AMT automates hyperparameter tuning by searching through defined parameter ranges to optimize model performance."
  },
  {
    "taskStatement": "2.2",
    "stem": "An ML engineer is training a tree-based model in SageMaker. To reduce overfitting, which hyperparameters are MOST important to tune?",
    "correct": "D",
    "difficulty": "EASY",
    "answers": {
      "A": "Number of epochs and batch size.",
      "B": "Learning rate and activation functions.",
      "C": "Number of layers and dropout rate.",
      "D": "Number of trees, maximum tree depth, and minimum samples per leaf."
    },
    "explanation": "Tree-based models' complexity and overfitting are controlled by number of trees, depth, and leaf size parameters, which balance bias and variance."
  },
  {
    "taskStatement": "2.2",
    "stem": "When fine-tuning a pretrained model on an imbalanced dataset, which practices help prevent the model from being biased toward majority classes?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use the original dataset without modification to preserve features.",
      "B": "Increase the learning rate drastically during fine-tuning.",
      "C": "Apply techniques such as resampling, class weighting, or synthetic data generation.",
      "D": "Exclude minority class samples from training to simplify optimization."
    },
    "explanation": "Addressing data imbalance with resampling, weighting loss functions, or synthetic samples helps models learn minority classes better and avoid bias."
  },
  {
    "taskStatement": "2.2",
    "stem": "An ML engineer needs to debug why a model fails to converge during training in SageMaker. Which tools and approaches are BEST suited to diagnose convergence issues?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use SageMaker Ground Truth to relabel data.",
      "B": "Leverage SageMaker Model Debugger to analyze training traces and tensor metrics.",
      "C": "Apply SageMaker Model Monitor on the deployed endpoint.",
      "D": "Tune hyperparameters with AMT blindly to find better settings."
    },
    "explanation": "SageMaker Model Debugger provides insights on tensor values, gradients, and identifies training pathologies causing convergence problems."
  },
  {
    "taskStatement": "2.2",
    "stem": "When training models using SageMaker script mode with TensorFlow, which best practice ensures reproducibility across training jobs?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use dynamic hyperparameters in the training script.",
      "B": "Store only final trained model artifacts.",
      "C": "Set random seeds explicitly and log environment versions in the training job.",
      "D": "Run training on diverse instance types for variability."
    },
    "explanation": "Setting random seeds, and logging package and environment versions ensure experiments can be repeated and results validated."
  },
  {
    "taskStatement": "2.2",
    "stem": "How does regularization by weight decay impact a neural network's training and final model?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "It adds a penalty for large weights to reduce overfitting and encourage simpler models.",
      "B": "It increases model complexity by adding more layers.",
      "C": "It speeds up training by increasing gradients.",
      "D": "It decreases bias but increases variance significantly."
    },
    "explanation": "Weight decay (L2 regularization) penalizes large weight magnitudes, preventing complex models and reducing overfitting."
  },
  {
    "taskStatement": "2.2",
    "stem": "An ML engineer wants to automate end-to-end model training, tuning, and deployment using SageMaker Pipelines. How can hyperparameter tuning be integrated effectively?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Manually run tuning jobs outside the pipeline and upload the best model.",
      "B": "Only use predefined models without tuning for automation simplicity.",
      "C": "Tune hyperparameters after deployment by monitoring endpoint performance.",
      "D": "Include SageMaker Automatic Model Tuning as a pipeline step with conditional logic for best model registration."
    },
    "explanation": "SageMaker Pipelines supports incorporating AMT jobs, enabling automated tuning and registering best model versions for deployment."
  },
  {
    "taskStatement": "2.2",
    "stem": "While training a model with SageMaker script mode, the ML engineer observes overfitting despite using data augmentation. What other methods should be considered to combat overfitting?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Increase the model complexity to fit the training data better.",
      "B": "Use dropout layers, early stopping, and L1/L2 regularization.",
      "C": "Reduce the training dataset size to remove noisy samples.",
      "D": "Disable all regularization to avoid underfitting."
    },
    "explanation": "Dropout, early stopping, and regularization are effective techniques to prevent overfitting and improve model generalization."
  },
  {
    "taskStatement": "2.2",
    "stem": "What is a consequence of using too large a hyperparameter search space for automatic hyperparameter tuning in SageMaker?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Faster convergence to optimal hyperparameters.",
      "B": "Guaranteed discovery of the best hyperparameters.",
      "C": "Longer tuning times and difficulty finding optimal values.",
      "D": "It reduces training cost significantly."
    },
    "explanation": "A larger search space increases the number of combinations to explore, potentially prolonging tuning and making optimization harder without sufficient budget."
  },
  {
    "taskStatement": "2.2",
    "stem": "How can the learning rate be adapted during training to improve convergence and avoid local minima?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Implement learning rate schedules such as cosine decay or step decay, or use adaptive optimizers like Adam.",
      "B": "Keep learning rate fixed throughout training.",
      "C": "Increase learning rate exponentially every epoch.",
      "D": "Use random learning rates at each batch."
    },
    "explanation": "Learning rate schedules and adaptive optimizers help models converge smoothly to good minima by adjusting step sizes during training."
  },
  {
    "taskStatement": "2.2",
    "stem": "An ML engineer observes that training accuracy improves while validation accuracy stagnates or decreases over epochs. What does this indicate and how can it be mitigated?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Indicates underfitting; increase model capacity.",
      "B": "Indicates data leakage; clean the dataset.",
      "C": "Indicates perfect fit; training should stop immediately.",
      "D": "Indicates overfitting; apply regularization and early stopping."
    },
    "explanation": "Divergence between training and validation accuracy means overfitting, which can be mitigated by regularization, dropout, and early stopping."
  },
  {
    "taskStatement": "2.3",
    "stem": "An ML engineer is evaluating a binary classification model using SageMaker Clarify. The confusion matrix indicates a high number of false positives compared to false negatives. Which metric should the engineer prioritize to improve model performance for a use case where false positives incur high costs?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Recall",
      "B": "Precision",
      "C": "Accuracy",
      "D": "Root Mean Square Error (RMSE)"
    },
    "explanation": "Precision measures the ratio of true positives to all positive predictions, so improving precision reduces false positives, which is critical when false positives are costly."
  },
  {
    "taskStatement": "2.3",
    "stem": "During model evaluation, an ML engineer notices that the training set accuracy is very high, but the test set accuracy is low. Which technique is most appropriate to address this issue when retraining the model?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Increase model complexity",
      "B": "Reduce the size of the training dataset",
      "C": "Disable early stopping",
      "D": "Apply regularization methods such as L1 or L2"
    },
    "explanation": "High training accuracy with low test accuracy indicates overfitting, and regularization can prevent overfitting by penalizing complex models."
  },
  {
    "taskStatement": "2.3",
    "stem": "You are tasked with establishing an experiment in SageMaker to compare a shadow variant model against the production variant. Which metric best enables reliable comparison of the two variant's performance under live traffic conditions?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Root Mean Square Error (RMSE) on training data",
      "B": "Training loss",
      "C": "Online A/B testing metrics such as precision and recall on live input",
      "D": "Validation accuracy from the latest training job"
    },
    "explanation": "Online A/B testing with live traffic metric evaluation accurately compares shadow and production model behavior under realistic conditions."
  },
  {
    "taskStatement": "2.3",
    "stem": "An ML engineer wants to detect if a deployed model\u2019s predictions are degrading over time due to changes in input data distribution. Which SageMaker feature should be used to detect this issue?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "SageMaker Model Monitor to detect data drift",
      "B": "SageMaker Debugger for model weight analysis",
      "C": "SageMaker Endpoint Auto Scaling",
      "D": "SageMaker Neo for edge optimization"
    },
    "explanation": "SageMaker Model Monitor helps detect data drift by monitoring input data distributions to deployed models."
  },
  {
    "taskStatement": "2.3",
    "stem": "Which metric combination is best to use for evaluating the performance of a multi-class classification model to ensure both balance and class separation?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Accuracy and RMSE",
      "B": "F1 score and Precision",
      "C": "Confusion matrix and Area Under the ROC Curve (AUC)",
      "D": "Recall and training loss"
    },
    "explanation": "The confusion matrix shows detailed misclassification patterns while AUC evaluates class separability."
  },
  {
    "taskStatement": "2.3",
    "stem": "An ML model is suspected to have convergence issues during training in SageMaker. Which SageMaker feature provides detailed insight into training iterations and metrics to detect this?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "SageMaker Model Monitor",
      "B": "SageMaker Clarify",
      "C": "SageMaker JumpStart",
      "D": "SageMaker Debugger"
    },
    "explanation": "SageMaker Debugger profiles training jobs and captures metrics such as gradients and loss to detect convergence problems."
  },
  {
    "taskStatement": "2.3",
    "stem": "When using SageMaker Clarify to assess model bias, which pre-training metric helps identify imbalance in label distribution for classification tasks?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Recall",
      "B": "F1 score",
      "C": "Area Under the ROC Curve (AUC)",
      "D": "Class Imbalance (CI)"
    },
    "explanation": "Class Imbalance (CI) quantifies the distribution imbalance of labels before training, which can lead to biased models."
  },
  {
    "taskStatement": "2.3",
    "stem": "Which techniques can an ML engineer use to reduce prediction bias caused by imbalanced datasets before model training?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Increase batch size during training",
      "B": "Synthetic data generation and resampling",
      "C": "Use a bigger neural network",
      "D": "Reduce training epochs"
    },
    "explanation": "Synthetic data generation and resampling are common pre-training techniques to mitigate imbalance-related bias."
  },
  {
    "taskStatement": "2.3",
    "stem": "In SageMaker, how can an engineer perform reproducible model evaluation experiments including training and hyperparameter variations?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Manually retrain and track experiments using Jupyter notebooks",
      "B": "Use SageMaker Model Monitor",
      "C": "Use SageMaker Experiments to track runs, parameters, metrics, and results",
      "D": "Store models in Amazon S3 only"
    },
    "explanation": "SageMaker Experiments tracks metadata and artifacts for reproducible ML experiments."
  },
  {
    "taskStatement": "2.3",
    "stem": "A model has high recall but low precision. Which statement best describes this situation?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "The model misses many positive cases",
      "B": "The model detects most positives but has many false positives",
      "C": "The model is perfectly balanced",
      "D": "The model is underfitting"
    },
    "explanation": "High recall means most positives found; low precision means many false positives among predictions."
  },
  {
    "taskStatement": "2.3",
    "stem": "Which SageMaker capability allows debugging model convergence by inspecting tensors and loss trends during training?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "SageMaker Clarify",
      "B": "SageMaker Model Monitor",
      "C": "SageMaker JumpStart",
      "D": "SageMaker Debugger"
    },
    "explanation": "SageMaker Debugger provides in-depth debugging including tensor capture during training for convergence analysis."
  },
  {
    "taskStatement": "2.3",
    "stem": "How can an ML engineer ensure model fairness by interpreting the model outputs and feature importance after training?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use SageMaker Clarify Explainability features",
      "B": "Use SageMaker Model Monitor",
      "C": "Use Amazon CloudWatch Logs",
      "D": "Use SageMaker Pipelines"
    },
    "explanation": "SageMaker Clarify's Explainability provides tools to interpret model predictions and feature importance for fairness."
  },
  {
    "taskStatement": "2.3",
    "stem": "Which hyperparameter optimization method balances exploration and exploitation efficiently and can be integrated with SageMaker automatic model tuning?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Grid search",
      "B": "Random search",
      "C": "Bayesian optimization",
      "D": "Manual tuning"
    },
    "explanation": "Bayesian optimization uses a probabilistic model to choose promising hyperparameters balancing exploration and exploitation."
  },
  {
    "taskStatement": "2.3",
    "stem": "An ML engineer wants to combine multiple models to improve prediction performance. Which ensemble method is best when training independent models and combining results via weighted voting?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Stacking",
      "B": "Bagging",
      "C": "Boosting",
      "D": "Voting ensemble"
    },
    "explanation": "Voting ensemble combines predictions from independent models based on majority or weighted votes."
  },
  {
    "taskStatement": "2.3",
    "stem": "What technique can prevent catastrophic forgetting when incrementally training a neural network with new data batches?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Increasing learning rate",
      "B": "Regularization methods like dropout and weight decay",
      "C": "Reducing network depth",
      "D": "Using only batch normalization"
    },
    "explanation": "Regularization techniques help maintain past knowledge while adapting to new data, mitigating catastrophic forgetting."
  },
  {
    "taskStatement": "2.3",
    "stem": "When analyzing model performance, which metric is least sensitive to dataset imbalance and more informative for unbalanced classification problems?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Accuracy",
      "B": "F1 score",
      "C": "Precision",
      "D": "Recall"
    },
    "explanation": "F1 score balances precision and recall, providing a better metric for imbalanced datasets than accuracy alone."
  },
  {
    "taskStatement": "2.3",
    "stem": "How does early stopping reduce training time and improve model generalization?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "By increasing epoch count",
      "B": "By disabling model checkpoints",
      "C": "By halting training when validation loss stops improving",
      "D": "By randomizing data shuffling"
    },
    "explanation": "Early stopping halts training once validation performance plateaus or degrades, preventing overfitting and saving time."
  },
  {
    "taskStatement": "2.3",
    "stem": "Which strategy allows combining base learners sequentially where each new model corrects errors from the previous ones?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Bagging",
      "B": "Voting ensemble",
      "C": "Boosting",
      "D": "Random forest"
    },
    "explanation": "Boosting trains models sequentially focusing on previous errors to improve accuracy."
  },
  {
    "taskStatement": "2.3",
    "stem": "Which approach is most effective to reduce model size for deployment on resource-constrained devices without significant accuracy loss?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Model pruning and quantization",
      "B": "Increasing model depth",
      "C": "Using early stopping during training",
      "D": "Increasing batch size during training"
    },
    "explanation": "Pruning removes unnecessary weights; quantization reduces precision, both shrink model size while preserving performance."
  },
  {
    "taskStatement": "2.3",
    "stem": "Which SageMaker component is used to manage different versions of models to enable repeatability and auditability?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "SageMaker Experiments",
      "B": "SageMaker Model Registry",
      "C": "SageMaker Pipelines",
      "D": "SageMaker Debugger"
    },
    "explanation": "Model Registry tracks model versions with metadata for deployment and auditing."
  },
  {
    "taskStatement": "2.3",
    "stem": "Which metric is suitable for evaluating a regression model\u2019s predictive accuracy on a test set?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Accuracy",
      "B": "F1 Score",
      "C": "Recall",
      "D": "Root Mean Square Error (RMSE)"
    },
    "explanation": "RMSE quantifies average magnitude of prediction errors for regression."
  },
  {
    "taskStatement": "2.3",
    "stem": "An ML engineer observes that the Area Under the ROC Curve (AUC) of the model increased, but precision decreased. What can be inferred?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "The tradeoff suggests increased true positive rate but more false positives",
      "B": "Model is improved overall without tradeoff",
      "C": "Model is underfitting",
      "D": "Model has perfect recall and precision"
    },
    "explanation": "Increasing AUC implies better discrimination; lower precision implies more false positives, indicating a tradeoff."
  },
  {
    "taskStatement": "2.3",
    "stem": "How can an ML engineer use the confusion matrix to identify model bias against a specific class?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Look at overall accuracy",
      "B": "Examine overall recall",
      "C": "Compare false negatives and false positives per class",
      "D": "Check model training loss"
    },
    "explanation": "A confusion matrix breaks down errors by class, revealing if some classes are systematically misclassified."
  },
  {
    "taskStatement": "2.3",
    "stem": "Which method can help mitigate selection bias in training data when creating an ML dataset?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use only data from the most recent period",
      "B": "Resample to create a representative distribution",
      "C": "Ignore missing values",
      "D": "Use synthetic features"
    },
    "explanation": "Resampling techniques help correct selection bias by balancing dataset representation."
  },
  {
    "taskStatement": "2.3",
    "stem": "After training a model externally, how can an engineer integrate it into SageMaker for inference and monitoring?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Retrain model only within SageMaker",
      "B": "Use SageMaker JumpStart only",
      "C": "Deploy model without registration",
      "D": "Use SageMaker Model Registry and custom containers for deployment"
    },
    "explanation": "The Model Registry supports managing external models, which can then be deployed with SageMaker endpoints."
  },
  {
    "taskStatement": "2.3",
    "stem": "What SageMaker feature facilitates performance baselining to track model improvements across iterations?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "SageMaker Experiments for metrics tracking",
      "B": "SageMaker Model Monitor for data drift",
      "C": "SageMaker Clarify for bias detection",
      "D": "SageMaker Debugger for training profiling"
    },
    "explanation": "SageMaker Experiments records metrics to establish performance baselines and compare runs."
  },
  {
    "taskStatement": "2.3",
    "stem": "Which SageMaker metric can help identify model overfitting during training?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "High training loss and high validation loss",
      "B": "Low training loss and high validation loss",
      "C": "Low validation loss and low training loss",
      "D": "High training loss and low validation loss"
    },
    "explanation": "Overfitting occurs when training error is low but validation error is high."
  },
  {
    "taskStatement": "2.3",
    "stem": "An ML engineer wants to interpret feature impact on a model trained with XGBoost in SageMaker. Which tool provides SHAP values for this purpose?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "SageMaker Model Monitor",
      "B": "SageMaker Debugger",
      "C": "SageMaker Clarify Explainability",
      "D": "SageMaker JumpStart"
    },
    "explanation": "SageMaker Clarify supports SHAP values to interpret feature contributions on models like XGBoost."
  },
  {
    "taskStatement": "2.3",
    "stem": "Which approach describes the proper use of a shadow variant model for gaining insights without impacting production?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy shadow as the primary model",
      "B": "Use shadow for training only",
      "C": "Redirect 100% traffic to shadow model",
      "D": "Route a subset of traffic to shadow model and compare results without affecting user responses"
    },
    "explanation": "Shadow testing enables evaluation of new models with live data without affecting production responses."
  },
  {
    "taskStatement": "2.3",
    "stem": "What key evaluation technique helps determine whether retraining a model is necessary due to concept drift?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Monitor training loss during initial training",
      "B": "Track degradation in performance metrics on recent data",
      "C": "Use hyperparameter tuning",
      "D": "Increase training dataset size"
    },
    "explanation": "Consistent drops in performance on recent data indicate concept drift requiring model retraining."
  },
  {
    "taskStatement": "3.1",
    "stem": "An ML engineer needs to deploy a model requiring real-time inference with millisecond latency and unpredictable traffic spikes. Which AWS deployment infrastructure best balances cost efficiency and scalability for this use case?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy the model on a fixed number of Amazon EC2 GPU instances behind an Application Load Balancer.",
      "B": "Use a SageMaker serverless endpoint configured with on-demand scaling to manage traffic variability.",
      "C": "Deploy as a batch transform job triggered periodically to handle inference requests.",
      "D": "Host the model on AWS Lambda with provisioned concurrency to ensure consistent latency."
    },
    "explanation": "For unpredictable traffic with real-time inference needs, SageMaker serverless endpoints provide automatic scaling from zero to handle bursts efficiently without fixed costs. EC2 instances incur fixed costs even when idle. Batch transform is unsuitable for real-time inference. Lambda with provisioned concurrency incurs fixed cost and may not scale cost-effectively for highly variable traffic."
  },
  {
    "taskStatement": "3.1",
    "stem": "You must deploy multiple ML models as endpoints sharing resources to optimize cost without sacrificing isolated model performance. Which SageMaker deployment architecture supports this?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Create separate real-time multi-container endpoints for each model with dedicated resources.",
      "B": "Deploy all models in a single container on a multi-model endpoint configured with exclusive concurrency.",
      "C": "Use SageMaker multi-model endpoints to host multiple models loaded on-demand in a shared container.",
      "D": "Deploy batch transform jobs for each model using shared Amazon S3 input and output locations."
    },
    "explanation": "SageMaker multi-model endpoints are designed to host multiple models on a single endpoint dynamically loading models on-demand, reducing costs and resource use. Multi-container endpoints isolate models per container, which is costlier. Batch transform is for offline batch inference and does not apply here."
  },
  {
    "taskStatement": "3.1",
    "stem": "A trained SageMaker model requires deployment for asynchronous inference with high throughput but without strict latency requirements. Which deployment option best fits?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy a real-time SageMaker endpoint with multiple instance types for scalability.",
      "B": "Use SageMaker batch transform job to perform inference in batches.",
      "C": "Deploy the model on Amazon ECS with an API Gateway for asynchronous processing.",
      "D": "Configure a SageMaker asynchronous inference endpoint to handle high-throughput requests."
    },
    "explanation": "SageMaker asynchronous inference endpoints are designed for workloads requiring high throughput and asynchronous processing without strict latency, supporting buffering and scaling. Real-time endpoints provide lower latency but can be costly at high throughput. Batch transform is offline, and ECS plus API Gateway adds unnecessary complexity."
  },
  {
    "taskStatement": "3.1",
    "stem": "You need to deploy a large NLP model to edge devices with constrained compute and memory while preserving accuracy. Which AWS service and strategy is most suitable?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use Amazon SageMaker Neo to compile and optimize the model for the target edge platform.",
      "B": "Deploy the original model on AWS Lambda@Edge with provisioned concurrency.",
      "C": "Implement the model as a SageMaker real-time endpoint and stream results to devices.",
      "D": "Convert the model to TensorFlow Lite format and deploy using AWS IoT Greengrass."
    },
    "explanation": "SageMaker Neo compiles and optimizes models to run efficiently on various edge devices while preserving accuracy. Lambda@Edge and SageMaker endpoints do not run directly on edge devices. TensorFlow Lite requires manual conversion and may not integrate as seamlessly with AWS services."
  },
  {
    "taskStatement": "3.1",
    "stem": "Your architecture requires deployment of a model with versioning and zero downtime updates. Which deployment method ensures seamless rollbacks and blue/green deployments?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use SageMaker model registry with endpoint variants and traffic shifting capabilities.",
      "B": "Deploy new models on separate EC2 instances and redirect traffic via Route 53 weighted records.",
      "C": "Replace the model in a single SageMaker endpoint without traffic shifting.",
      "D": "Use AWS Lambda with alias traffic shifting for deployment."
    },
    "explanation": "SageMaker model registry supports versioning and deployment with endpoint variants allowing blue/green deployments with traffic shifting, enabling zero downtime and easy rollback. Replacing models without traffic shifting causes downtime. EC2 with Route 53 is more manual and complex. Lambda alias shifting is for Lambda functions, not SageMaker models."
  },
  {
    "taskStatement": "3.1",
    "stem": "Which compute resource specification is most critical when deploying a computer vision model in SageMaker with high input image resolution requiring GPU acceleration?",
    "correct": "D",
    "difficulty": "HARD",
    "answers": {
      "A": "Prioritize CPU count over GPU capabilities to maximize parallel data preprocessing.",
      "B": "Use general-purpose CPU instances to minimize costs at the expense of speed.",
      "C": "Select memory-optimized CPU instances for loading large models into RAM.",
      "D": "Choose GPU-based instances with sufficient VRAM to handle high-resolution image processing."
    },
    "explanation": "GPU instances with adequate VRAM are essential to efficiently process and infer high-resolution images in computer vision models. CPU-only instances limit acceleration and cause slowdowns. Memory optimization alone does not compensate for GPU parallelism needed for such workloads."
  },
  {
    "taskStatement": "3.1",
    "stem": "A ML team wants to deploy a prediction endpoint that automatically adjusts capacity based on request rates, minimizing cost without impacting latency. How should auto-scaling be configured?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Set auto-scaling on instance count triggered by CPU utilization above 80%.",
      "B": "Configure auto-scaling using SageMaker endpoint burst capacity setting.",
      "C": "Use SageMaker endpoint auto-scaling policies on invocation count or model latency metrics.",
      "D": "Manually scale instances based on time-of-day traffic patterns."
    },
    "explanation": "SageMaker endpoint auto-scaling can be configured using invocation count or model latency to dynamically adapt capacity to real traffic patterns, balancing cost and latency. CPU utilization may not correlate directly with request load. Manual or burst capacity settings lack full automation or precision."
  },
  {
    "taskStatement": "3.1",
    "stem": "Which container choice for deploying a custom ML model to SageMaker optimally supports iterative development and debugging?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use a fully pre-built SageMaker built-in algorithm container.",
      "B": "Build and push a custom Docker container to Amazon ECR containing model and inference code.",
      "C": "Deploy model code directly to SageMaker notebook instance for in-place debugging.",
      "D": "Use AWS Lambda to containerize and deploy the model as a function."
    },
    "explanation": "Building a custom Docker container and pushing it to Amazon ECR provides full flexibility for development, debugging, and dependency management. Built-in containers don't support custom debugging easily. Deploying directly to notebooks is not a deployment solution. Lambda is not typically suitable for large ML model inference."
  },
  {
    "taskStatement": "3.1",
    "stem": "To reduce cold-start latency on an infrequently accessed SageMaker real-time endpoint, which deployment strategy is most effective?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy as a serverless endpoint with default scaling.",
      "B": "Configure the endpoint on spot instances to reduce costs.",
      "C": "Use batch transform tasks run on demand.",
      "D": "Deploy the endpoint on provisioned instances with minimum capacity to keep warm."
    },
    "explanation": "Provisioned instances with minimum capacity keep the endpoint active, reducing cold-start latency. Serverless endpoints scale to zero, causing cold starts. Spot instances are unreliable and batch transform is offline, unsuitable for real-time."
  },
  {
    "taskStatement": "3.1",
    "stem": "You are deploying a model that must support multi-tenant inference requests with strict data isolation per customer. Which deployment approach best satisfies this?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy separate SageMaker real-time endpoints per customer with individual IAM roles and VPC isolation.",
      "B": "Use a single multi-model endpoint sharing all model files and load balancing inference.",
      "C": "Deploy a single container exposing a multi-tenant API managing inference isolation internally.",
      "D": "Use SageMaker batch transform jobs per tenant on shared storage."
    },
    "explanation": "Separate endpoints per customer with IAM and VPC isolation ensure security and data isolation, which multi-model or shared container approaches cannot guarantee. Batch transform is offline and not real time."
  },
  {
    "taskStatement": "3.1",
    "stem": "Which Amazon SageMaker endpoint type is best suited for deploying large models that exceed single-instance memory limits?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Real-time single-container endpoint with large memory instance.",
      "B": "Multi-container endpoint that partitions the model across multiple containers.",
      "C": "Serverless endpoint configured with multi-instance concurrency.",
      "D": "Batch transform job with distributed processing."
    },
    "explanation": "Multi-container endpoints can split large models to run across multiple containers, overcoming single-instance memory limits during inference. Single-container endpoints rely on instance memory available. Serverless endpoints have resource limits. Batch transform is offline processing."
  },
  {
    "taskStatement": "3.1",
    "stem": "You must provision a SageMaker real-time endpoint with compute optimized instances, ensuring availability across multiple Availability Zones. How should you design this deployment?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Create a single endpoint with one instance type in one Availability Zone.",
      "B": "Manually deploy identical endpoints in multiple AZs without load balancing.",
      "C": "Deploy SageMaker endpoint in a multi-AZ VPC subnet with endpoint attached to a Network Load Balancer.",
      "D": "Use SageMaker asynchronous endpoint to distribute inference across AZs."
    },
    "explanation": "Deploying the endpoint within VPC subnets spanning multiple AZs and associating it with a Network Load Balancer enables high availability and failover across AZs. Single AZ or manual multi-endpoint without load balancing lacks availability. Asynchronous endpoints are not designed for multi-AZ failover."
  },
  {
    "taskStatement": "3.1",
    "stem": "What tradeoff should be considered when choosing between deploying a SageMaker real-time endpoint versus a SageMaker batch transform job?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Real-time endpoints have higher latency but lower operational complexity than batch jobs.",
      "B": "Batch transform supports real-time streaming data which real-time endpoints do not.",
      "C": "Real-time endpoints do not support model versioning while batch jobs do.",
      "D": "Real-time endpoints provide low-latency inference but incur continuous cost; batch transform is cost-efficient for large offline inference with latency tolerance."
    },
    "explanation": "Real-time endpoints enable low-latency predictions but incur continuous cost while running. Batch transform is suitable for offline batch jobs where latency is not critical, and can be more cost-effective but does not support real-time use cases."
  },
  {
    "taskStatement": "3.1",
    "stem": "A financial services company requires deploying models with stringent network isolation and compliance standards. Which configuration ensures maximum security in deployment?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy endpoints in public subnets with IAM roles restricting access.",
      "B": "Deploy SageMaker endpoints within private VPC subnets with no internet gateway and use VPC endpoints for S3 access.",
      "C": "Deploy models on EC2 instances outside the VPC with security groups to restrict IPs.",
      "D": "Use SageMaker serverless endpoints with encrypted payloads."
    },
    "explanation": "Deploying endpoints in private VPC subnets without internet access and using VPC endpoints to access S3 meet the highest security and compliance, eliminating public exposure. Public subnets and external EC2 lack network isolation. Serverless endpoints currently do not support private VPC networking."
  },
  {
    "taskStatement": "3.1",
    "stem": "During deployment, you observe variable inference latency caused by cold starts on your SageMaker real-time endpoint using Spot Instances. What is the best mitigation strategy?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Configure a minimum instance count with On-Demand instances alongside Spot Instances.",
      "B": "Switch entirely to Spot Instances with increased bidding price.",
      "C": "Set up a batch transform endpoint for inference.",
      "D": "Use serverless endpoints to eliminate cold starts."
    },
    "explanation": "Using a mix of On-Demand with minimum capacity and Spot Instances ensures baseline readiness and reduces cold start latency, while benefiting from Spot cost savings. Sole reliance on Spot may cause interruptions, batch transform is offline, and serverless endpoints have cold starts."
  },
  {
    "taskStatement": "3.1",
    "stem": "Which deployment orchestrator is ideal for managing complex ML pipelines involving training, validation, deployment, and monitoring within AWS?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS CloudFormation",
      "B": "AWS CodePipeline",
      "C": "Amazon EventBridge",
      "D": "SageMaker Pipelines"
    },
    "explanation": "SageMaker Pipelines specifically orchestrate ML workflows including training, evaluation, deployment, and monitoring with built-in ML-specific features. CloudFormation manages infrastructure, CodePipeline is CI/CD focused, and EventBridge handles event routing, not workflows."
  },
  {
    "taskStatement": "3.1",
    "stem": "A deep learning model requires GPU-based compute for inference but must deploy on a low-latency endpoint with minimal cost. Which instance type and endpoint configuration is optimal?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy CPU-optimized instances with high concurrency real-time endpoints.",
      "B": "Use memory-optimized instances with batch transform endpoints.",
      "C": "Use GPU-based instances with multi-model real-time endpoints to share GPU among models.",
      "D": "Deploy GPU instances with serverless endpoints for on-demand usage."
    },
    "explanation": "GPU-based real-time endpoints deliver low latency for deep learning inference. Using multi-model endpoints supports model sharing on the same GPU instances reducing cost. CPU or memory optimized instances won\u2019t meet GPU requirements. Serverless endpoints do not currently support GPU instance types."
  },
  {
    "taskStatement": "3.1",
    "stem": "How can an ML engineer optimize latency and cost for real-time inference when deploying multiple lightweight models with low traffic per model?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Create separate real-time SageMaker endpoints for each model on CPU instances.",
      "B": "Use SageMaker multi-model endpoints to dynamically load models on shared compute instances.",
      "C": "Deploy models as batch transform jobs triggered per request.",
      "D": "Containerize all models in one large custom Docker container for a single endpoint."
    },
    "explanation": "Multi-model endpoints load models on-demand within a shared container and instance reducing costs for multiple models with low traffic. Separate endpoints increase costs. Batch transform is offline. One large container reduces modularity and increases complexity."
  },
  {
    "taskStatement": "3.1",
    "stem": "When deploying ML models on AWS for inference, why might an engineer choose asynchronous endpoints over real-time endpoints?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "To achieve real-time sub-millisecond latency.",
      "B": "To utilize GPU acceleration unavailable to real-time endpoints.",
      "C": "To avoid the need for request batching during inference.",
      "D": "To handle large payloads or unpredictable spikes without blocking the client."
    },
    "explanation": "Asynchronous endpoints buffer requests, enabling handling large payloads or traffic spikes without forcing clients to wait, suitable when response time is flexible. Real-time endpoints provide low latency but can become overwhelmed. GPU acceleration is supported on both."
  },
  {
    "taskStatement": "3.1",
    "stem": "What factors should be considered when choosing between deploying ML models on Amazon ECS versus SageMaker endpoints?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon ECS offers built-in hyperparameter tuning capabilities, SageMaker does not.",
      "B": "SageMaker endpoints cannot be integrated with VPCs, ECS can.",
      "C": "SageMaker provides native ML model deployment, scaling, monitoring, and versioning; ECS requires custom setup for these.",
      "D": "ECS supports multi-model endpoints, SageMaker doesn\u2019t."
    },
    "explanation": "SageMaker provides native managed services tailored for ML deployment including model versioning, auto-scaling, monitoring, and native integration with ML workflows, whereas ECS needs custom infrastructure and tooling for these capabilities."
  },
  {
    "taskStatement": "3.1",
    "stem": "Which SageMaker endpoint deployment strategy facilitates A/B testing of two models in production with controlled traffic distribution?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy two variants under the same endpoint and split traffic percentage between them.",
      "B": "Deploy separate endpoints and manually route client requests via DNS.",
      "C": "Sequentially switch the single endpoint between models at fixed intervals.",
      "D": "Use batch transform jobs to compare model outputs offline."
    },
    "explanation": "SageMaker supports deploying multiple model variants under a single endpoint and configuring traffic distribution per variant, facilitating controlled A/B testing. Separate endpoints require client logic; switches cause downtime and batch transform is offline."
  },
  {
    "taskStatement": "3.1",
    "stem": "A data scientist wants to deploy a model trained outside SageMaker within the SageMaker inference environment with minimal code changes. Which deployment mechanism should be used?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Rewrite the model in SageMaker built-in algorithms format.",
      "B": "Package the model artifacts and use a SageMaker pre-built container compatible with the framework used.",
      "C": "Deploy the model as an AWS Lambda function with custom dependencies.",
      "D": "Use AWS Glue to convert and deploy the model inside SageMaker."
    },
    "explanation": "SageMaker pre-built containers support common ML frameworks and allow models trained externally to be deployed with minimal modification. Rewriting is inefficient. Lambda has size/latency limits. AWS Glue is for ETL, not model deployment."
  },
  {
    "taskStatement": "3.1",
    "stem": "What is the main benefit of deploying models to SageMaker asynchronous inference endpoints instead of real-time endpoints?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Lower deployment cost by eliminating compute usage during off-hours.",
      "B": "Faster response times for real-time user interaction.",
      "C": "Ability to handle inference requests with large payloads without timing out.",
      "D": "Support for GPU acceleration during inference."
    },
    "explanation": "Asynchronous endpoints buffer requests and handle large payloads asynchronously, which real-time endpoints may timeout on. They are suitable when immediate response is not required. Real-time endpoints provide low latency but may not handle large payloads."
  },
  {
    "taskStatement": "3.1",
    "stem": "Which network configuration is required to deploy a SageMaker endpoint that accesses data in Amazon S3 but must not have direct internet access?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy endpoint in a public subnet with a NAT gateway for S3 access.",
      "B": "Enable public IP and restrict S3 access via IAM policies.",
      "C": "Attach endpoint to default VPC with direct internet access.",
      "D": "Deploy endpoint in private subnet with a VPC endpoint for S3 access configured."
    },
    "explanation": "Deploying in a private subnet with a configured VPC Endpoint for S3 provides secure, private connectivity to S3 without internet access. Public IP or NAT expose the endpoint to the internet which may violate security requirements."
  },
  {
    "taskStatement": "3.1",
    "stem": "Your ML model requires minimal latency and must handle inference from IoT devices at the edge with occasional internet connectivity. How do you optimize deployment?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy the model exclusively on AWS Lambda with edge networking enabled.",
      "B": "Compile and deploy the model on edge devices via SageMaker Neo, syncing updates asynchronously.",
      "C": "Use SageMaker real-time endpoints in the cloud accessed directly from devices.",
      "D": "Batch inferencing with data periodically uploaded to S3 for processing."
    },
    "explanation": "SageMaker Neo compiles models optimized for edge devices that can run locally with minimal latency. Devices can sync when connected. Real-time cloud endpoints depend on connectivity and higher latency; batch inference is not real-time."
  },
  {
    "taskStatement": "3.1",
    "stem": "During deployment, how does choosing between serverless and provisioned real-time SageMaker endpoints affect cost and scalability?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Serverless endpoints scale automatically to zero, reducing costs for sporadic traffic; provisioned endpoints incur fixed costs regardless of usage.",
      "B": "Provisioned endpoints tend to be more cost-effective for intermittent workloads than serverless.",
      "C": "Serverless endpoints cannot scale beyond one instance.",
      "D": "Provisioned endpoints cannot use GPU instances."
    },
    "explanation": "Serverless endpoints automatically scale from zero, so cost matches usage, ideal for spiky workloads. Provisioned endpoints maintain minimum instance counts, incurring baseline costs. Serverless supports CPU instances mainly. Provisioned endpoints can use GPUs."
  },
  {
    "taskStatement": "3.1",
    "stem": "Which SageMaker endpoint type allows you to deploy models for asynchronous batch processing with automatic scaling and built-in retry logic?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Real-time endpoints",
      "B": "Asynchronous inference endpoints",
      "C": "Serverless endpoints",
      "D": "Batch transform jobs"
    },
    "explanation": "Asynchronous inference endpoints support asynchronous requests with automatic scaling, retries, and buffering suitable for variable workloads. Real-time endpoints are synchronous; batch transform is offline; serverless endpoints are for real-time but limited scale currently."
  },
  {
    "taskStatement": "3.1",
    "stem": "How do you best optimize performance and cost when deploying multiple small models with independent traffic profiles to production?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy each model on dedicated provisioned real-time endpoints.",
      "B": "Aggregate models in a single large container deployed as serverless endpoint.",
      "C": "Use SageMaker multi-model endpoints to share resources and load models dynamically.",
      "D": "Deploy models as batch transform jobs with scheduled triggers."
    },
    "explanation": "Multi-model endpoints allow multiple models to share a single endpoint and instances, dynamically loading models when needed, reducing resource overhead for low-traffic models. Dedicated endpoints increase cost; serverless currently limited; batch jobs are not real-time."
  },
  {
    "taskStatement": "3.2",
    "stem": "An ML engineer is automating the deployment of SageMaker endpoints within a secure Amazon VPC. The endpoints must support high throughput and low latency inference for real-time applications. Which combination of configurations will meet these requirements most effectively?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy endpoints in a public subnet with internet access and configure auto scaling on CPU utilization.",
      "B": "Use an asynchronous endpoint outside the VPC and configure batch transform jobs for inference.",
      "C": "Deploy endpoints in private subnets without security groups to minimize latency.",
      "D": "Deploy endpoints in private subnets with appropriate security groups and enable SageMaker endpoint auto scaling based on invocation concurrency."
    },
    "explanation": "Deploying endpoints inside a VPC private subnet with security groups ensures secure connectivity. Enabling SageMaker endpoint auto scaling based on invocations supports fluctuating demand to maintain low latency and high throughput."
  },
  {
    "taskStatement": "3.2",
    "stem": "You need to automate the provisioning of training infrastructure for a distributed deep learning model on SageMaker using infrastructure as code (IaC). Which approach best ensures portability and maintainability of resources?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Manually provision Amazon EC2 GPU instances and create training scripts with hardcoded resource IDs.",
      "B": "Use AWS CloudFormation or AWS CDK to define SageMaker training jobs and associated resources declaratively.",
      "C": "Use the SageMaker console to configure training jobs and extract code snippets for automation.",
      "D": "Create custom shell scripts to launch training instances and install dependencies at runtime."
    },
    "explanation": "AWS CloudFormation and CDK provide declarative, template-driven infrastructure provisioning which enables portability, versioning, and repeatability essential for maintainable ML pipelines."
  },
  {
    "taskStatement": "3.2",
    "stem": "During containerized deployment of a SageMaker model, you must create a custom Docker image that includes a specific ML framework version and a pre- and post-processing script. What best practice should you follow when building and managing this container?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Embed credentials for AWS resources directly inside the Dockerfile for seamless access.",
      "B": "Use the AWS Deep Learning Containers without customization to reduce complexity.",
      "C": "Build containers locally, push them to Amazon ECR with immutable version tags, and use SageMaker execution roles for permissions.",
      "D": "Use the latest 'latest' image tags for ML frameworks to ensure up-to-date software."
    },
    "explanation": "Building custom containers locally, versioning with immutable tags in ECR, and managing permissions via SageMaker execution roles ensures secure, reliable, and traceable deployments."
  },
  {
    "taskStatement": "3.2",
    "stem": "You are tasked with selecting metrics to configure SageMaker endpoint auto scaling in a scenario where the application requires tight latency controls under variable traffic. Which metrics would you prioritize configuring for auto scaling?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Model latency, invocation count per instance, and CPU utilization.",
      "B": "Disk usage, RAM usage, and network throughput.",
      "C": "Training job epoch time and batch size.",
      "D": "Number of API Gateway requests and Lambda invocations."
    },
    "explanation": "Model latency and invocation count per instance directly impact real-time inference performance. CPU utilization helps assess resource usage for scaling decisions."
  },
  {
    "taskStatement": "3.2",
    "stem": "A team wants to build a containerized ML inference application for SageMaker using a BYOC approach. They need to automate deployment and ensure the container can communicate securely with Amazon S3 data sources in a different VPC. What is the recommended secure architectural approach?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Build the container with hardcoded AWS credentials for cross-VPC S3 access.",
      "B": "Use IAM roles for SageMaker with VPC endpoints configured for Amazon S3 access and deploy the container inside the VPC.",
      "C": "Host the container on Amazon ECS outside the VPC and allow open S3 bucket policies.",
      "D": "Use Lambda functions to proxy S3 access from the container."
    },
    "explanation": "IAM roles and VPC endpoints allow secure, permission-bound access to S3 from SageMaker endpoints deployed in the VPC without exposing credentials or opening buckets publicly."
  },
  {
    "taskStatement": "3.2",
    "stem": "Which technique is most effective when automating the provisioning of SageMaker multi-container endpoints using AWS CloudFormation or CDK to ensure smooth version updates without downtime?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Delete the existing endpoint and recreate with the new containers immediately.",
      "B": "Use manual updates to the endpoint via the SageMaker console and then update IaC templates.",
      "C": "Deploy a new endpoint alongside the existing one and switch traffic using DNS updates manually.",
      "D": "Use CloudFormation or CDK blue-green deployment strategies to update endpoints with minimal downtime."
    },
    "explanation": "Blue-green deployment orchestrated via IaC allows new model versions to deploy alongside existing ones and swap traffic safely, minimizing downtime and disruptions."
  },
  {
    "taskStatement": "3.2",
    "stem": "While automating the setup of containers for real-time inference on SageMaker, you want to reduce image size without compromising functionality. What is a best practice for container size optimization?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Base your Docker image on lightweight base images like Amazon Linux 2 or Alpine and minimize included packages.",
      "B": "Include all dependencies and SDKs regardless of usage to ensure flexibility.",
      "C": "Use Windows containers for compatibility despite their larger size.",
      "D": "Use the full Ubuntu image to avoid missing dependencies at runtime."
    },
    "explanation": "Lightweight base images reduce container size substantially and improve deploy time and startup latency, which is critical for real-time inference endpoints."
  },
  {
    "taskStatement": "3.2",
    "stem": "An ML engineer needs to programmatically configure SageMaker endpoints inside a VPC to meet compliance regulations requiring network traffic to stay within the VPC. Which combination of configurations is necessary?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy endpoints in public subnets with NAT gateways for internet access.",
      "B": "Use default SageMaker endpoints with no VPC configuration.",
      "C": "Configure SageMaker endpoint VPC configuration with subnet IDs and security group IDs matching the private VPC resources.",
      "D": "Connect endpoints via VPN to on-premises network without VPC configuration."
    },
    "explanation": "Configuring the VPC subnets and security groups directly on the SageMaker endpoints ensures all network traffic stays within the specified VPC and complies with regulations."
  },
  {
    "taskStatement": "3.2",
    "stem": "You are designing a CI/CD pipeline for SageMaker model deployment using AWS CDK. The pipeline must automate container builds, push images to Amazon ECR, and deploy models with zero downtime. Which AWS service combinations are essential for this automation?",
    "correct": "A",
    "difficulty": "HARD",
    "answers": {
      "A": "AWS CodeBuild for container builds, Amazon ECR for image storage, AWS CodePipeline to orchestrate deployment, and AWS CloudFormation or CDK to provision resources.",
      "B": "Manual Docker builds and uploading images to Amazon S3, AWS Lambda for deployment triggers.",
      "C": "Use Amazon SageMaker SDK alone to perform container builds and deployments.",
      "D": "AWS CloudTrail for deployment logging and Amazon SNS for notifications only."
    },
    "explanation": "AWS CodeBuild automates Docker container builds, ECR stores images, CodePipeline orchestrates steps, and CloudFormation/CDK manages provisioning for automated and repeatable deployments."
  },
  {
    "taskStatement": "3.2",
    "stem": "When scripting infrastructure for ML model hosting following best practices, what is the key benefit of using AWS Cloud Development Kit (CDK) over plain CloudFormation YAML templates?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "CDK consumes less AWS service quotas than CloudFormation.",
      "B": "CDK allows defining infrastructure using familiar programming languages with abstractions, improving maintainability and reusability.",
      "C": "CDK automatically deploys models without additional pipelines.",
      "D": "CDK eliminates the need for IAM role configuration."
    },
    "explanation": "CDK enables defining infrastructure as code in languages like Python or TypeScript, offering higher-level abstractions and constructs that simplify code reuse and maintenance compared to verbose YAML templates."
  },
  {
    "taskStatement": "3.2",
    "stem": "You are monitoring delays in SageMaker asynchronous endpoints during high-load conditions. Which IaC feature and configuration adjustments can help automatically scale resources to minimize these delays?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Manually increase instance counts during peak times in CloudFormation templates.",
      "B": "Configure SageMaker endpoint auto scaling policies with metrics like InvocationsPerInstance and model latency in CDK alongside EventBridge rules.",
      "C": "Use fixed instance counts with larger instance types and no auto scaling.",
      "D": "Deploy multiple different endpoints and reroute traffic manually during delays."
    },
    "explanation": "Using auto scaling policies configured programmatically via IaC and CloudWatch metrics can dynamically allocate resources based on traffic patterns, reducing latency under load."
  },
  {
    "taskStatement": "3.2",
    "stem": "In a requirement to deploy both CPU- and GPU-optimized inference containers on a SageMaker multi-container endpoint, how should you configure the infrastructure scripted with AWS CDK?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy separate single-container endpoints for CPU and GPU and route traffic outside of SageMaker.",
      "B": "Use a single instance type and synchronize all containers on it regardless of optimization.",
      "C": "Configure the endpoint with multi-container support selecting instance types that support both CPU and GPU workloads or use multi-model endpoints with appropriate containers.",
      "D": "Deploy CPU workloads in AWS Lambda and GPU in SageMaker separate endpoints."
    },
    "explanation": "Multi-container endpoints can host heterogeneous containers; selecting compatible instance types and properly scripting multi-container deployment in CDK enables serving both CPU and GPU optimally."
  },
  {
    "taskStatement": "3.2",
    "stem": "To maintain compliance, an organization requires all SageMaker model containers to be scanned automatically for vulnerabilities prior to deployment. What is an effective way to integrate this into automated infrastructure deployment?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Rely entirely on AWS\u2019s default container security without additional scanning.",
      "B": "Scan containers manually outside the deployment pipeline before pushing to ECR.",
      "C": "Use Docker Hub as container registry to leverage Docker security scanning.",
      "D": "Integrate Amazon ECR image scanning into the CI/CD pipeline and codify deployment steps to block unscanned or vulnerable images."
    },
    "explanation": "Amazon ECR supports image scanning for vulnerabilities which can be enforced in CI/CD pipelines ensuring only secure images are deployed via automation tools like CDK or CloudFormation."
  },
  {
    "taskStatement": "3.2",
    "stem": "When creating containers for SageMaker endpoints, why is it recommended to minimize layers and combine commands in the Dockerfile?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "It enables easier rollback to previous layers during deployment failures.",
      "B": "It reduces image size and speeds up the container build, push, and startup processes, optimizing deployment speed.",
      "C": "It improves logging granularity for debugging at runtime.",
      "D": "It automatically enhances security by isolating processes."
    },
    "explanation": "Consolidating commands into fewer layers reduces the final image size, resulting in faster builds, pushes, and quicker cold starts in real-time inference endpoints."
  },
  {
    "taskStatement": "3.2",
    "stem": "When automating SageMaker endpoint deployment in a private subnet of a customer VPC, what networking component must you ensure is configured to provide necessary AWS service access?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Interface VPC endpoints (AWS PrivateLink) for SageMaker API and S3 access.",
      "B": "A public NAT gateway in the private subnet for internet access.",
      "C": "Configure Elastic IP addresses attached to the private subnets.",
      "D": "Open security group rules to allow all outbound traffic to internet."
    },
    "explanation": "Interface VPC endpoints enable private connectivity to AWS services like SageMaker and S3 from within private subnets without traversing the public internet, maintaining compliance."
  },
  {
    "taskStatement": "3.2",
    "stem": "How can an ML engineer automate rollback mechanisms in SageMaker endpoint deployments scripted with IaC to ensure service stability during failed deployments?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Manually monitor endpoints and redeploy previous containers if errors occur.",
      "B": "Use AWS Lambda functions for manual rollback triggered via CloudWatch alarms.",
      "C": "Implement deployment strategies like blue/green or canary deployments in CDK or CloudFormation with automatic traffic shifting.",
      "D": "Schedule endpoint recreation at off-peak times to minimize risk."
    },
    "explanation": "Automated blue/green or canary deployments with traffic shift capabilities embedded in IaC allow safe transitions and automatic rollback on issues, reducing downtime and operational overhead."
  },
  {
    "taskStatement": "3.2",
    "stem": "Which of the following best describes the purpose of using IAM roles and policies when automating SageMaker endpoint deployments inside a VPC?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "To securely provide SageMaker endpoints permissions to access required AWS resources without embedding credentials.",
      "B": "To enable SageMaker endpoints to be accessible publicly over the internet.",
      "C": "To allow cross-account access to the SageMaker console for all users.",
      "D": "To bypass VPC security groups for endpoint traffic."
    },
    "explanation": "IAM roles and policies grant SageMaker endpoints least-privilege access to AWS resources securely and eliminate the need to store credentials inside containers or code."
  },
  {
    "taskStatement": "3.2",
    "stem": "An ML team wants to use AWS CDK to script multi-environment deployment of SageMaker endpoints (dev, staging, prod) sharing base infrastructure but varying compute specifications. What CDK practice supports this efficiently?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Create completely separate CDK stacks for each environment with duplicated code.",
      "B": "Use CDK context variables and environment-specific configuration files to parameterize instance types and scaling settings.",
      "C": "Hardcode instance types in CDK code and deploy sequentially.",
      "D": "Deploy same instance specs across all environments for consistency."
    },
    "explanation": "Parameterizing environment-specific variables via context or config files allows reuse of base infrastructure code and easy customization supporting maintainability and DRY principles."
  },
  {
    "taskStatement": "3.2",
    "stem": "While deploying SageMaker endpoints with auto scaling, which CloudWatch alarm configuration is critical to prevent scaling too aggressively, causing cost spikes and potential throttling?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Set a low threshold on CPU utilization without cooldown periods.",
      "B": "Set high thresholds on disk I/O operations to trigger scale down.",
      "C": "Enable alarms on network bytes transmitted to scale out rapidly.",
      "D": "Implement appropriate cooldown periods and multiple metrics (e.g., latency and invocation rate) combined for scaling decisions."
    },
    "explanation": "Cooldowns prevent rapid flapping between scales and combining multiple metrics ensures scaling is balanced to workload patterns, avoiding unnecessary costs while maintaining performance."
  },
  {
    "taskStatement": "3.2",
    "stem": "You want to script deployment of SageMaker endpoints using AWS CDK alongside Amazon ECS container deployments referencing the same model artifacts stored in S3. How can you ensure artifact version consistency across services?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Manually update S3 URIs in both CDK stacks whenever artifacts change.",
      "B": "Store artifacts in Amazon ECR and deploy from there exclusively.",
      "C": "Use AWS CodePipeline to build, version, and pass artifact UIDs via CDK parameters to both SageMaker and ECS deployments atomically.",
      "D": "Use hardcoded URIs in environment variables with no automation."
    },
    "explanation": "Integrating CodePipeline with artifact versioning and passing version parameters to IaC ensures consistent deployment across different services referencing the same model artifacts."
  },
  {
    "taskStatement": "3.2",
    "stem": "What is the main advantage of using Amazon Elastic Container Registry (ECR) with immutable tags in the context of automated SageMaker model deployment?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "ECR encrypts container images by default providing enhanced security.",
      "B": "Immutable tags prevent image overwrites, ensuring traceability and reproducibility of deployments.",
      "C": "Immutable tags reduce storage costs by compressing images.",
      "D": "ECR automatically updates containers to the latest image versions with immutable tags."
    },
    "explanation": "Immutable tags prevent accidental image overwrites, allowing deployments to reference specific container versions for auditability and stable environment reproduction."
  },
  {
    "taskStatement": "3.2",
    "stem": "An organization requires that all infrastructure code creating SageMaker resources be version controlled and peer-reviewed before deployment. Which tooling and process combination supports this?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use a Git-based repository that triggers AWS CodeBuild and CodePipeline to run deployment validations and push IaC changes.",
      "B": "Manually write CloudFormation templates and deploy them using the AWS console.",
      "C": "Use AWS Lambda functions to commit code on behalf of developers.",
      "D": "Use unmanaged scripts stored locally on developer machines."
    },
    "explanation": "A Git workflow with pipeline automation for validation and deployment enforces version control and peer review, enabling policy enforcement and tracing changes systematically."
  },
  {
    "taskStatement": "3.2",
    "stem": "When using AWS CDK to script deployment of a custom SageMaker container with dependencies, how can you minimize deployment failures related to environment mismatch?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Hardcode dependency versions in Dockerfile and avoid testing locally.",
      "B": "Use AWS Marketplace container images as base to avoid custom builds.",
      "C": "Implement container builds using container image build tools with reproducible build settings and test images in staging before production.",
      "D": "Skip dependency versioning to allow flexibility during inference."
    },
    "explanation": "Reproducible builds and thorough testing in non-production environments ensure environments match precisely, reducing unexpected failures in production."
  },
  {
    "taskStatement": "3.2",
    "stem": "Which of the following security best practices should be implemented when scripting SageMaker endpoint infrastructure using IaC in a shared AWS account?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Grant broad IAM permissions to deployment users for simplicity.",
      "B": "Implement least privilege IAM roles and policies attached to SageMaker resources and enforce resource tagging for cost and access tracking.",
      "C": "Disable VPC endpoints to allow open internet access for easier troubleshooting.",
      "D": "Store secrets like database credentials directly inside Docker containers."
    },
    "explanation": "Least privilege practices and tagging improve security posture, ensure proper cost allocation, and reduce risk of unauthorized access and resource sprawl."
  },
  {
    "taskStatement": "3.2",
    "stem": "To optimize network traffic costs and latency, what configuration should be included in the IaC templates for SageMaker endpoint deployments that must access data in an Amazon S3 bucket?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Configure VPC Gateway endpoint for Amazon S3 to route traffic internally without leaving AWS network.",
      "B": "Allow outbound internet access on endpoint subnets for public S3 access.",
      "C": "Use NAT Gateways for S3 access from endpoints in private subnets exclusively.",
      "D": "Direct endpoints to fetch data from public internet URLs."
    },
    "explanation": "A VPC Gateway endpoint for S3 enables private, cost-effective, and low-latency access within the AWS network, reducing egress charges and improving security."
  },
  {
    "taskStatement": "3.2",
    "stem": "How can you best implement infrastructure as code (IaC) for SageMaker endpoints that require dynamic resource provisioning based on variable workloads?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Hardcode instance counts and types in CloudFormation templates and update manually.",
      "B": "Provision maximum resource capacity up front to avoid scaling issues.",
      "C": "Use IaC to provision the minimum infrastructure along with auto scaling configurations to dynamically adjust resources.",
      "D": "Deploy endpoints without auto scaling and monitor manually."
    },
    "explanation": "Combining IaC provisioning of baseline infrastructure with auto scaling enables efficient dynamic resource management adapting to workload fluctuations automatically."
  },
  {
    "taskStatement": "3.2",
    "stem": "Which AWS tool can you use in your automated SageMaker deployment pipeline to detect code defects and performance bottlenecks before container creation?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon CodeGuru Reviewer to analyze code quality and suggest improvements.",
      "B": "AWS Inspector to scan Docker images for vulnerabilities.",
      "C": "AWS Trusted Advisor to recommend cost savings.",
      "D": "Amazon Macie to classify sensitive data in code repositories."
    },
    "explanation": "Amazon CodeGuru Reviewer integrates with CI pipelines to provide automated code reviews highlighting defects and inefficiencies prior to container packaging and deployment."
  },
  {
    "taskStatement": "3.2",
    "stem": "How should you use AWS Glue DataBrew in combination with automated SageMaker infrastructure provisioning to ensure data transformations are repeatable and consistent?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Perform manual transformations through DataBrew UI, export results, and upload to S3 for SageMaker.",
      "B": "Use DataBrew only for ad hoc cleansing and do not integrate with IaC.",
      "C": "Write custom code transformations instead of using DataBrew for better control.",
      "D": "Create DataBrew jobs and recipes programmatically via AWS SDK/CLI and trigger them within deployment pipelines before model training and endpoint provisioning."
    },
    "explanation": "Automating DataBrew job and recipe creation and execution via scripts integrates data transformation in the ML pipeline, ensuring repeatability and consistency alongside infrastructure deployment."
  },
  {
    "taskStatement": "3.2",
    "stem": "When configuring SageMaker endpoint auto scaling policies in IaC, why is it important to include both scale-out and scale-in cooldown periods?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Cooldowns prevent the endpoint from ever scaling down, keeping capacity high.",
      "B": "Cooldown periods prevent rapid oscillations between scaling events, reducing instability and cost spikes.",
      "C": "Cooldowns increase the frequency of scaling triggering to improve responsiveness.",
      "D": "Cooldowns ensure only scale-in events are delayed, not scale-out events."
    },
    "explanation": "Cooldowns provide a buffer time before another scaling action occurs, avoiding thrashing and ensuring resource stability and cost efficiency."
  },
  {
    "taskStatement": "3.2",
    "stem": "You are automating the deployment of SageMaker endpoints using CDK and want to integrate monitoring and logging with minimal manual configuration. Which built-in SageMaker feature should you enable in your deployment script?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable CloudTrail logging for SageMaker admin activities only.",
      "B": "Manually configure CloudWatch Logs in a separate step after deployment.",
      "C": "Enable SageMaker Model Debugger and CloudWatch Metrics within the endpoint configuration for automated resource monitoring.",
      "D": "Send logs to Amazon S3 buckets manually created."
    },
    "explanation": "SageMaker Model Debugger and CloudWatch Metrics can be enabled programmatically during deployment to automatically capture logs and monitoring data without manual setup."
  },
  {
    "taskStatement": "3.2",
    "stem": "What is the implication of choosing On-Demand Instances versus Spot Instances in scripted SageMaker endpoint deployment templates for cost and availability?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Spot Instances provide guaranteed availability but cost more than On-Demand.",
      "B": "On-Demand provides higher availability at higher cost; Spot is cheaper but may be interrupted, requiring handling in deployment scripts.",
      "C": "Spot Instances have the same uptime guarantees as On-Demand within SageMaker.",
      "D": "On-Demand Instances cannot be used for real-time endpoints."
    },
    "explanation": "On-Demand instances offer stable availability critical for real-time endpoints, whereas Spot instances lower cost but involve potential interruptions requiring fallback strategies."
  },
  {
    "taskStatement": "3.2",
    "stem": "How can you use AWS Systems Manager Parameter Store in your automated SageMaker deployment pipeline?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Store configuration parameters like IAM role ARNs, VPC IDs, and image URIs to be referenced securely in IaC scripts.",
      "B": "Automatically build and push Docker images to Amazon ECR.",
      "C": "Run SageMaker training jobs through parameterized scripts.",
      "D": "Monitor endpoint health status in real-time."
    },
    "explanation": "Parameter Store centralizes configuration management, enabling scripts to retrieve sensitive and environment-specific parameters securely during deployments."
  },
  {
    "taskStatement": "3.3",
    "stem": "An ML engineer wants to automate retraining a SageMaker model whenever new data is committed to a Git repository. Which AWS service combination best supports a CI/CD pipeline that triggers model retraining with minimal manual intervention?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS CodeDeploy connected to AWS Lambda to listen for Git commits and trigger training.",
      "B": "AWS CodeBuild polls the Git repository and triggers a training job on schedule.",
      "C": "AWS CodePipeline integrated with CodeCommit and SageMaker to automatically trigger retraining when a new commit is pushed.",
      "D": "AWS CloudFormation template triggered on Git commit to launch SageMaker training jobs."
    },
    "explanation": "AWS CodePipeline integrates natively with CodeCommit repositories to automate the CI/CD workflow including SageMaker training jobs, enabling automated retraining triggered by code or data changes with minimal manual effort."
  },
  {
    "taskStatement": "3.3",
    "stem": "What is the most effective deployment strategy for rolling out a new version of an ML model in a CI/CD pipeline to minimize user impact if the new model performs poorly?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Immediate replacement of the old model with the new version at the production endpoint.",
      "B": "Canary deployment directing a small percentage of traffic to the new model while monitoring performance before full rollout.",
      "C": "Blue/green deployment pre-deploying new model in parallel using same production endpoint URL.",
      "D": "Manual rollback to previous model version without traffic segmentation."
    },
    "explanation": "Canary deployment allows gradual exposure of the new model to a subset of users, enabling monitoring and quick rollback if issues arise, minimizing negative user impact compared to immediate replacement."
  },
  {
    "taskStatement": "3.3",
    "stem": "In a SageMaker CI/CD pipeline, what is the primary role of AWS CodeBuild?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "It compiles, builds, and tests source code and ML training scripts as stages in the pipeline.",
      "B": "It manages the deployment of models to SageMaker endpoints.",
      "C": "It monitors deployed models for data drift and triggers retraining.",
      "D": "It handles version control of ML code repositories."
    },
    "explanation": "AWS CodeBuild is responsible for building and testing code artifacts, including ML training scripts, within the pipeline before deployment stages."
  },
  {
    "taskStatement": "3.3",
    "stem": "Which feature of AWS CodePipeline helps implement rollback functionality in a continuous deployment process for machine learning models?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Integration with SageMaker Model Registry to version models automatically.",
      "B": "Use of CloudTrail to log all deployment events for audit purposes.",
      "C": "Enabling manual approval actions to control deployments.",
      "D": "Use of multiple deployment stages with the ability to redeploy a previous stable version on failure."
    },
    "explanation": "CodePipeline supports multiple stages and deployment actions, allowing redeployment of previous versions if a newer deployment fails, enabling rollback functionality."
  },
  {
    "taskStatement": "3.3",
    "stem": "How can an ML engineer implement tests in a CI/CD pipeline to validate an ML model before deployment?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "By running manual ad-hoc tests after deployment completes.",
      "B": "By incorporating unit tests, integration tests, and performance tests within AWS CodeBuild stages in the pipeline.",
      "C": "By relying solely on evaluation metrics calculated after model deployment.",
      "D": "By using Amazon CloudWatch Alarms on endpoint latency post-deployment."
    },
    "explanation": "Effective CI/CD pipelines include automated unit and integration tests in the build stages to validate the model and code before deployment, catching issues early."
  },
  {
    "taskStatement": "3.3",
    "stem": "Which AWS service or tool helps automate triggering a SageMaker model training job as part of a CI/CD pipeline?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon EventBridge can detect events such as code commits and invoke SageMaker training jobs automatically.",
      "B": "AWS Config tracks configuration changes and triggers training jobs.",
      "C": "Amazon CloudTrail logs API calls but does not trigger training jobs directly.",
      "D": "AWS CloudFormation deploys infrastructure but does not trigger training workflows."
    },
    "explanation": "Amazon EventBridge can listen to triggers like Git commits and invoke Lambda functions or SageMaker training jobs to automate training workflow integration."
  },
  {
    "taskStatement": "3.3",
    "stem": "When configuring a CI/CD pipeline for SageMaker model deployment, how should secret credentials for accessing resources be managed?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Store credentials in pipeline environment variables as plaintext for easy access.",
      "B": "Hardcode secrets in training scripts to ensure pipeline access.",
      "C": "Use AWS Secrets Manager and IAM roles to securely manage and access sensitive credentials in pipeline stages.",
      "D": "Embed credentials in Docker containers used for training and deployment."
    },
    "explanation": "The best practice is to use AWS Secrets Manager combined with IAM roles for secure, auditable access to secrets within CI/CD pipelines without exposing credentials."
  },
  {
    "taskStatement": "3.3",
    "stem": "What is a key benefit of incorporating SageMaker Pipelines into a CI/CD workflow compared to using only AWS CodePipeline?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "SageMaker Pipelines offers unlimited integration with all AWS developer tools.",
      "B": "SageMaker Pipelines provides ML-specific workflow steps such as data loading, training, evaluation, and model registration tailored for ML use cases.",
      "C": "SageMaker Pipelines replaces the need for version control systems like Git.",
      "D": "SageMaker Pipelines automates deployment to Kubernetes clusters only."
    },
    "explanation": "SageMaker Pipelines is designed specifically for ML workflows, offering steps optimized for model building, evaluation, and deployment beyond generic CI/CD orchestration tools like CodePipeline."
  },
  {
    "taskStatement": "3.3",
    "stem": "An ML engineer wants to implement continuous testing of model quality after deployment. Which approach fits best in a CI/CD pipeline?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Run tests only on training data before deployment to production.",
      "B": "Manually evaluate model predictions once per month and update the pipeline accordingly.",
      "C": "Perform integration tests on infrastructure setups unrelated to data or model quality.",
      "D": "Automate model quality checks using batch inference with test datasets and incorporate results as pipeline gates before promoting models to production."
    },
    "explanation": "Integrating automated model quality checks in the pipeline ensures only models meeting quality criteria proceed to production, enhancing reliability and compliance."
  },
  {
    "taskStatement": "3.3",
    "stem": "Which CodePipeline action type is most appropriate to package ML model artifacts prior to deployment?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Source action type to fetch latest code from Git repositories.",
      "B": "Build action type to execute scripts that package model artifacts and dependencies into containers or S3 buckets.",
      "C": "Deploy action type to push models directly to endpoints without packaging.",
      "D": "Approval action type to manually check artifacts before deployment."
    },
    "explanation": "The build stage packages code and model artifacts, preparing them for deployment, whereas source and deploy serve different roles in the pipeline."
  },
  {
    "taskStatement": "3.3",
    "stem": "How should model versioning be integrated within a CI/CD pipeline for SageMaker?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use static model names and overwrite model artifacts on each deployment.",
      "B": "Maintain model versions only in Git tags without SageMaker tracking.",
      "C": "Register models in SageMaker Model Registry with explicit versioning and promote versions through pipeline stages.",
      "D": "Manually label models deployed to endpoints without integration into the pipeline."
    },
    "explanation": "The SageMaker Model Registry provides structured versioning and management of model artifacts, enabling controlled promotion and rollback inside CI/CD workflows."
  },
  {
    "taskStatement": "3.3",
    "stem": "When using AWS CodeDeploy in a CI/CD pipeline for ML model deployment, what deployment type supports gradually shifting traffic to new model versions?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Canary deployment type progressively diverts a percentage of traffic to the new model.",
      "B": "Recreate deployment immediately replaces old version with new version.",
      "C": "Blue/Green deployment uses separate environments but does not shift traffic gradually.",
      "D": "Linear deployment is unsupported in CodeDeploy."
    },
    "explanation": "Canary deployments phasedly introduce new model versions to a subset of users to detect issues before full rollout."
  },
  {
    "taskStatement": "3.3",
    "stem": "Which AWS CodePipeline feature is essential for tracking the full model lifecycle in an automated ML CI/CD pipeline?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Manual approvals before training job execution.",
      "B": "Integration with CloudWatch Logs for endpoint monitoring.",
      "C": "Use of CloudFormation templates for infrastructure provisioning.",
      "D": "Use of stages and artifacts to track source code, training artifacts, and deployment manifests across pipeline executions."
    },
    "explanation": "CodePipeline stages and artifacts define the flow and track the input/output artifacts supporting traceability throughout the ML lifecycle."
  },
  {
    "taskStatement": "3.3",
    "stem": "In an automated deployment pipeline for ML, how is continuous training triggered based on model drift detected in production?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Manually inspect SageMaker Model Monitor alerts and start retraining.",
      "B": "Configure SageMaker Model Monitor to send drift events to Amazon EventBridge which triggers pipeline retraining stages.",
      "C": "Configure CloudTrail to retrain models based on usage logs.",
      "D": "Use CodeBuild to poll model metrics periodically and trigger retraining manually."
    },
    "explanation": "Integrating Model Monitor with EventBridge automates retraining workflows triggered by drift detection, enabling continuous training in pipelines."
  },
  {
    "taskStatement": "3.3",
    "stem": "How can an ML engineer enforce least-privilege access controls in a CI/CD pipeline that deploys ML models using AWS services?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Grant full Admin privileges to all pipeline roles for operational simplicity.",
      "B": "Embed static IAM keys in pipeline code to restrict permissions.",
      "C": "Use IAM roles with scoped permissions, and leverage IAM role chaining or service roles for pipeline actions and SageMaker resources.",
      "D": "Rely solely on VPC network isolation to protect pipeline resources."
    },
    "explanation": "Implementing fine-grained IAM roles with specific permissions and using role assumption minimizes security risks while maintaining necessary access."
  },
  {
    "taskStatement": "3.3",
    "stem": "Which strategy minimizes downtime when deploying ML models using AWS CodeDeploy within a CI/CD pipeline?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Immediate replacement at the endpoint without pre-warming instances.",
      "B": "Blue/green deployment strategy with traffic shifting to new environments that are fully provisioned before switch-over.",
      "C": "Manual instance scaling before deployment without traffic redirection.",
      "D": "Single rollback only after failure without parallel environment."
    },
    "explanation": "Blue/green deployments provision new environments and route traffic gradually, avoiding downtime during model deployment updates."
  },
  {
    "taskStatement": "3.3",
    "stem": "How does AWS CodePipeline facilitate rollback operations for failed ML model deployments?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "By retaining previous successful pipeline executions and enabling manual or automated redeployment of prior artifacts.",
      "B": "By automatically deleting failed model versions from SageMaker Model Registry.",
      "C": "By pausing deployment indefinitely until manual intervention.",
      "D": "By rerunning the training job to attempt a better model build."
    },
    "explanation": "CodePipeline keeps artifacts from previous executions, supporting redeployments to roll back failed changes effectively."
  },
  {
    "taskStatement": "3.3",
    "stem": "What is a best practice for integrating unit tests on ML preprocessing scripts in a CI/CD pipeline?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Run unit tests only once per month outside the pipeline.",
      "B": "Include automated unit tests in CodeBuild stages to validate data transformation correctness before training.",
      "C": "Skip unit testing for preprocessing scripts because of large datasets.",
      "D": "Run unit tests post-deployment on production data manually."
    },
    "explanation": "Automating unit testing in the build phase ensures data preprocessing logic correctness before costly training and deployment steps."
  },
  {
    "taskStatement": "3.3",
    "stem": "How should an ML engineer handle artifact storage in a CI/CD pipeline for SageMaker when deploying multiple model versions?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Store all artifacts in the same S3 location, overwriting older versions.",
      "B": "Store artifacts only locally on the build server.",
      "C": "Use versioned S3 buckets or prefixes and the SageMaker Model Registry to organize and access model versions systematically.",
      "D": "Embed artifacts inside container images and discard the originals after deployment."
    },
    "explanation": "Organizing artifacts with versioning and integrating with the Model Registry enables traceability and reproducibility in deployment pipelines."
  },
  {
    "taskStatement": "3.3",
    "stem": "What is the role of Amazon EventBridge in automating ML workflows within a CI/CD pipeline?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "EventBridge routes events such as code commits or monitoring alarms to trigger subsequent pipeline steps like training or deployment.",
      "B": "EventBridge stores model artifacts during deployment.",
      "C": "EventBridge manages IAM permissions for pipeline resources.",
      "D": "EventBridge compiles and builds training code."
    },
    "explanation": "EventBridge enables event-driven automation by triggering actions in response to service events within ML pipelines."
  },
  {
    "taskStatement": "3.3",
    "stem": "Which CI/CD pipeline stage type would you configure to invoke SageMaker Pipelines containing ML workflow steps?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Source stage only supports fetching code, not workflow invocation.",
      "B": "Build stage compiles code but does not orchestrate SageMaker workflows directly.",
      "C": "Deploy stage is limited to infra provisioning.",
      "D": "Custom action invoking AWS SDK or Lambda to trigger SageMaker Pipeline executions within the pipeline."
    },
    "explanation": "To integrate SageMaker Pipelines within CodePipeline, custom actions or Lambda invocations are used to trigger ML workflows programmatically."
  },
  {
    "taskStatement": "3.3",
    "stem": "An ML engineer wants to enable automated integration testing of deployed models in a CI/CD pipeline. What is an effective method?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Wait for manual user feedback to verify model accuracy post-deployment.",
      "B": "Incorporate automated test jobs that run batch inference on test datasets and evaluate output correctness before approving deployment stages.",
      "C": "Run tests only on training data offline before deployment.",
      "D": "Use CloudWatch Logs to manually review inference output after deployment."
    },
    "explanation": "Automated integration tests validate deployed model behavior systematically within the pipeline before promoting to production."
  },
  {
    "taskStatement": "3.3",
    "stem": "How can an ML engineer securely manage pipeline credentials for third-party repositories accessed during model training?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Hardcode credentials in training script containers.",
      "B": "Distribute credentials to all developers manually.",
      "C": "Use AWS Secrets Manager to store and retrieve credentials dynamically in pipeline and training environments via IAM roles.",
      "D": "Embed credentials in environment variables without encryption."
    },
    "explanation": "Secrets Manager allows centralized, secure management of sensitive credentials with access controlled by IAM and integrated retrieval in pipeline stages."
  },
  {
    "taskStatement": "3.3",
    "stem": "What triggers an AWS CodePipeline execution in a typical SageMaker ML workflow?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "Push events or pull requests in a source control (CodeCommit, GitHub).",
      "B": "Manual button click only.",
      "C": "AWS Lambda scheduled daily without source control integration.",
      "D": "CloudWatch logs completion of model training only."
    },
    "explanation": "CI/CD pipelines commonly start automatically on source code changes or commits, enabling continuous integration and deployment."
  },
  {
    "taskStatement": "3.3",
    "stem": "In the event of failed model validation during pipeline testing, what is an appropriate automated pipeline response?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Proceed to deployment with warnings logged.",
      "B": "Manually notify engineers but continue deployment.",
      "C": "Automatically increase compute resources and retry the test.",
      "D": "Halt the pipeline execution and notify stakeholders to prevent promoting a suboptimal model."
    },
    "explanation": "Failing fast and stopping the pipeline prevents deployment of models that do not meet validation criteria, ensuring quality assurance."
  },
  {
    "taskStatement": "3.3",
    "stem": "Which mechanism in AWS CI/CD tools allows parallel execution of different ML pipeline stages for faster iteration?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Sequential chaining of CodePipeline actions only.",
      "B": "Parallel action execution within CodePipeline stages or multiple CodeBuild projects triggered simultaneously.",
      "C": "Single CodeDeploy deployment per pipeline only.",
      "D": "Manual orchestration of parallelism outside AWS services."
    },
    "explanation": "AWS CodePipeline supports parallel actions and multiple CodeBuild projects to speed up pipelines by parallelizing independent tasks."
  },
  {
    "taskStatement": "3.3",
    "stem": "Which tool helps audit and log all changes in a CI/CD ML pipeline to satisfy compliance requirements?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon CloudWatch by itself only collects logs, not audit trails.",
      "B": "AWS CloudFormation manages infrastructure but not audit logs.",
      "C": "AWS CloudTrail records all AWS API calls and user activity for auditing pipeline actions.",
      "D": "SageMaker Model Monitor tracks model data drift, not pipeline audit logs."
    },
    "explanation": "CloudTrail provides comprehensive logging of API calls and activities critical for security and compliance auditing in CI/CD pipelines."
  },
  {
    "taskStatement": "3.3",
    "stem": "How can you integrate rollback capability for SageMaker endpoint deployments in a CI/CD pipeline?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy a new model and delete the old one immediately without rollback.",
      "B": "Use manual rollback with no automation.",
      "C": "Leverage SageMaker Model Registry versions and CodePipeline stages to deploy selected model versions and revert to previous versions automatically if needed.",
      "D": "Use AWS Lambda to restart training when deployment fails."
    },
    "explanation": "Model Registry versioning combined with automated pipeline stages provides structured rollback processes for endpoint deployments."
  },
  {
    "taskStatement": "3.3",
    "stem": "How does incorporating unit and integration tests for ML pipelines impact the deployment lifecycle?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Increases deployment time without quality benefits.",
      "B": "Improves reliability by detecting defects early, preventing faulty models from reaching production.",
      "C": "Is unnecessary because ML workflows are data-driven, not code-driven.",
      "D": "Only valuable for infrastructure code, not ML code."
    },
    "explanation": "Automated testing increases confidence in ML pipeline changes, reducing production failures and downtime."
  },
  {
    "taskStatement": "3.3",
    "stem": "When deploying ML models with frequent retraining, how does CI/CD pipeline automation help manage model artifacts?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Manually store and track artifacts outside the pipeline.",
      "B": "Use only Git to version control large ML model binaries.",
      "C": "Overwrite prior artifacts in S3 to conserve storage space.",
      "D": "Automate artifact versioning in S3 and Model Registry with pipeline metadata to enable reproducibility and traceability."
    },
    "explanation": "Automated version control via pipelines ensures proper tracking and audit of models across retraining cycles."
  },
  {
    "taskStatement": "3.3",
    "stem": "What is a challenge of integrating automated CI/CD pipelines for ML with existing organizational security policies?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Lack of integration with AWS services.",
      "B": "No support for environment variables in pipelines.",
      "C": "Ensuring least privilege access while allowing necessary pipeline steps and SageMaker operations can be complex.",
      "D": "Pipelines do not support containerized deployments."
    },
    "explanation": "Balancing security policies with pipeline functionality requires careful IAM role design and enforcement to avoid over-permissioning."
  },
  {
    "taskStatement": "4.1",
    "stem": "A data scientist wants to monitor model inference in production to detect data drift and concept drift quickly. Which combination of AWS services and features should be employed to effectively monitor both data input distribution and model prediction quality?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use Amazon CloudWatch to monitor endpoint CPU utilization and latency metrics.",
      "B": "Use AWS Lambda functions to preprocess data and trigger alerts when anomalies are detected.",
      "C": "Use SageMaker Model Monitor to configure baseline data constraints and evaluation schedules, combined with SageMaker Clarify to detect bias and drift in input data and model output.",
      "D": "Configure Amazon SNS to send notifications on model inference completion."
    },
    "explanation": "SageMaker Model Monitor is designed to automatically detect data drift by comparing incoming data to a baseline dataset. Additionally, SageMaker Clarify can analyze feature importance and detect bias and drift in model outputs, providing a comprehensive monitoring framework for inference quality and performance."
  },
  {
    "taskStatement": "4.1",
    "stem": "An ML engineer notices that the real-time prediction endpoint\u2019s input data distribution is changing, causing degradation of model performance over time. What process should they implement using SageMaker Model Monitor to address this issue?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Manually review all input data and retrain the model weekly.",
      "B": "Set up SageMaker Model Monitor to create monitoring schedules that detect and alert on data drift, enabling automatic retraining pipelines when drift thresholds are exceeded.",
      "C": "Deploy a shadow endpoint to run parallel predictions without monitoring data drift.",
      "D": "Increase instance count to handle the increased load."
    },
    "explanation": "SageMaker Model Monitor can be scheduled to analyze incoming data and detect drift relative to the baseline. Alerts can trigger automated retraining pipelines to maintain model accuracy without manual intervention."
  },
  {
    "taskStatement": "4.1",
    "stem": "Which metric should be primarily monitored to detect concept drift during model inference in a classification problem?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Endpoint CPU utilization",
      "B": "Mean squared error on training data",
      "C": "Input feature distribution statistics",
      "D": "Prediction distribution changes (e.g., class label distribution or confidence scores) over time"
    },
    "explanation": "Concept drift refers to changes in the relationship between input features and the target variable. Monitoring the prediction distribution or confidence scores over time helps detect concept drift, as shifts in predicted outputs indicate the model\u2019s assumptions might no longer hold."
  },
  {
    "taskStatement": "4.1",
    "stem": "An ML engineer uses SageMaker Model Monitor but observes a high false positive rate in data quality alerts. What advanced configuration can reduce false positives while still detecting meaningful data quality issues?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Adjust threshold parameters in the monitoring job\u2019s data quality constraints to balance sensitivity and specificity.",
      "B": "Disable monitoring of low-variance features.",
      "C": "Increase the frequency of monitoring to hourly intervals.",
      "D": "Remove features from the baseline dataset."
    },
    "explanation": "Fine-tuning thresholds in SageMaker Model Monitor constraints allows the team to balance sensitivity to detect actual drift vs false positives, reducing noise while ensuring meaningful alerts are generated."
  },
  {
    "taskStatement": "4.1",
    "stem": "You deployed a multi-model endpoint in SageMaker hosting five models. How can you monitor inference data quality for each model individually?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Configure a single Model Monitor job that aggregates data across all models.",
      "B": "Use separate Model Monitor jobs with filtering based on the MODEL_NAME header or inference metadata per model.",
      "C": "Use Amazon CloudWatch metrics for the endpoint as a whole.",
      "D": "Enable automatic model logging without additional configuration."
    },
    "explanation": "For multi-model endpoints, Model Monitor can filter incoming data by model name in headers or metadata, enabling individual monitoring for data quality per model."
  },
  {
    "taskStatement": "4.1",
    "stem": "How does SageMaker Model Monitor detect data drift in streaming inference data against the baseline dataset?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "By invoking AWS Lambda functions for real-time anomaly detection.",
      "B": "By comparing sample statistics of batch data only after endpoint shutdown.",
      "C": "By using Amazon CloudWatch metrics on endpoint invocations.",
      "D": "By regularly computing statistics (e.g., mean, min/max, distribution histograms) of actual inference inputs and comparing them with baseline statistics using statistical tests."
    },
    "explanation": "Model Monitor calculates statistical summaries on inference data and compares them periodically with baseline summaries using statistical tests to detect distribution shifts indicating data drift."
  },
  {
    "taskStatement": "4.1",
    "stem": "What is the best practice to ensure model monitoring captures new features when the feature schema evolves in production?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Update the baseline dataset and monitoring constraints to include new features and redeploy the Model Monitor job.",
      "B": "Ignore new features to maintain monitoring consistency.",
      "C": "Delete previous baseline and start monitoring from scratch without historical context.",
      "D": "Use default monitoring settings with no schema updates."
    },
    "explanation": "When feature schema changes, monitoring must adapt to new features by updating the baseline dataset and constraints; otherwise, alerts may be inaccurate or missed."
  },
  {
    "taskStatement": "4.1",
    "stem": "During inference monitoring, an engineer identifies that model predictions exhibit bias against a certain subgroup after deployment. How can they validate and mitigate this bias using AWS tools?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Retrain the model on the same dataset without changes.",
      "B": "Disable inference monitoring to avoid false alerts.",
      "C": "Use SageMaker Clarify to analyze fairness and bias metrics on inference data and retrain the model with enhanced data balancing or pre-processing techniques if needed.",
      "D": "Increase endpoint capacity to reduce latency."
    },
    "explanation": "SageMaker Clarify provides fairness reports and bias detection on inference data, allowing the engineer to identify and remediate bias by data or model adjustments."
  },
  {
    "taskStatement": "4.1",
    "stem": "Which method allows you to continuously monitor and evaluate model drift without impacting the production endpoint's performance?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy a single endpoint with integrated monitoring and batch evaluation.",
      "B": "Implement a shadow endpoint that receives same input as production for offline evaluation and monitoring.",
      "C": "Increase instance types to handle both production traffic and monitoring.",
      "D": "Use CloudWatch to track endpoint invocation counts only."
    },
    "explanation": "Shadow endpoints can receive live traffic duplicated from production but do not serve user requests; they enable off-line drift detection and performance evaluation without affecting production."
  },
  {
    "taskStatement": "4.1",
    "stem": "What data collection strategy ensures SageMaker Model Monitor can detect and alert for out-of-distribution inputs during inference?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Capture all inference requests without filtering.",
      "B": "Sample only successful prediction outputs.",
      "C": "Collect only latency and CPU metrics.",
      "D": "Collect feature values and prediction outputs of inference requests and compare them against the baseline distribution."
    },
    "explanation": "To detect out-of-distribution inputs, the complete feature values and prediction outputs must be collected and compared to baseline data distributions, enabling statistical tests for anomalies."
  },
  {
    "taskStatement": "4.1",
    "stem": "An ML engineer wants to detect inference data quality problems such as missing values and invalid formats in near real-time. Which approach on AWS best supports this?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Schedule daily batch jobs using AWS Glue to validate the inference dataset.",
      "B": "Configure SageMaker Model Monitor real-time monitoring using monitoring schedules on endpoint data streams.",
      "C": "Manually review CloudWatch logs for inference errors after each deployment.",
      "D": "Implement data validation logic inside the application client."
    },
    "explanation": "SageMaker Model Monitor supports near real-time data quality monitoring by analyzing streaming endpoint invocation data with configurable schedules and alerts."
  },
  {
    "taskStatement": "4.1",
    "stem": "How does SageMaker Clarify help in monitoring models post-deployment?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "By providing insights into feature importance, bias, and drift in both training and inference data.",
      "B": "By deploying multiple models for A/B testing automatically.",
      "C": "By increasing the security of SageMaker endpoints.",
      "D": "By optimizing endpoint auto scaling policies based on traffic."
    },
    "explanation": "SageMaker Clarify is designed to detect bias and explain model predictions, supporting monitoring of fairness and drift after deployment."
  },
  {
    "taskStatement": "4.1",
    "stem": "Which of the following best practices enhances monitoring inferencing quality and reducing model degradation risks?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Disabling data quality monitoring to reduce costs.",
      "B": "Capturing only output predictions without input data for monitoring.",
      "C": "Establishing baseline data constraints, configuring monitoring schedules, and integrating automated alerting for drift and anomaly detection.",
      "D": "Relying solely on endpoint error logs to identify problems."
    },
    "explanation": "Robust monitoring requires baseline constraints, scheduled monitoring jobs, and automated alerts to detect data quality or prediction anomalies quickly."
  },
  {
    "taskStatement": "4.1",
    "stem": "An ML engineer observes high variance in model prediction confidence scores over time. Which drift type is this indicative of and what monitoring tool can capture this?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Covariate drift; monitored by CloudWatch metrics.",
      "B": "Label drift; monitored by Amazon Athena queries.",
      "C": "Prior probability shift; monitored by AWS Glue DataBrew.",
      "D": "Concept drift; monitored by SageMaker Model Monitor analyzing prediction distributions."
    },
    "explanation": "High variance in confidence scores indicates concept drift, where the input-output relationship changes; SageMaker Model Monitor tracks prediction distributions for this purpose."
  },
  {
    "taskStatement": "4.1",
    "stem": "How can a data scientist incorporate explainability into the model monitoring workflow for inference endpoints using AWS services?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use CloudWatch to log endpoint throughput and latency.",
      "B": "Integrate SageMaker Clarify explainability features to produce SHAP values and feature attribution reports during inference monitoring.",
      "C": "Enable SageMaker Neo to optimize model performance.",
      "D": "Create custom dashboards in Amazon QuickSight without underlying explainability data."
    },
    "explanation": "SageMaker Clarify can generate feature attribution explanations (e.g., SHAP values) during inference, supporting transparent model monitoring and decision-making."
  },
  {
    "taskStatement": "4.1",
    "stem": "Which configuration aspect must be considered when setting up SageMaker Model Monitor to capture inference data for monitoring?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable data capture on the deployed endpoint specifying percentage of requests to be logged and data destination S3 bucket.",
      "B": "Use CloudTrail logs exclusively to gather inference data.",
      "C": "Install custom agents on endpoint instances for data collection.",
      "D": "Configure AWS Config rules to trigger data sampling."
    },
    "explanation": "SageMaker endpoints support data capture configuration that logs inputs and/or outputs and stores them in S3 for Model Monitor analysis."
  },
  {
    "taskStatement": "4.1",
    "stem": "What is the recommended approach to monitor multiple inference endpoints with similar models to maintain consistency in data quality monitoring?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Create unique Model Monitor jobs for each endpoint with no shared baselines.",
      "B": "Disable monitoring on secondary endpoints to reduce cost.",
      "C": "Share baseline statistics and constraints across Model Monitor jobs for homogeneous endpoints while maintaining separate monitoring schedules.",
      "D": "Monitor inputs but ignore outputs for secondary endpoints."
    },
    "explanation": "Using the same baseline statistics enables consistent detection of drift across similar endpoints, while separate jobs tailor monitoring to each endpoint's data."
  },
  {
    "taskStatement": "4.1",
    "stem": "When configuring alerts for model inference monitoring, which AWS service enables notification delivery to the DevOps team for rapid response?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "Amazon Polly",
      "B": "Amazon SNS",
      "C": "Amazon Lex",
      "D": "Amazon QuickSight"
    },
    "explanation": "Amazon SNS (Simple Notification Service) allows setting up alerts from monitoring jobs that send notifications via email, SMS, or HTTP endpoints."
  },
  {
    "taskStatement": "4.1",
    "stem": "An inference endpoint is generating a high number of invalid input errors. How can AWS monitoring tools help quickly isolate which feature is causing the problem?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use SageMaker Model Monitor to analyze data quality constraints violations feature-wise to identify problematic inputs.",
      "B": "Review CloudTrail trails for API invocation anomalies.",
      "C": "Analyze EC2 instance system logs for application errors.",
      "D": "Check AWS Billing dashboard for usage spikes."
    },
    "explanation": "Model Monitor supports feature-level constraint checks (e.g., missing, out of range) that help pinpoint which input features fail validation during inference."
  },
  {
    "taskStatement": "4.1",
    "stem": "What is the effect of frequent data drift detected during inference monitoring on model maintenance strategies?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Ignore drift if prediction latency remains low.",
      "B": "Continually increase instance count to handle load.",
      "C": "Trigger more frequent model retraining and evaluation cycles to adapt to changing data distribution.",
      "D": "Disable monitoring to reduce overhead."
    },
    "explanation": "Persistent drift suggests the model no longer fits current data well and necessitates ongoing retraining or model updates to maintain accuracy."
  },
  {
    "taskStatement": "4.1",
    "stem": "When enabling SageMaker Model Monitor data capture for inferencing, what data privacy or security concerns should be addressed?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Disabling data encryption for faster performance.",
      "B": "Ensuring captured data is encrypted at rest and in transit; applying IAM policies to restrict access to captured data storage.",
      "C": "Using public S3 buckets for captured data for easy access.",
      "D": "Bypassing compliance audits since data capture is internal."
    },
    "explanation": "Data capture involves sensitive inputs and outputs; encryption and IAM policies safeguard data privacy and compliance requirements."
  },
  {
    "taskStatement": "4.1",
    "stem": "How can SageMaker Clarify complement Model Monitor in maintaining ethical AI practices post-deployment?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "By increasing endpoint auto scaling limits.",
      "B": "Providing bias detection, feature attribution, and fairness analysis capabilities for monitoring deployed models.",
      "C": "By optimizing model training speed.",
      "D": "By storing data lakes for training data."
    },
    "explanation": "Clarify aids in monitoring bias and fairness metrics in models post-deployment to ensure ethical AI standards are upheld."
  },
  {
    "taskStatement": "4.1",
    "stem": "An ML engineer is preparing to use Model Monitor to track model inference data quality. What initial step is necessary before deploying monitoring jobs?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Establish a baseline dataset with statistics and constraints representing expected data characteristics.",
      "B": "Deploy the endpoint without data capture enabled.",
      "C": "Configure CloudWatch for model latency metrics only.",
      "D": "Skip baseline creation and start monitoring immediately."
    },
    "explanation": "Baseline data enables Model Monitor to compare real-time inference data and detect deviations or drift accurately."
  },
  {
    "taskStatement": "4.1",
    "stem": "What challenge can occur if inference data used for monitoring is not representative of production traffic, and how can it be mitigated?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "The model will overfit; mitigated by reducing dataset size.",
      "B": "Alerts will trigger too frequently; mitigated by disabling monitors.",
      "C": "Inaccurate drift detection due to skewed data; mitigated by capturing a representative sample covering various use cases.",
      "D": "Increased costs; mitigated by decreasing instance count."
    },
    "explanation": "Monitoring effectiveness depends on representative inference data; capturing non-representative traffic can cause false negatives or false positives in detected drift."
  },
  {
    "taskStatement": "4.1",
    "stem": "How can you automate the remediation process upon detecting model drift or quality issues with SageMaker monitoring tools?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Manually check alerts and retrain models when notified.",
      "B": "Schedule monthly model updates regardless of alerts.",
      "C": "Increase logging verbosity to capture errors.",
      "D": "Integrate Model Monitor alerts with AWS Lambda functions or Step Functions to trigger retraining pipelines automatically."
    },
    "explanation": "Automation reduces lag in response by hooking monitoring alerts to workflows (e.g., Lambda) that retrain and redeploy models promptly."
  },
  {
    "taskStatement": "4.1",
    "stem": "Why is it important to monitor both input feature distributions and model prediction outputs during inference?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "To reduce endpoint costs significantly.",
      "B": "Because changes can occur independently: input features can drift (covariate drift) or model predictions can shift due to concept drift.",
      "C": "To avoid the need for retraining models.",
      "D": "Only prediction output monitoring is sufficient; inputs are irrelevant."
    },
    "explanation": "Monitoring both input data and predictions provides comprehensive drift detection and early warnings of degraded model performance or bias."
  },
  {
    "taskStatement": "4.1",
    "stem": "What is the impact of enabling full data capture for a high-throughput real-time SageMaker endpoint?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "No impact; SageMaker optimizes capture automatically.",
      "B": "Captured data is stored temporarily and then deleted immediately.",
      "C": "May incur significant storage costs and increased latency; recommend sampling or partial data capture.",
      "D": "Disables Model Monitor functionality."
    },
    "explanation": "Full capture of all requests can generate large volumes of data causing cost and performance issues; sampling strategies balance monitoring and overhead."
  },
  {
    "taskStatement": "4.1",
    "stem": "In a regulated industry, what steps ensure the inference monitoring process complies with data privacy and security policies?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Encrypt data in transit and at rest; restrict IAM access; anonymize sensitive data before capture.",
      "B": "Publicly share raw inference data for transparency.",
      "C": "Disable data capture to avoid privacy concerns.",
      "D": "Use default monitoring without additional security configurations."
    },
    "explanation": "Encryption, access controls, and anonymization are essential to protect sensitive data in monitoring pipelines and meet compliance."
  },
  {
    "taskStatement": "4.1",
    "stem": "An S3 bucket storing inference data for model monitoring has been accidentally deleted. What best practice should you employ next to resume monitoring without data loss?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Restart inference endpoints.",
      "B": "Manually monitor endpoints without logged data.",
      "C": "Use another S3 bucket without updating configurations.",
      "D": "Restore bucket from backup (if enabled), verify SageMaker monitoring configuration, and re-enable data capture to continue monitoring."
    },
    "explanation": "Recovering the bucket from backups, verifying monitoring settings, and re-enabling are necessary to restore continuous data capture and drift detection."
  },
  {
    "taskStatement": "4.1",
    "stem": "How does SageMaker Model Monitor support monitoring of edge device deployed models?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "By automatically collecting metrics from edge devices via CloudWatch.",
      "B": "By enabling periodic data uploads from edge devices to Amazon S3 and running batch Model Monitor jobs on these datasets.",
      "C": "By embedding Model Monitor agent in edge hardware.",
      "D": "Edge models cannot be monitored with SageMaker Model Monitor."
    },
    "explanation": "Edge devices typically upload collected data periodically; batch Model Monitor jobs analyze these uploads to detect drift or quality issues."
  },
  {
    "taskStatement": "4.1",
    "stem": "What is a limitation of SageMaker Model Monitor when monitoring asynchronous inference endpoints?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Cannot capture output data.",
      "B": "Cannot monitor multiple models simultaneously.",
      "C": "Data capture latency may delay detection due to batch processing nature.",
      "D": "Does not support any data quality constraints."
    },
    "explanation": "Asynchronous endpoints process requests in batches causing inherent delays in capturing data and generating monitoring results, imposing latency on drift detection."
  },
  {
    "taskStatement": "4.2",
    "stem": "An ML engineer is tasked with monitoring Amazon SageMaker endpoints to optimize both performance and cost. Which combination of AWS services and approaches should the engineer use to get detailed infrastructure metrics, set alerts on unusual resource usage, and analyze cost trends effectively?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use Amazon CloudWatch for metrics and AWS Config for cost analysis.",
      "B": "Use AWS X-Ray for tracing, AWS Budgets for cost alerts, and SageMaker Model Monitor for metrics.",
      "C": "Enable SageMaker Clarify, Amazon CloudTrail, and AWS Trusted Advisor for monitoring and cost visualization.",
      "D": "Use Amazon CloudWatch for resource metrics and alarms, AWS Cost Explorer and Budgets for cost analysis, and AWS CloudTrail for audit logging."
    },
    "explanation": "Amazon CloudWatch provides detailed metrics and alarm capabilities for resource monitoring. AWS Cost Explorer and Budgets offer comprehensive cost analysis and alerting. CloudTrail logs API calls and changes, which assist audits. This integrated approach provides effective monitoring and cost optimization."
  },
  {
    "taskStatement": "4.2",
    "stem": "You want to design a tagging strategy for ML resources to enable precise cost allocation and monitoring. Which of the following tagging practices will best support rightsizing and cost optimization across multiple SageMaker endpoint deployments?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use a single common tag for all endpoints to simplify billing reports.",
      "B": "Assign tags by project, environment, team, and endpoint type consistently on all resources.",
      "C": "Tag only the SageMaker endpoint resources, ignoring underlying infrastructure such as instances and storage.",
      "D": "Use autogenerated random tags to distribute cost attribution uniformly across endpoints."
    },
    "explanation": "Consistent tagging by project, environment, team, and endpoint type allows clear cost allocation and optimization insights across deployments, enabling better rightsizing recommendations."
  },
  {
    "taskStatement": "4.2",
    "stem": "During cost optimization reviews, you notice that several SageMaker endpoints provisioned with On-Demand instances are underutilized. Which purchasing option modification can effectively reduce costs without sacrificing the ability to scale?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Switch to SageMaker Savings Plans and configure auto scaling with Spot Instances when appropriate.",
      "B": "Replace all On-Demand endpoints with Reserved Instances regardless of usage patterns.",
      "C": "Use only EC2 Spot Instances without fallback to On-Demand for production endpoints.",
      "D": "Keep On-Demand instances and reduce instance sizes to the smallest available."
    },
    "explanation": "SageMaker Savings Plans reduce costs for predictable usage, while Spot Instances can be used with auto scaling to reduce costs during low usage periods. This balances cost and availability without sacrificing scalability."
  },
  {
    "taskStatement": "4.2",
    "stem": "An ML pipeline requires monitoring of infrastructure to detect latency spikes and CPU bottlenecks in real time. Which AWS tools should be integrated to provide end-to-end observability including tracing and log analytics?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon QuickSight and AWS Trusted Advisor",
      "B": "AWS X-Ray for distributed tracing and Amazon CloudWatch Logs Insights for log analytics",
      "C": "Amazon Athena and AWS Glue Data Catalog",
      "D": "AWS Compute Optimizer and AWS Config"
    },
    "explanation": "AWS X-Ray enables distributed tracing to analyze latency, while CloudWatch Logs Insights allows querying of logs for performance bottlenecks, together providing comprehensive observability."
  },
  {
    "taskStatement": "4.2",
    "stem": "You plan to use SageMaker Inference Recommender for rightsizing endpoints. What data should you provide to the Inference Recommender to achieve accurate infrastructure optimization recommendations?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Historical cost reports and billing tags",
      "B": "Endpoint CPU utilization and error rates only",
      "C": "Sample payloads, model artifacts, and representative traffic patterns",
      "D": "Only the model size and framework used"
    },
    "explanation": "Inference Recommender uses model artifacts, sample payloads, and traffic patterns to simulate inference workloads and recommend optimal instance types and configurations."
  },
  {
    "taskStatement": "4.2",
    "stem": "When monitoring SageMaker endpoint latency issues, which combination of metric dimensions should be prioritized to isolate performance bottlenecks effectively?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Instance type, model version, and invocation count",
      "B": "IAM role, submission timestamp, and VPC ID",
      "C": "CloudTrail event source and user agent",
      "D": "Endpoint name and S3 bucket name"
    },
    "explanation": "Instance type, model version, and invocation count dimensions help determine whether performance issues correlate with hardware, code changes, or workload."
  },
  {
    "taskStatement": "4.2",
    "stem": "How does enabling detailed monitoring with Amazon CloudWatch Logs and AWS CloudTrail benefit cost optimization for ML infrastructure?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Automatically reduces instance sizes based on logs alone",
      "B": "Generates instant cost saving recommendations without any manual analysis",
      "C": "Directly decreases the number of endpoint invocations",
      "D": "Provides granular insights into resource usage and API activity to inform rightsizing and capacity planning"
    },
    "explanation": "Detailed monitoring logs resource usage metrics and API activity, which enables informed decisions for rightsizing infrastructure and optimizing costs."
  },
  {
    "taskStatement": "4.2",
    "stem": "Your team wants to automate detection of idle SageMaker endpoints to reduce unnecessary charges. Which combination of AWS services and configurations will help implement this automation?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Cost Explorer with manual weekly review",
      "B": "Amazon CloudWatch alarms on invocation metrics with AWS Lambda to disable endpoints",
      "C": "SageMaker Model Monitor with Amazon S3 event triggers",
      "D": "AWS CodePipeline to redeploy endpoints monthly"
    },
    "explanation": "CloudWatch alarms detect low or zero invocations; Lambda functions can then automatically disable or scale down endpoints to reduce costs."
  },
  {
    "taskStatement": "4.2",
    "stem": "In the context of monitoring an ML infrastructure, what is a common indicator that model performance issues may be related to infrastructure bottlenecks rather than data or model bias?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Persistently high accuracy with occasional errors",
      "B": "Stable invocation count and increased model drift scores",
      "C": "Increased latency and throttling errors despite unchanged model outputs",
      "D": "Sudden drop in label distribution balance"
    },
    "explanation": "Increased latency and throttling generally indicate infrastructure stress, causing performance degradation unrelated to model quality or data bias."
  },
  {
    "taskStatement": "4.2",
    "stem": "You want to set automated scaling policies for a SageMaker real-time endpoint. Which of the following is the MOST appropriate metric to base scaling decisions on to optimize cost and latency?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "InvocationLatency (p99) or CPUUtilization",
      "B": "DiskReadOps and DiskWriteOps",
      "C": "Number of model versions in production",
      "D": "IAM role change count during inference"
    },
    "explanation": "Invocation latency (especially the 99th percentile) and CPU utilization are key indicators to trigger scaling to meet demand and optimize performance and cost."
  },
  {
    "taskStatement": "4.2",
    "stem": "You observe frequent latency spikes on a SageMaker endpoint serving batch inference, with constant CPU utilization near peak. What strategies can help optimize infrastructure cost while maintaining throughput?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Increase instance count without changing instance types",
      "B": "Switch to more powerful instances with better network bandwidth and enable batching optimization",
      "C": "Disable endpoint auto scaling and fix instance count",
      "D": "Reduce batch payload sizes without changing instance type"
    },
    "explanation": "Upgrading to instances with higher CPU and network capabilities and batching inference requests optimize resource usage and reduce latency spikes."
  },
  {
    "taskStatement": "4.2",
    "stem": "In a multi-account AWS environment, how would you effectively monitor and control costs of ML infrastructure across accounts?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Manually aggregate billing reports from each account monthly",
      "B": "Use the AWS Health Dashboard for cost tracking",
      "C": "Deploy SageMaker endpoints only in one account to reduce complexity",
      "D": "Use AWS Organizations consolidated billing with cost allocation tags and cross-account CloudWatch dashboards"
    },
    "explanation": "AWS Organizations with consolidated billing and consistent tagging enables centralized cost tracking and monitoring through aggregated dashboards."
  },
  {
    "taskStatement": "4.2",
    "stem": "Your ML workflow involves frequent model retraining. How can logging infrastructure usage during retraining help reduce overall ML costs?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "By enabling instance auto scaling for endpoints",
      "B": "By increasing training job batch sizes automatically",
      "C": "By identifying overprovisioned compute resources and optimizing training configuration",
      "D": "By automatically deleting old model versions"
    },
    "explanation": "Logging resource usage during training identifies inefficient resource allocation, enabling configuration adjustments to reduce cost without impacting performance."
  },
  {
    "taskStatement": "4.2",
    "stem": "When deploying containerized ML models on Amazon Elastic Kubernetes Service (EKS), what monitoring setup is essential to optimize costs and performance for inference serving?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "CloudTrail for IAM role auditing",
      "B": "Prometheus metrics scraping combined with CloudWatch container insights for CPU, memory, and response time analysis",
      "C": "AWS Glue for batch data transformations",
      "D": "Amazon QuickSight dashboards for financial reporting"
    },
    "explanation": "Prometheus and CloudWatch container insights provide detailed metrics from containers, essential for monitoring resource use and adapting infrastructure efficiently in EKS."
  },
  {
    "taskStatement": "4.2",
    "stem": "Which combination of metrics from Amazon CloudWatch provides the BEST indication of infrastructure health for SageMaker hosting endpoints?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Billing reports and IAM role change counts",
      "B": "S3 bucket size and Glue job duration",
      "C": "CPUUtilization, MemoryUtilization, InvocationLatency, and Invocations",
      "D": "AWS Lambda concurrent executions and error rates"
    },
    "explanation": "CPU and memory utilization reveal resource use; invocation latency and call count reflect endpoint responsiveness and traffic, together indicating health and performance."
  },
  {
    "taskStatement": "4.2",
    "stem": "AWS Compute Optimizer recommends downsizing instances for a SageMaker endpoint to reduce costs. What should you consider before applying these recommendations?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Current and projected workload patterns, latency requirements, and traffic variability",
      "B": "Model accuracy only",
      "C": "IAM policy restrictions",
      "D": "End user geographic distribution"
    },
    "explanation": "Downsizing must fit workload demand and latency requirements to avoid performance degradation despite cost savings."
  },
  {
    "taskStatement": "4.2",
    "stem": "You want to integrate real-time monitoring of SageMaker inference endpoint errors into your CI/CD pipeline. Which AWS service helps you capture such application-level logs and trigger alerts for failed invocations?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Glue",
      "B": "Amazon CloudWatch Logs with Metric Filters and Alarms",
      "C": "AWS Config",
      "D": "AWS CodePipeline"
    },
    "explanation": "CloudWatch Logs collects invocation logs; metric filters detect errors and create alarms that can trigger downstream alerts or actions in CI/CD."
  },
  {
    "taskStatement": "4.2",
    "stem": "What is the best practice when setting retention policies for Amazon CloudWatch Logs generated by ML infrastructure for cost optimization?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Never delete logs to ensure compliance",
      "B": "Retain all logs indefinitely",
      "C": "Delete logs daily to reduce costs",
      "D": "Retain logs based on compliance requirements and delete older logs that no longer add value"
    },
    "explanation": "Balancing compliance and operational needs with cost management requires setting retention that fits requirements, purging older logs to save cost."
  },
  {
    "taskStatement": "4.2",
    "stem": "To troubleshoot capacity issues causing throttling in SageMaker endpoints, which AWS tool helps diagnose whether resource limits or scaling policies are the root cause?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon CloudWatch Service Quotas monitoring",
      "B": "AWS Glue Data Catalog",
      "C": "Amazon S3 Storage Lens",
      "D": "AWS Trusted Advisor Security checks"
    },
    "explanation": "CloudWatch metrics combined with Service Quotas helps identify instance limits or quotas being exceeded and whether scaling policies are configured correctly."
  },
  {
    "taskStatement": "4.2",
    "stem": "How can combining SageMaker Inference Recommender and AWS Compute Optimizer improve cost efficiency for ML model deployments?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "By recommending new ML algorithms",
      "B": "By automatically retraining models",
      "C": "By suggesting optimal instance types and correcting overprovisioning at the infrastructure level",
      "D": "By generating synthetic data for training"
    },
    "explanation": "Inference Recommender suggests best instance types for models, and Compute Optimizer identifies underutilized resources for cost reduction, together improving infrastructure efficiency."
  },
  {
    "taskStatement": "4.2",
    "stem": "When implementing cost tracking dashboards for ML infrastructure, what data aggregation and visualization approach provides the best insights for large-scale metric analysis?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Show all raw metric data without aggregation",
      "B": "Aggregate metrics by resource tags and time intervals, then visualize trends and anomalies",
      "C": "Display only cost data from AWS Billing console",
      "D": "Filter metrics by IAM user names only"
    },
    "explanation": "Aggregating metrics by tags (project/team) and time enables meaningful trend analysis, supporting cost optimization and anomaly detection."
  },
  {
    "taskStatement": "4.2",
    "stem": "Your ML infrastructure uses SageMaker endpoints with provisioned concurrency on Lambda functions for preprocessing. What monitoring approach helps prevent unexpected surge costs effectively?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Only monitor model training jobs",
      "B": "Use AWS Trusted Advisor for endpoint scaling",
      "C": "Monitor S3 bucket sizes",
      "D": "Set CloudWatch alarms on Lambda concurrent executions and invocation rates to adjust provisioned concurrency"
    },
    "explanation": "Monitoring Lambda concurrency and invocations with alarms enables dynamic adjustment of provisioned concurrency to control costs during surges."
  },
  {
    "taskStatement": "4.2",
    "stem": "An ML engineer observes that the inference cost suddenly increased after a recent deployment of a new model version. What monitoring data and analysis steps should be prioritized to determine the cause?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Check AWS IAM logs for unauthorized usage",
      "B": "Analyze training job billing details",
      "C": "Review endpoint invocation counts, instance types used, and compare model latency before and after deployment",
      "D": "Examine S3 bucket replication configurations"
    },
    "explanation": "Increased cost is often due to higher invocation volume, more expensive instance usage, or degraded latency causing scaling; analyzing these metrics identifies the cost drivers."
  },
  {
    "taskStatement": "4.2",
    "stem": "How can partitioning monitoring data by model version and endpoint improve infrastructure maintenance and cost management?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "It increases storage costs without benefits",
      "B": "It enables targeted anomaly detection and cost allocation by specific model deployment versions",
      "C": "It complicates dashboard creation",
      "D": "It is unsupported in AWS CloudWatch"
    },
    "explanation": "Partitioning by model version/endpoints allows focused analysis of performance and cost trends, quickly identifying problematic versions or overhead causes."
  },
  {
    "taskStatement": "4.2",
    "stem": "Which approach best leverages Amazon EventBridge to automate ML infrastructure cost optimization?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Manually review monthly cost reports only",
      "B": "Use EventBridge to schedule SageMaker training",
      "C": "Trigger AWS Glue jobs based on billing reports",
      "D": "Configure EventBridge rules to detect specific CloudWatch metrics and automatically adjust resources or invoke AWS Lambda functions"
    },
    "explanation": "EventBridge can respond to performance or cost metric anomalies by triggering automated corrective actions, enabling proactive cost optimization."
  },
  {
    "taskStatement": "4.2",
    "stem": "What is a key consideration when setting scaling policies based on custom CloudWatch metrics for SageMaker endpoints to balance cost and performance?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use the highest possible threshold to avoid scaling",
      "B": "Scale only during off-business hours",
      "C": "Define thresholds that prevent oscillations and incorporate cooldown periods for scaling actions",
      "D": "Disable auto scaling during peak load"
    },
    "explanation": "Appropriate threshold and cooldown prevent frequent scaling up/down oscillations, which can be costly and cause performance instability."
  },
  {
    "taskStatement": "4.2",
    "stem": "How can Amazon QuickSight be utilized effectively in monitoring and managing ML infrastructure costs?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "QuickSight replaces CloudWatch for infrastructure metrics",
      "B": "QuickSight provides visual analytics of aggregated cost and usage data enabling interactive dashboards and drill-downs",
      "C": "QuickSight autonomously adjusts resources to reduce costs",
      "D": "QuickSight monitors only security compliance"
    },
    "explanation": "QuickSight enables rich visualization of billing and cost data aggregated from multiple sources, facilitating analysis and decision-making."
  },
  {
    "taskStatement": "4.2",
    "stem": "Your ML deployment includes models hosted on multi-container SageMaker endpoints. How should you monitor the infrastructure costs and performance at granular container-level resolution?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable CloudWatch Container Insights and create dashboards with container-level CPU, memory, and network metrics",
      "B": "Analyze only endpoint-level metrics in CloudWatch",
      "C": "Use SageMaker Model Monitor for container performance",
      "D": "Configure AWS Glue to collect container metrics"
    },
    "explanation": "CloudWatch Container Insights provides detailed metrics per container essential for understanding and optimizing costs and performance of multi-container endpoints."
  },
  {
    "taskStatement": "4.3",
    "stem": "An ML engineer wants to restrict access so only specific SageMaker training jobs can read from a particular Amazon S3 bucket containing sensitive data. What is the MOST secure and scalable method to achieve this?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Attach S3 Bucket policies granting read access to all SageMaker service roles.",
      "B": "Embed S3 access keys in training job scripts to authenticate requests.",
      "C": "Create an IAM role granting S3 read access and associate it exclusively with the SageMaker training jobs.",
      "D": "Use resource-based policies on the training jobs to allow access to the S3 bucket."
    },
    "explanation": "The secure and scalable approach is to create an IAM role with least privilege for S3 read and associate it with SageMaker training jobs. This avoids embedding credentials or broad bucket policies exposing data to all SageMaker resources."
  },
  {
    "taskStatement": "4.3",
    "stem": "Which IAM policy element ensures that an Amazon SageMaker endpoint can ONLY be accessed from within a specific VPC subnet?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Condition with `StringEquals` on `aws:sourceVpce`.",
      "B": "Condition with `StringEquals` on `aws:SourceVpc` or `aws:sourceIp` corresponding to subnet CIDR.",
      "C": "Principal element attached directly to VPC subnet resource.",
      "D": "Allow action only for SageMaker endpoint ARN without conditions."
    },
    "explanation": "IAM policies often enforce network-level restrictions using the `Condition` block with keys like `aws:SourceVpc` or by limiting based on source IP addresses mapped to subnet CIDR blocks."
  },
  {
    "taskStatement": "4.3",
    "stem": "You need to audit access to SageMaker training jobs and their associated resources for compliance. Which AWS service combination should you use to capture detailed, immutable logs with minimal impact on training performance?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable AWS CloudTrail data events for SageMaker and S3, storing logs in an encrypted S3 bucket.",
      "B": "Configure Amazon CloudWatch Logs to capture API calls directly from SageMaker training jobs.",
      "C": "Use AWS Config rules to record all SageMaker activity and resource configurations.",
      "D": "Enable VPC Flow Logs on the SageMaker VPC to monitor all traffic to training instances."
    },
    "explanation": "CloudTrail data events capture detailed API-level logs including data plane operations with minimal performance impact and are best suited for compliance auditing."
  },
  {
    "taskStatement": "4.3",
    "stem": "When designing a CI/CD pipeline for ML model deployment with AWS CodePipeline and SageMaker, how should you securely provide pipeline stages permission to deploy new model versions to SageMaker endpoints?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Store SageMaker credentials in plain text in pipeline environment variables.",
      "B": "Use a fixed IAM user\u2019s access keys embedded in pipeline scripts.",
      "C": "Authorize pipeline stages with root account permissions for convenience.",
      "D": "Create and assign IAM roles with the least privilege scoped to pipeline stages to access SageMaker."
    },
    "explanation": "Security best practice mandates using IAM roles with least privilege for automation, avoiding hardcoded credentials or root account usage."
  },
  {
    "taskStatement": "4.3",
    "stem": "A security audit reveals that a SageMaker notebook instance's IAM role has overly broad permissions allowing access to unrelated S3 buckets. What is the BEST remediation approach?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Delete and recreate the notebook instance with a new role having default permissions.",
      "B": "Adjust the IAM role's policy to grant access ONLY to the specific S3 buckets the notebook requires.",
      "C": "Move the data to a new bucket with public read-only access to reduce complexity.",
      "D": "Enable Amazon Macie to monitor bucket access from the notebook instance."
    },
    "explanation": "Reducing permissions by narrowing the IAM role policy scope to required buckets follows the principle of least privilege and directly addresses the audit concern."
  },
  {
    "taskStatement": "4.3",
    "stem": "Which strategy provides the MOST secure way to isolate network access to SageMaker endpoints serving sensitive models?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy endpoints with public internet access and implement token-based authentication.",
      "B": "Deploy endpoints within a VPC and control access via security groups and VPC endpoints.",
      "C": "Use default SageMaker endpoints without network controls but rely on IAM authentication only.",
      "D": "Configure endpoint access with a simple HTTP basic authentication proxy."
    },
    "explanation": "Deploying endpoints within a VPC with security groups and interface VPC endpoints ensures network isolation and secure communication without exposing endpoints publicly."
  },
  {
    "taskStatement": "4.3",
    "stem": "You want to ensure that a SageMaker model can only be deployed by your approved CI/CD pipeline and no other user or process. How can you enforce this restriction using IAM?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use IAM resource policies to allow deployment actions only when called by the pipeline\u2019s assumed role principal.",
      "B": "Allow all authenticated users to deploy but audit deployments extensively.",
      "C": "Set SageMaker bucket policies restricting uploads to pipeline users only.",
      "D": "Use IP address conditions to restrict deployment to a corporate office."
    },
    "explanation": "IAM resource policies conditionally allow resource actions only by entities (roles) matching the pipeline, enforcing strict deployment control."
  },
  {
    "taskStatement": "4.3",
    "stem": "A model deployed on SageMaker needs to access sensitive credentials during inference securely. What is the recommended approach to manage these credentials?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Hardcode credentials within model container environment variables.",
      "B": "Store credentials on the notebook instance and fetch at runtime.",
      "C": "Use IAM roles with temporary credentials provided via the SageMaker execution environment and AWS Secrets Manager.",
      "D": "Embed credentials directly into the model artifact."
    },
    "explanation": "Assigning IAM roles to the endpoint to grant temporary credentials combined with Secrets Manager for secure secrets storage ensures best practice security without hardcoding."
  },
  {
    "taskStatement": "4.3",
    "stem": "An administrator wants to enforce encryption of all SageMaker training data in transit and at rest by default without manual configuration. How can this policy be implemented at the AWS account level?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Train users to always enable encryption options manually in SageMaker UI.",
      "B": "Apply encryption only to specific SageMaker notebook instances.",
      "C": "Use resource tagging to track encrypted resources and inform admins manually.",
      "D": "Create a Service Control Policy (SCP) within AWS Organizations denying non-encrypted data storage and transmission actions globally."
    },
    "explanation": "SCPs offer centralized control to enforce encryption compliance across accounts, preventing any actions that do not meet encryption requirements."
  },
  {
    "taskStatement": "4.3",
    "stem": "What is the MOST secure method to enable a SageMaker endpoint to securely access a private Docker container stored in Amazon Elastic Container Registry (ECR)?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Embed ECR authentication tokens in the container at build time.",
      "B": "Assign an IAM role to the SageMaker endpoint that grants permissions to pull images from ECR.",
      "C": "Make the ECR repository public temporarily during deployment.",
      "D": "Copy container images from ECR to the SageMaker endpoint storage manually."
    },
    "explanation": "Assigning an IAM role to SageMaker endpoint with ECR pull permissions follows security best practice without exposing credentials or making repositories public."
  },
  {
    "taskStatement": "4.3",
    "stem": "You want to detect unauthorized access and anomalous API calls to your SageMaker resources. Which configuration BEST enables you to do this?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable AWS CloudTrail with event logging for SageMaker API and integrate with Amazon GuardDuty for threat detection.",
      "B": "Set up SageMaker Model Monitor to monitor inference data only.",
      "C": "Create AWS Config rules for resource configuration compliance.",
      "D": "Rely on manual log reviews of SageMaker CloudWatch metrics daily."
    },
    "explanation": "CloudTrail logs API activity enabling audit trails; GuardDuty analyzes logs to detect threats in near real time, making this combination effective for security monitoring."
  },
  {
    "taskStatement": "4.3",
    "stem": "How can you restrict SageMaker Ground Truth labeling jobs so they only access specific datasets and do not leak data?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use default Ground Truth roles without modification.",
      "B": "Allow Ground Truth to access all datasets in the account for flexibility.",
      "C": "Create a dedicated IAM role scoped with least privilege to specific S3 buckets and datasets for labeling jobs.",
      "D": "Use network ACLs to block all dataset access except on labeling job instances."
    },
    "explanation": "Granting least privilege access via a dedicated IAM role scoped to only required buckets is the secure method to prevent data leakage."
  },
  {
    "taskStatement": "4.3",
    "stem": "An ML engineer tries to deploy a SageMaker endpoint inside a VPC but receives errors related to inability to pull container images from Amazon ECR. What is the MOST likely cause?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "The SageMaker endpoint\u2019s IAM role lacks ECR pull permissions.",
      "B": "The KMS key for encrypting the container images is misconfigured.",
      "C": "The container image is not compatible with SageMaker runtime.",
      "D": "No VPC endpoints for Amazon ECR exist, so the endpoint cannot access public ECR repositories from inside the VPC."
    },
    "explanation": "When deploying inside a VPC without internet access, ECR requires either VPC endpoints or NAT gateways for container image pulling."
  },
  {
    "taskStatement": "4.3",
    "stem": "Which practices help prevent privilege escalations in IAM roles used for SageMaker pipelines?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Allow all actions for SageMaker services to avoid workflow failures.",
      "B": "Grant roles only necessary permissions for pipeline steps and avoid IAM policy chaining or delegation.",
      "C": "Use a single administrative role for all pipeline activities to simplify management.",
      "D": "If debugging is needed, temporarily allow admin permissions then remove after issues."
    },
    "explanation": "Following least privilege and avoiding complex IAM chaining or delegation reduces attack surfaces and prevents escalating privileges."
  },
  {
    "taskStatement": "4.3",
    "stem": "What is a security best practice for storing AWS access credentials used during SageMaker model training in automated workflows?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Save credentials inside training script source code in Git repositories.",
      "B": "Distribute long-term credentials embedded in container images.",
      "C": "Use IAM roles for EC2 or SageMaker training jobs to obtain temporary credentials dynamically.",
      "D": "Manually refresh static credentials every six months."
    },
    "explanation": "IAM roles provide temporary, automatically rotated credentials at runtime and avoid static credential exposure."
  },
  {
    "taskStatement": "4.3",
    "stem": "You want to monitor and audit all invocations to SageMaker endpoints but want to avoid modifying endpoint code. Which native AWS feature provides this capability MOST efficiently?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable Amazon CloudWatch Logs integration for SageMaker endpoints to capture invocation logs.",
      "B": "Configure SageMaker endpoints to send logs to Amazon S3 directly.",
      "C": "Implement custom logging inside model container code for every inference.",
      "D": "Use AWS Config rules to detect invocation patterns."
    },
    "explanation": "CloudWatch Logs integration for SageMaker endpoints captures invocation and infrastructure logs without code changes, enabling central audit and monitoring."
  },
  {
    "taskStatement": "4.3",
    "stem": "A SageMaker pipeline requires access to multiple AWS services securely during execution. How should you architect the pipeline's permission management?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use a single, broad permission IAM role for all pipeline activities across services.",
      "B": "Assign distinct IAM roles with scoped permissions to each pipeline step using role assumption.",
      "C": "Grant pipeline owner user full admin permissions to simplify access.",
      "D": "Embed AWS credentials directly inside pipeline scripts."
    },
    "explanation": "Assigning scoped roles per pipeline step limits blast radius and follows least privilege, enhancing security and manageability."
  },
  {
    "taskStatement": "4.3",
    "stem": "How does AWS Secrets Manager improve the security of ML workflows compared to hardcoding secrets in environment variables?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "By automatically encrypting environment variables on startup.",
      "B": "By restricting secrets access to only EC2 metadata service.",
      "C": "By requiring manual secret rotation every month.",
      "D": "By securely storing, encrypting, rotating secrets and enabling controlled retrieval via IAM policies."
    },
    "explanation": "Secrets Manager provides secure encrypted storage with automatic rotation and fine-grained access control, reducing secret exposure risk."
  },
  {
    "taskStatement": "4.3",
    "stem": "What is a key security consideration when enabling SageMaker notebook instance internet access for data scientists?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Ensure the notebook uses the latest SageMaker container image only.",
      "B": "Assign the notebook the AdministratorAccess IAM policy for simplicity.",
      "C": "Use VPC security groups to restrict outbound traffic and enable notebook proxy configurations to control access.",
      "D": "Disable all encryption on notebooks for better performance."
    },
    "explanation": "Limiting network traffic through security groups and proxies reduces risk of accidental data leaks or malicious external connections from notebooks."
  },
  {
    "taskStatement": "4.3",
    "stem": "You need to ensure that only authorized users can create or delete SageMaker models and endpoints. Which method BEST enforces this?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use resource policies on model artifacts to restrict operations.",
      "B": "Apply IAM policies with explicit Deny on create/delete actions to unauthorized principals.",
      "C": "Rely on network ACLs to block users from API endpoints.",
      "D": "Control access only via tagging SageMaker resources."
    },
    "explanation": "IAM policies with explicit deny on critical actions provide strong access control at API operation level, preventing unauthorized user actions."
  },
  {
    "taskStatement": "4.3",
    "stem": "What approach is recommended to secure SageMaker model registry artifacts when auditing compliance?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable encryption at rest using AWS KMS and restrict access to the registry via IAM policies.",
      "B": "Store models in unencrypted S3 buckets for performance.",
      "C": "Allow all ML engineers to access registered models for collaboration.",
      "D": "Disable monitoring of model registry access due to cost concerns."
    },
    "explanation": "Encrypting at rest and applying least privilege access control ensures registry artifacts' confidentiality and integrity under audit requirements."
  },
  {
    "taskStatement": "4.3",
    "stem": "While deploying a multi-container SageMaker endpoint on a private subnet, you encounter timeouts fetching model artifacts from S3. What is the MOST secure fix?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Modify the endpoint to be publicly accessible to fetch artifacts.",
      "B": "Use an S3 bucket policy to allow public read access temporarily.",
      "C": "Manually copy model artifacts to local endpoint storage before deployment.",
      "D": "Create a VPC Gateway Endpoint for S3 to enable private, secure access from the endpoint\u2019s subnet."
    },
    "explanation": "VPC Gateway Endpoints for S3 allow private communication inside the VPC without internet access, providing secure and scalable access."
  },
  {
    "taskStatement": "4.3",
    "stem": "Which IAM policy condition key can restrict access to SageMaker resources based on time of day?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "aws:ResourceTag",
      "B": "aws:CurrentTime",
      "C": "aws:RequestTag",
      "D": "aws:SourceIp"
    },
    "explanation": "The `aws:CurrentTime` condition key can be used to allow or deny actions based on the time when the request is made, enabling time-based access control."
  },
  {
    "taskStatement": "4.3",
    "stem": "How can you restrict outgoing network traffic from SageMaker training jobs to only approved IP addresses?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Configure SageMaker notebook proxy settings.",
      "B": "Set IAM permissions to block internet access.",
      "C": "Deploy training jobs in a VPC and use security groups and network ACLs to restrict egress connections.",
      "D": "Disable internet access via SageMaker console settings."
    },
    "explanation": "Placing training jobs in VPC allows applying network controls (security groups, ACLs) for egress filtering, which IAM cannot enforce for network traffic."
  },
  {
    "taskStatement": "4.3",
    "stem": "Which method best secures access to Amazon Elastic File System (EFS) used by SageMaker training jobs for sensitive data?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use NFSv3 protocol with default EFS settings openly accessible.",
      "B": "Restrict EFS mount targets within a VPC and configure security groups to limit mount access to only authorized instances.",
      "C": "Store unencrypted data on EFS with open inbound NFS ports.",
      "D": "Configure EFS as publicly accessible via internet gateway."
    },
    "explanation": "EFS is secured by restricting mount target access to authorized VPC subnets and using security groups to limit network access, protecting sensitive data."
  },
  {
    "taskStatement": "4.3",
    "stem": "Your organization requires immutability and CloudTrail logging for all SageMaker model artifacts stored in S3. Which combination of settings supports this requirement?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable S3 Object Lock with compliance mode for artifacts' bucket and CloudTrail data event logging for write operations.",
      "B": "Rely on manual logs maintained by ML engineers.",
      "C": "Encrypt artifacts and use versioning without Object Lock.",
      "D": "Use an external logging system to track changes separately."
    },
    "explanation": "S3 Object Lock compliance mode enforces immutability; CloudTrail data events track API write calls, fulfilling audit and compliance needs."
  },
  {
    "taskStatement": "4.3",
    "stem": "Which principal of least privilege is demonstrated by granting only specific SageMaker roles permission to see AWS Secrets Manager secrets?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Granting all users read access to simplify operations.",
      "B": "Assigning admin permissions to roles for maximum flexibility.",
      "C": "Sharing secrets manually after identity verification.",
      "D": "Restricting secrets access through IAM policies scoped narrowly to only necessary roles."
    },
    "explanation": "Least privilege means granting minimal necessary access; restricting Secrets Manager permissions per role limits exposure."
  },
  {
    "taskStatement": "4.3",
    "stem": "When configuring VPC security groups for SageMaker notebook instances, which port should you typically restrict to enhance security?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "Port 22 (SSH)",
      "B": "Port 443 (HTTPS)",
      "C": "Port 8080 (application HTTP)",
      "D": "Port 3306 (MySQL)"
    },
    "explanation": "Restricting SSH port (22) access reduces attack surface as SSH isn't typically needed through the VPC security group for SageMaker notebooks."
  },
  {
    "taskStatement": "4.3",
    "stem": "For SageMaker training on sensitive data, what encryption feature should be enabled to protect data handled during training?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable encryption of EBS volumes attached to the training instances.",
      "B": "Store training data unencrypted in S3 for performance.",
      "C": "Disable encryption to speed up training time.",
      "D": "Only encrypt data after training completes."
    },
    "explanation": "Encrypting attached EBS volumes protects data at rest on training instances during the entire training lifecycle, fulfilling security requirements."
  },
  {
    "taskStatement": "4.3",
    "stem": "Which AWS service logs would you use to detect failed or unauthorized attempts to assume roles linked with SageMaker execution?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon CloudWatch Logs",
      "B": "AWS Config logs",
      "C": "AWS CloudTrail",
      "D": "AWS Trusted Advisor reports"
    },
    "explanation": "CloudTrail records IAM role assumptions and authorization failures, enabling detection of unauthorized role access attempts."
  },
  {
    "taskStatement": "4.3",
    "stem": "You notice that unauthorized IP addresses are accessing your SageMaker endpoints despite VPC restrictions. Which misconfiguration might be causing this?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "IAM policies are too permissive for endpoint access.",
      "B": "Endpoints are deployed with public access enabled instead of VPC-only mode.",
      "C": "Security groups are too restrictive.",
      "D": "CloudTrail is disabled on the account."
    },
    "explanation": "Deploying SageMaker endpoints with public access ignores VPC restrictions, allowing external IPs access."
  },
  {
    "taskStatement": "4.3",
    "stem": "What must you configure to restrict a CI/CD pipeline\u2019s CodeBuild project to access only SageMaker models and deployments in a specific AWS region?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Restrict user permissions in the AWS console.",
      "B": "Use AWS Organizations SCP to block other regions globally.",
      "C": "Set VPC peering only with the SageMaker service endpoint.",
      "D": "Add an IAM condition to the CodeBuild role restricting resource ARNs by region prefix."
    },
    "explanation": "IAM conditions using resource ARN patterns can limit access regionally, restricting the CodeBuild role as requested."
  },
  {
    "taskStatement": "4.3",
    "stem": "An ML engineer must prevent logs from leaking sensitive information during SageMaker pipeline execution. Which approach helps minimize exposure?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Mask or filter sensitive data prior to logging and restrict CloudWatch Logs access via IAM.",
      "B": "Disable all logging for cost savings.",
      "C": "Allow all engineers full CloudWatch Logs access for troubleshooting.",
      "D": "Store logs in unencrypted S3 buckets for easy access."
    },
    "explanation": "Masking sensitive log data and limiting IAM access to logs preserves privacy and security compliance while supporting troubleshooting."
  }
]