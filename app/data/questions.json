[
  {
    "taskStatement": "1.1",
    "stem": "A company processes IoT sensor data streams at 200 MB/s for ML feature engineering. The data arrives in JSON format and must be ingested into SageMaker Data Wrangler in near-real time. The ingestion solution must minimize operational overhead and storage costs while enabling efficient downstream transformations. Which solution meets these requirements?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy Amazon Kinesis Data Streams to buffer JSON records. Configure an AWS Lambda function to batch and convert records into Parquet, then write to S3. Use Data Wrangler to read from S3.",
      "B": "Use Amazon Kinesis Data Firehose to ingest JSON data directly into an S3 bucket with Parquet conversion and GZIP compression. Configure Data Wrangler to read from that S3 bucket.",
      "C": "Set up an Amazon Managed Streaming for Apache Kafka cluster. Use Kafka Connect to stream data into an Amazon Redshift table. Use Data Wrangler to query Redshift.",
      "D": "Ingest streams into an AWS Glue Streaming ETL job. Write output to Amazon DynamoDB. Use Data Wrangler to fetch items from DynamoDB."
    },
    "explanation": "Kinesis Data Firehose natively converts JSON to Parquet with compression and writes to S3, minimizing operational overhead and cost. The other options add complexity or incur higher cost/management burden."
  },
  {
    "taskStatement": "1.1",
    "stem": "A dataset consists of structured CSV transaction logs, semi-structured JSON user event logs, and tens of millions of small binary image files. The ML pipeline uses Spark on EMR for preprocessing and SageMaker for training. The dataset has grown to multi-terabyte scale and ingestion performance is suffering. Which storage configuration should the ML engineer choose to optimize throughput, cost, and simplicity?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Store CSV and JSON in S3. Store images in Amazon FSx for Lustre mounted to EMR. Use Spark on EMR to read both sources.",
      "B": "Import all data into Amazon Redshift with Spectrum. Store CSV/JSON in tables, images as BLOBs. UNLOAD data for SageMaker training.",
      "C": "Store all data in Amazon S3 as partitioned, SNAPPY-compressed Parquet files. Configure EMR to read via the S3A connector and SageMaker to use S3 input mode.",
      "D": "Use Amazon EFS to store all raw files. Mount EFS to EMR clusters and SageMaker training jobs as a unified data source."
    },
    "explanation": "Partitioned Parquet on S3 offers cost-effective, high-throughput storage, simple management, and native support in Spark and SageMaker. FSx adds cost/ops, Redshift BLOBs and Spectrum incur complexity, and EFS suffers lower throughput and higher cost for large-scale data."
  },
  {
    "taskStatement": "1.1",
    "stem": "An ML engineer runs a SageMaker processing job to merge and feature-engineer 50 million small JSON files in Amazon S3. The job fails due to S3 request throttling from excessive LIST and GET operations. Which solution will reduce operational overhead and ensure reliable job completion?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Configure a VPC endpoint for S3 in the SageMaker processing job to reduce throttling. Increase parallelism to maximize throughput.",
      "B": "Enable S3 Transfer Acceleration on the bucket to speed up GET requests. Use the Transfer Acceleration endpoint in the processing job.",
      "C": "Use AWS Glue to run a job that aggregates the small JSON files into larger SNAPPY-compressed Parquet files in S3. Update the SageMaker processing job to read the Parquet files.",
      "D": "Copy all JSON files to an Amazon EFS file system using AWS DataSync. Configure the SageMaker processing job to read directly from EFS."
    },
    "explanation": "Aggregating small files into larger Parquet files reduces S3 request count and improves throughput with minimal ongoing operations. VPC endpoints and Transfer Acceleration do not change S3 request rate limits; EFS adds complexity and cost."
  },
  {
    "taskStatement": "1.2",
    "stem": "An ML engineer needs to encode a high-cardinality categorical feature (10 000 unique values) for a tree-based model. They must minimize memory footprint, avoid one-hot explosion, and preserve ordering where meaningful. Which approach and AWS tool should they use?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use one-hot encoding in SageMaker Data Wrangler to produce sparse binary columns.",
      "B": "Use label encoding in AWS Glue DataBrew to assign integer codes to categories.",
      "C": "Use binary encoding in SageMaker Data Wrangler to compress categories into \u2308log\u2082(10000)\u2309 binary features.",
      "D": "Use frequency encoding in an AWS Glue ETL job to replace each category with its occurrence count."
    },
    "explanation": "Binary encoding (also called bit hashing) reduces dimensionality to \u2308log\u2082(n)\u2309 columns and preserves some ordinal information. SageMaker Data Wrangler supports a built-in binary encoding transform, minimizing memory and avoiding one-hot explosion."
  },
  {
    "taskStatement": "1.2",
    "stem": "A data scientist is building a cleaning pipeline in SageMaker Data Wrangler for a numerical dataset with extreme outliers and missing values. They need to: (1) cap outliers at the 1st and 99th percentiles, (2) impute remaining missing values with the column median, and (3) standardize features to zero mean and unit variance. Which sequence of Wrangler nodes achieves this with minimal custom code?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Standardize \u2192 percentile clip \u2192 median impute",
      "B": "Median impute \u2192 percentile clip \u2192 standardize",
      "C": "Percentile clip \u2192 median impute \u2192 standardize",
      "D": "Median impute \u2192 standardize \u2192 percentile clip"
    },
    "explanation": "Clipping outliers first avoids imputing capped values. Next, median imputation handles any remaining missing data. Finally, standardization yields zero mean/unit variance on the cleaned data."
  },
  {
    "taskStatement": "1.2",
    "stem": "A real-time recommendation engine requires streaming user events from Kinesis Data Streams to be transformed (JSON flattening, type conversion) and ingested into SageMaker Feature Store with under-second latency. Which solution minimizes operational overhead and meets latency SLAs?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Implement an AWS Lambda function triggered by Kinesis Data Streams that transforms each record and calls the SageMaker Feature Store PutRecord API.",
      "B": "Run an AWS Glue streaming ETL job on Kinesis Data Streams with PySpark to transform and write directly to Feature Store.",
      "C": "Deploy an Apache Flink application on Amazon EMR to consume Kinesis, perform transformations, write to S3, then batch-load into Feature Store.",
      "D": "Use Amazon Kinesis Data Analytics (Flink SQL) to transform the stream and send to a SageMaker Batch Transform job for periodic ingestion."
    },
    "explanation": "A Lambda function on Kinesis provides sub-second processing with minimal infrastructure to manage. It can call PutRecord directly. Glue streaming and EMR/Flink introduce greater complexity and latency; Batch Transform cannot meet real-time SLAs."
  },
  {
    "taskStatement": "1.3",
    "stem": "A health-tech startup has a dataset in Amazon S3 with PII fields (names, SSNs) and binary labels. They must prepare the data for SageMaker training by removing or masking PII, validating data quality, computing pre-training bias metrics (class imbalance, difference in proportions), and mitigating identified bias before training. Which sequence of AWS services and actions fulfills these requirements with minimal operational overhead?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use Amazon Macie to discover PII \u2192 apply client-side KMS encryption \u2192 run a SageMaker Processing job with a custom script to compute bias metrics.",
      "B": "Use AWS Glue Data Quality to profile dataset \u2192 use AWS Glue ETL to anonymize PII \u2192 run SageMaker Model Monitor to compute pre-training bias metrics.",
      "C": "Use SageMaker Ground Truth to label PII columns \u2192 use SageMaker Data Wrangler to transform data \u2192 use SageMaker Clarify ModelBias to compute post-training bias.",
      "D": "Use SageMaker Data Wrangler to detect and mask PII with built-in transforms \u2192 launch a SageMaker Clarify DataBias job to calculate pre-training CI and DPL metrics \u2192 apply synthetic oversampling for the minority class via Data Wrangler or a SageMaker Processing job."
    },
    "explanation": "Option D leverages Data Wrangler\u2019s built-in PII masking, uses Clarify\u2019s DataBias monitoring to compute pre-training bias metrics, and then mitigates imbalance via a native transform or Processing job, minimizing custom code and meeting compliance and bias-mitigation requirements."
  },
  {
    "taskStatement": "1.3",
    "stem": "During preprocessing, an ML engineer discovers a significant class imbalance: one protected class comprises only 1% of the training data. They need to generate additional synthetic samples for that class without introducing label noise and then validate the augmented dataset\u2019s quality. Which approach aligns best with AWS-recommended bias mitigation and data validation practices?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use SageMaker Clarify\u2019s synthetic data generator to produce minority-class examples and merge with original data.",
      "B": "Launch a SageMaker Processing job that uses scikit-learn\u2019s SMOTE to create synthetic minority-class samples, then run AWS Glue Data Quality jobs to validate data integrity.",
      "C": "Use AWS Glue DataBrew\u2019s \u201cGenerate rows\u201d transform to duplicate minority-class records until balance is achieved.",
      "D": "Ingest data into SageMaker Feature Store and use record augmentation in Feature Store to rebalance classes."
    },
    "explanation": "Option B applies SMOTE in a managed Processing job to generate realistic synthetic samples for the minority class, then validates the augmented dataset with Glue Data Quality, aligning with best practices for bias mitigation and data integrity."
  },
  {
    "taskStatement": "1.3",
    "stem": "An ML engineer must deliver preprocessed, bias-mitigated training data to a SageMaker training job. The data must be encrypted at rest and in transit, and the training dataset split must be stratified by a protected attribute to avoid introducing bias. How should the engineer configure the data pipeline to meet these requirements?",
    "correct": "D",
    "difficulty": "HARD",
    "answers": {
      "A": "Store the CSVs in S3 with SSE-S3 encryption, use File input mode in SageMaker training, and rely on built-in random shuffle for splits.",
      "B": "Provision an encrypted FSx for Lustre file system, copy preprocessed files there, and configure the training job with File mode and a JSON split manifest.",
      "C": "Mount an encrypted Amazon EFS volume in the training container, copy data via a Processing job that shuffles and splits, then train using File mode.",
      "D": "Store preprocessed data in S3 with SSE-KMS encryption, use Pipe input mode for the training job, and implement a stratified shuffle-and-split routine inside the training container to ensure splits respect the protected attribute."
    },
    "explanation": "Option D ensures end-to-end encryption with SSE-KMS, leverages Pipe mode to stream data efficiently, and uses a custom stratified shuffle-and-split routine in the container to maintain fairness across protected groups."
  },
  {
    "taskStatement": "2.1",
    "stem": "A fintech company is building a credit-scoring model to classify loan applicants as high or low risk. The dataset consists of 1 million rows of structured tabular data with a mix of numerical and categorical features of moderate cardinality. Regulatory requirements mandate that the model be highly interpretable for audit, and the application demands low-latency inference. Data scientists want to minimize manual feature engineering. Which SageMaker built-in algorithm should the ML engineer choose?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use the XGBoost built-in algorithm with default hyperparameters.",
      "B": "Use the Factorization Machines built-in algorithm to capture feature interactions.",
      "C": "Use the Linear Learner built-in algorithm configured for logistic regression.",
      "D": "Use the K-Nearest Neighbors built-in algorithm for classification."
    },
    "explanation": "Linear Learner in logistic regression mode provides a fully interpretable model with low inference latency and minimal feature engineering. XGBoost offers higher accuracy but less interpretability. Factorization Machines capture interactions but are harder to audit. KNN has high latency and is not suited for large datasets."
  },
  {
    "taskStatement": "2.1",
    "stem": "A legal analytics startup needs to automate abstractive summarization of large contract documents. The team lacks expertise in training sequence-to-sequence models and requires a fully managed, high-quality solution that supports few-shot prompting. Which modeling approach should the ML engineer select?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use Amazon Comprehend\u2019s extractive summarization API on the contracts.",
      "B": "Fine-tune a T5 sequence-to-sequence model on SageMaker using the Hugging Face framework from JumpStart.",
      "C": "Invoke a foundation model via Amazon Bedrock (for example, Titan) with a prompt template for abstractive summarization.",
      "D": "Build a custom TensorFlow sequence-to-sequence model from scratch on SageMaker training instances."
    },
    "explanation": "Amazon Bedrock provides managed foundation models that excel at few-shot abstractive summarization with minimal ML expertise. Comprehend only supports extractive summarization. Fine-tuning on SageMaker or building from scratch incurs significant development and infrastructure overhead."
  },
  {
    "taskStatement": "2.1",
    "stem": "An industrial IoT provider collects streaming time-series sensor data from thousands of devices and needs to detect anomalies in near real time. The provider wants a fully managed service requiring minimal ML development and configuration. Which AWS service or approach should the ML engineer choose?",
    "correct": "C",
    "difficulty": "EASY",
    "answers": {
      "A": "Train and deploy a Random Cut Forest (RCF) model on SageMaker for anomaly detection.",
      "B": "Develop and train a custom LSTM-based anomaly detector on SageMaker using TensorFlow.",
      "C": "Use Amazon Lookout for Metrics to automatically detect anomalies in the time-series data.",
      "D": "Use the anomaly-detection recipe in SageMaker Studio JumpStart and deploy the generated pipeline."
    },
    "explanation": "Amazon Lookout for Metrics is a fully managed anomaly-detection service that automatically tracks time-series metrics with minimal configuration. Training an RCF or LSTM on SageMaker requires substantial ML development and ongoing maintenance. JumpStart recipes simplify development but still require managing model training and pipelines."
  },
  {
    "taskStatement": "2.2",
    "stem": "An ML engineer previously ran a hyperparameter tuning job on a deep learning model and wants to optimize a new tuning job by reusing the results of that earlier job. Additionally, to reduce overall training cost and time, the engineer needs to automatically stop underperforming training jobs during tuning. Which configuration will meet these requirements?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Run a new hyperparameter tuning job using BayesianOptimization search, with MaxNumberOfTrainingJobs set to 100, and leave EarlyStoppingType unset.",
      "B": "Run a warm start tuning job with type TRANSFER_LEARNING and disable early stopping to leverage prior results only.",
      "C": "Run a warm start hyperparameter tuning job with type IDENTICAL_DATA_AND_ALGORITHM and set EarlyStoppingType to Auto.",
      "D": "Run a random search tuning job with MaxNumberOfTrainingJobs set to 50 and enable EarlyStoppingType to OfflineStopping."
    },
    "explanation": "A warm start of type IDENTICAL_DATA_AND_ALGORITHM reuses prior tuning results for the same algorithm and search space, and setting EarlyStoppingType to Auto applies SageMaker\u2019s median stopping rule to halt underperforming jobs early."
  },
  {
    "taskStatement": "2.2",
    "stem": "A data scientist has fine-tuned a 2 GB PyTorch BERT model for text classification on a GPU instance. The model must now be deployed to a CPU-based inference endpoint with a memory footprint below 500 MB while maintaining at least 95% of its original accuracy. Which approach best meets these requirements with the least development effort?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Export the model to ONNX, write custom quantization code to convert weights to int8, and then deploy the ONNX model on the CPU endpoint.",
      "B": "Compile and optimize the trained PyTorch model using Amazon SageMaker Neo to perform graph optimizations and int8 quantization, then deploy the Neo-compiled model to the CPU endpoint.",
      "C": "Rewrite the model architecture to reduce hidden layer sizes by 50%, retrain from scratch on CPU, and deploy the smaller model.",
      "D": "Use AWS Lambda with a custom container to dynamically load and prune model weights at inference time to reduce memory usage."
    },
    "explanation": "SageMaker Neo automates model graph optimization and precision quantization (e.g., int8), reducing size and improving CPU performance with minimal code changes while preserving accuracy."
  },
  {
    "taskStatement": "2.2",
    "stem": "A research team has trained a custom XGBoost model locally and now wants to integrate it into Amazon SageMaker for managed hosting, hyperparameter tuning, and CI/CD pipelines without rewriting the training code. What is the most appropriate way to import and serve this externally trained model in SageMaker?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Package the model artifact into a model.tar.gz, build a custom inference Docker container (BYOC) that loads the artifact, push it to Amazon ECR, and create a SageMaker Model referencing that container and S3 artifact.",
      "B": "Translate the local training code into a SageMaker Script Mode training script, run it in a built-in XGBoost container, and register the new model.",
      "C": "Use the SageMaker SDK to call CreateTrainingJob with LocalMode enabled to import and train the model artifact directly.",
      "D": "Upload the model artifact to Amazon SageMaker Model Registry without a container and deploy it to a serverless endpoint."
    },
    "explanation": "Bringing an externally trained model into SageMaker requires a Bring-Your-Own-Container (BYOC) that contains the inference logic; SageMaker Model Registry alone cannot host artifacts without a container."
  },
  {
    "taskStatement": "2.3",
    "stem": "A financial services company is building a fraud detection model. The base fraud rate in production is 1%. On a validation set of 10,000 transactions (100 frauds, 9,900 non-frauds), two candidate models yield the following metrics:\n\nModel A: precision = 0.667, recall = 0.8\nModel B: precision = 0.8, recall = 0.6\n\nThe business cost of a false positive (FP) is $1 and the cost of a false negative (FN) is $10. Which model has the lower expected cost per 10,000 transactions, and which should the company choose?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Choose Model A: expected cost = (FP=40\u00d7$1)+(FN=20\u00d7$10) = $240",
      "B": "Choose Model B: expected cost = (FP=15\u00d7$1)+(FN=40\u00d7$10) = $415",
      "C": "Both models have the same cost",
      "D": "Cannot decide without additional metrics"
    },
    "explanation": "Compute TP, FP, FN for each: Model A: TP=0.8\u00d7100=80, FP=80\u00d7(1/0.667\u22121)=40, FN=20 \u2192 cost=40+200=240. Model B: TP=60, FP=60\u00d7(1/0.8\u22121)=15, FN=40 \u2192 cost=15+400=415. Model A yields lower cost."
  },
  {
    "taskStatement": "2.3",
    "stem": "An ML engineer needs to detect if a production classification model begins to rely on different features over time due to data drift. Which SageMaker Clarify monitor class should the engineer configure to track changes in feature contributions (for example, SHAP values) between a baseline and production data?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "ModelBiasMonitor",
      "B": "ModelExplainabilityMonitor",
      "C": "ModelQualityMonitor",
      "D": "DataQualityMonitor"
    },
    "explanation": "ModelExplainabilityMonitor tracks explainability metrics such as SHAP feature attributions over time. The other monitors handle bias metrics (ModelBiasMonitor), overall prediction quality (ModelQualityMonitor), or input data distributions (DataQualityMonitor)."
  },
  {
    "taskStatement": "2.3",
    "stem": "A deep neural network trained on SageMaker displays stagnating training loss and high validation loss. The engineer enabled SageMaker Debugger\u2019s default rules and then enabled the vanishing gradient rule, which flagged anomalies in the earliest layers. Which action best addresses the vanishing gradient problem in these layers?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Increase the global learning rate to accelerate gradient propagation",
      "B": "Replace sigmoid/tanh activations with ReLU (and use He initialization)",
      "C": "Add L2 weight regularization to penalize large weights",
      "D": "Reduce batch size to increase gradient noise and variability"
    },
    "explanation": "Vanishing gradients in early layers are mitigated by using activation functions with constant gradients (ReLU) and appropriate weight initializations (He). Other options (higher learning rate, L2 penalty, smaller batches) do not directly solve vanishing gradient issues."
  },
  {
    "taskStatement": "3.1",
    "stem": "A fintech firm has developed a credit-scoring ML model (<50 MB) that must serve real-time API requests with no more than 20 ms 95th-percentile latency. Traffic patterns are unpredictable, ranging from 5 to 500 requests per minute. The firm wants to minimize infrastructure management overhead and pay only for the compute capacity it uses, while ensuring consistent low-latency performance. Which SageMaker deployment infrastructure should the ML engineer select?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy the model to a SageMaker serverless endpoint with default concurrency limits.",
      "B": "Deploy the model to a multi-model real-time SageMaker endpoint on a single ml.m5.large instance with auto scaling.",
      "C": "Deploy the model to a SageMaker real-time endpoint on ml.c5.large instances with a provisioned concurrency configuration and target-tracking auto scaling.",
      "D": "Deploy the model to a SageMaker asynchronous inference endpoint with default VCPU provisioning."
    },
    "explanation": "A serverless endpoint can cold-start and breach latency requirements. A single-instance multi-model endpoint cannot guarantee sub-20 ms under unpredictable load. Asynchronous inference is batch-oriented. A real-time endpoint with provisioned concurrency keeps containers warm and uses target-tracking scaling to elastically adjust capacity while maintaining low latency."
  },
  {
    "taskStatement": "3.1",
    "stem": "An industrial IoT company needs to deploy a vision ML model to 1 000 ARM-based edge cameras with intermittent connectivity. The model must run local inference with latency <50 ms and accept periodic updates without manual intervention. Which deployment infrastructure should the ML engineer choose?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Containerize the model and deploy it to AWS Lambda functions on AWS Greengrass Core.",
      "B": "Use SageMaker Edge Manager to package and deploy the model directly to AWS IoT devices.",
      "C": "Compile and optimize the model with SageMaker Neo for the target ARM architecture and deploy it to devices using AWS IoT Greengrass.",
      "D": "Deploy the model to a SageMaker real-time endpoint and configure the devices to call the endpoint when connected."
    },
    "explanation": "Lambda on Greengrass incurs container startup and may not meet <50 ms. Edge Manager provides monitoring but still requires a runtime-optimized model. A real-time endpoint requires connectivity. SageMaker Neo compiles and optimizes the model for ARM, and AWS IoT Greengrass handles offline deployment and periodic updates with minimal ops overhead."
  },
  {
    "taskStatement": "3.1",
    "stem": "A retail company requires an automated, end-to-end CI/CD pipeline for their ML workflow: data preprocessing, training with hyperparameter tuning, model registration and approval, and blue/green deployment to production endpoints. The pipeline must integrate with a Git repository for version control, provide step-level observability, and support easy rollback. Which orchestrator should the ML engineer select to meet these requirements with minimal custom infrastructure?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS CodePipeline with custom AWS Lambda functions for each ML workflow step.",
      "B": "Amazon Managed Workflows for Apache Airflow (MWAA) with DAGs defining each stage.",
      "C": "AWS Step Functions orchestrating AWS Batch jobs for training and deploying Step Functions tasks.",
      "D": "Amazon SageMaker Pipelines with integrated steps for data processing, training, model registry, approval, and deployment."
    },
    "explanation": "CodePipeline requires significant custom Lambda code for ML steps. MWAA is general-purpose and needs custom operators. Step Functions plus Batch require building and managing additional compute and monitoring. SageMaker Pipelines natively integrates preprocessing, training, tuning, registry, approval, and deployment, supports Git integration, lineage, monitoring, and rollback with minimal custom infrastructure."
  },
  {
    "taskStatement": "3.2",
    "stem": "A machine learning team must deploy a SageMaker real-time multi-model endpoint in private subnets with no internet access. The models are packaged as custom Docker images stored in Amazon ECR. The team wants to automate provisioning of all networking, ECR, and SageMaker resources using infrastructure as code (IaC) with minimal operational overhead, and to enforce coding best practices and unit tests. Which approach best meets these requirements?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Write an AWS CloudFormation template that defines the VPC, private subnets, ECR repository, SageMaker model, endpoint configuration, and endpoint resources.",
      "B": "Develop an AWS CDK application (in a supported language) that defines the VPC with interface endpoints, ECR repository, SageMaker model, endpoint configuration, and auto scaling policies, and run unit tests against the CDK constructs.",
      "C": "Use an AWS SAM template to define a Lambda function that creates the VPC and provisions the SageMaker endpoint when invoked.",
      "D": "Author a Terraform module to provision the VPC, ECR repository, and SageMaker resources, and manage state in an S3 backend."
    },
    "explanation": "AWS CDK provides a programmable IaC framework with built-in support for unit testing of constructs, reduces YAML/JSON boilerplate compared to raw CloudFormation, and automates resource provisioning including VPC interface endpoints and SageMaker auto scaling policies with minimal operational overhead."
  },
  {
    "taskStatement": "3.2",
    "stem": "A company\u2019s SageMaker real-time endpoint experiences sudden traffic spikes, causing increased latency. The current target-tracking auto scaling policy uses CPUUtilization. The operations team wants to trigger scale-out more quickly on incoming inference requests while avoiding over-provisioning during lulls. Which metric should they use in the target-tracking policy?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "CPUUtilization",
      "B": "ModelLatency",
      "C": "InvocationsPerInstance",
      "D": "MemoryUtilization"
    },
    "explanation": "InvocationsPerInstance measures the number of inference requests handled per instance, providing a direct signal of request load and enabling faster scaling on bursts, whereas CPUUtilization and MemoryUtilization lag and ModelLatency may not correlate directly with load volume."
  },
  {
    "taskStatement": "3.2",
    "stem": "An ML engineer needs an automated, end-to-end pipeline that builds custom inference container images on code changes, pushes them to ECR, and updates a SageMaker endpoint to use the new image\u2014all defined as code. Which design has the least operational overhead?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use EventBridge to trigger a CodeBuild project on Git push; CodeBuild builds and pushes the image to ECR; a CloudFormation stack update is triggered manually to point the endpoint to the new image.",
      "B": "Define a CodePipeline pipeline (in AWS CDK) that uses CodeCommit, a CodeBuild action to build/push the image, and a CloudFormation action to update the SageMaker endpoint; deploy the pipeline via the CDK app.",
      "C": "Install AWS CLI scripts on an EC2 instance to poll CodeCommit for changes, build and push the container, then run AWS CLI to update the endpoint.",
      "D": "Use CodePipeline with CodeCommit and a Lambda step to build the container image, then invoke an AWS SAM deployment to update the endpoint."
    },
    "explanation": "A CDK-defined CodePipeline with CodeCommit, CodeBuild, and CloudFormation actions provides a fully managed, declarative CI/CD pipeline with minimal custom code, built-in integration, and automated endpoint updates, reducing operational overhead compared to scripting or Lambda-based workarounds."
  },
  {
    "taskStatement": "3.3",
    "stem": "An ML engineer is tasked with building a fully automated CI/CD pipeline for an Amazon SageMaker\u2013based model. The pipeline must: 1) pull code and configuration from a Git repository, 2) run unit tests and data validation, 3) execute data transformation in a SageMaker Processing job, 4) train the model, 5) register the trained model in the SageMaker Model Registry, and 6) perform a canary deployment to production with traffic shifting. The solution must minimize custom Lambda code and leverage native AWS services. Which pipeline architecture best meets these requirements?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use AWS CodePipeline with stages: Source (GitHub), CodeBuild (run tests and data validation), CloudFormation (provision Processing and Training jobs and register model), Manual approval, CloudFormation (update endpoint).",
      "B": "Use AWS CodePipeline with stages: Source (GitHub), CodeBuild (run tests, invoke direct SDK calls to Processing and Training, register model), Manual approval, CodeBuild (use AWS CLI to update endpoint).",
      "C": "Implement a SageMaker Pipeline that includes Processing, Training, Evaluation, and Model Registry steps, and trigger it via EventBridge on git push. Use SageMaker Pipeline\u2019s built-in endpoint update step with canary configuration.",
      "D": "Use AWS CodePipeline with stages: Source (GitHub), CodeBuild (invoke a SageMaker Pipeline via AWS CLI to run Processing, Training, Evaluation, and register the model), Approval, CodeDeploy (configured for SageMaker endpoint canary deployment and traffic shifting)."
    },
    "explanation": "Option D minimizes custom code by delegating ML workflow orchestration to SageMaker Pipelines and uses native CodePipeline stages and CodeDeploy for canary traffic shifting. It cleanly separates CI (CodeBuild) from CD (CodeDeploy) without custom Lambdas."
  },
  {
    "taskStatement": "3.3",
    "stem": "A new CodePipeline contains a CodeBuild action that uses the AWS CLI to start SageMaker Training and Model Deployment jobs. The CodeBuild project\u2019s IAM role has permissions for sagemaker:CreateTrainingJob, sagemaker:CreateModel, and sagemaker:CreateEndpoint, but the build fails with an AccessDenied error stating that the role cannot be passed. What is the LEAST-privilege IAM change required to allow the CodeBuild stage to succeed?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "Add iam:PassRole permission for the SageMaker execution role to the CodeBuild project's IAM role policy.",
      "B": "Update the SageMaker execution role trust policy to allow sts:AssumeRole from codepipeline.amazonaws.com.",
      "C": "Add iam:PassRole permission for the CodeBuild project role to the CodePipeline service role policy.",
      "D": "Add sts:AssumeRole permission for the SageMaker execution role in the CodeBuild project's trust policy."
    },
    "explanation": "When CodeBuild calls SageMaker, it must pass the SageMaker service execution role. Granting iam:PassRole on that role in the CodeBuild project's IAM role policy satisfies the least-privilege requirement."
  },
  {
    "taskStatement": "3.3",
    "stem": "A financial services team uses SageMaker Model Monitor to emit CloudWatch metrics when data drift exceeds thresholds. They need to automatically retrain the model end-to-end (processing, training, evaluation, registry) and roll out the new model with a linear traffic shift as soon as drift is detected. Which combination of AWS services and configurations will satisfy these requirements with minimal custom code?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Create a CloudWatch alarm on the Model Monitor drift metric and an EventBridge rule that triggers an AWS CodePipeline pipeline. In CodePipeline, invoke a SageMaker Pipeline (processing, training, evaluation, model registration) and add a CodeDeploy stage configured for SageMaker endpoint linear traffic shifting.",
      "B": "Subscribe an SNS topic to the Model Monitor violation notification and use an AWS Lambda function to start a SageMaker Pipeline and update the endpoint via SDK with gradual traffic shifting.",
      "C": "Configure Model Monitor to directly invoke a SageMaker Pipeline on drift and include a built-in traffic shifting step in the SageMaker Pipeline definition.",
      "D": "Schedule a daily CodeBuild job to query Model Monitor metrics, and if drift is detected, run a training job and invoke a CloudFormation change set to update the endpoint."
    },
    "explanation": "Option A uses native integration: CloudWatch\u2192EventBridge to trigger CodePipeline, SageMaker Pipelines for retraining, and CodeDeploy for linear traffic shifting. This minimizes custom code and leverages managed services end-to-end."
  },
  {
    "taskStatement": "4.1",
    "stem": "An e-commerce company deployed a recommendation model on SageMaker and needs to monitor both input data drift and model bias in production. They have a baseline training dataset for drift detection and fairness metrics for bias detection. To minimize operational overhead and leverage fully managed monitoring, which solution meets these requirements?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use a single SageMaker Model Monitor job with default settings to detect both drift and bias; schedule hourly.",
      "B": "Configure SageMaker Model Monitor (DefaultModelMonitor) to run a data quality monitoring job with baseline statistics and constraints for input features, and SageMaker Clarify ModelBiasMonitor to run a bias monitoring job with baseline fairness metrics; configure both on a daily schedule.",
      "C": "Use SageMaker Clarify's ModelExplainabilityMonitor to detect both data drift and bias by specifying a SHAP baseline, and schedule it hourly.",
      "D": "Use AWS Lambda triggered every hour to run custom Python scripts that compute drift metrics and bias metrics against baselines; send alerts via Amazon SNS."
    },
    "explanation": "SageMaker Model Monitor (DefaultModelMonitor) is optimized for data drift and quality monitoring using baseline statistics and constraints. SageMaker Clarify\u2019s ModelBiasMonitor is designed to monitor bias against fairness baselines. Combining these two fully managed monitors meets both drift and bias requirements with minimal custom code and operational overhead. Options A and C misuse or over-simplify the services, and D introduces unnecessary custom code."
  },
  {
    "taskStatement": "4.1",
    "stem": "A SaaS provider hosts a real-time image classification endpoint on Amazon SageMaker. They have observed intermittent spikes in 5XX invocation errors and increased inference latency impacting user experience. The operations team needs a solution with the least operational overhead to automatically detect and alert on these issues in near real time. Which approach should the team implement?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "Enable Amazon CloudWatch Logs for the endpoint; configure a metric filter to count '5XX' errors; create CloudWatch alarms for '5XX' error count and for 'ModelLatency' metric.",
      "B": "Configure SageMaker Model Monitor to capture inference requests and responses; schedule a data quality monitoring job every 5 minutes with a custom script to check for errors and latency; publish custom metrics to CloudWatch.",
      "C": "Configure DataCaptureConfig on the endpoint to capture all invocations to S3; create an AWS Lambda function triggered by S3 events that calculates error rates and latency; publish custom CloudWatch metrics and alarms.",
      "D": "Use SageMaker Clarify ModelExplainabilityMonitor to detect anomalies in output embeddings, which will indirectly detect errors and latency issues; schedule it on an hourly basis."
    },
    "explanation": "SageMaker endpoints emit built-in CloudWatch metrics such as Invocation5XXErrors and ModelLatency. Creating CloudWatch alarms on these metrics provides near real-time monitoring with zero custom code and minimal overhead. Model Monitor (B) and Lambda/S3 solutions (C) introduce unnecessary complexity, and Clarify (D) is not designed for error or latency monitoring."
  },
  {
    "taskStatement": "4.1",
    "stem": "A financial analytics team deployed a credit-scoring model on SageMaker real-time endpoints. They want to detect univariate feature drift in critical numeric input features (such as \u2018annual_income\u2019 and \u2018debt_ratio\u2019) and alert if the distribution has shifted beyond acceptable thresholds. They already have training data to serve as a baseline. Which SageMaker feature and configuration should the team use to meet this requirement with minimal custom coding?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Configure SageMaker Clarify ModelBiasMonitor with the training dataset as a baseline and set the 'drift_detection' parameter for numeric features; schedule hourly.",
      "B": "Use SageMaker Model Monitor's DefaultModelMonitor to create a MonitorSchedule with a DataQualityJobDefinition that specifies baseline_statistics and baseline_constraints created from the training dataset; set the monitoring schedule to run hourly.",
      "C": "Deploy a Python-based Lambda function that loads the training dataset baseline, fetches the latest batch of inference requests, computes Kolmogorov\u2013Smirnov tests for each numeric feature, and sends alerts via Amazon SNS.",
      "D": "Use Amazon CloudWatch Metrics Insight to query the 'InputDataMean' metric for each feature and configure alarms when mean deviates by more than a threshold from the training data mean."
    },
    "explanation": "SageMaker Model Monitor\u2019s DefaultModelMonitor supports univariate feature drift detection by automatically generating baseline_statistics and baseline_constraints from training data, and scheduling the monitoring job. This fully managed solution minimizes custom coding. Clarify\u2019s ModelBiasMonitor (A) is for fairness, not general drift, and options C and D require significant custom development or rely on unsupported metric calculations."
  },
  {
    "taskStatement": "4.2",
    "stem": "A company hosts a SageMaker real-time inference endpoint that experiences predictable daily traffic spikes at 9 AM and 6 PM, plus unpredictable fluctuations throughout the day. The ML engineer needs to minimize costs during off-peak hours while ensuring the endpoint maintains a p95 latency below 100 ms. The solution must use built-in AWS services and require minimal custom code. Which configuration should the engineer implement?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Configure a step scaling policy in Amazon CloudWatch that scales out when CPU Utilization > 70% and scales in when CPU Utilization < 30%; set MinCapacity=1 and MaxCapacity=10.",
      "B": "Deploy an AWS Lambda function triggered by Amazon EventBridge schedule rules at 8:50 AM and 5:50 PM to call UpdateEndpointWeightsAndCapacities, and use a target tracking policy for unpredictable loads.",
      "C": "Define an Application Auto Scaling target tracking policy on the SageMaker endpoint based on p95 latency with MinCapacity=1, MaxCapacity=10, and add a scheduled scaling action to increase capacity to 8 at 8:50 AM and 5:50 PM.",
      "D": "Use Spot Instances by converting the endpoint to asynchronous inference, configure Spot for inference to de-provision overnight, and rely on target tracking for bursts."
    },
    "explanation": "Option C leverages built-in Application Auto Scaling for SageMaker to handle both scheduled and dynamic scaling in a single service with minimal custom code. Step and Lambda solutions are more complex and less precise; asynchronous/Spot inference cannot guarantee real-time p95 latency."
  },
  {
    "taskStatement": "4.2",
    "stem": "An ML engineer needs to optimize cost and performance of multiple SageMaker real-time inference endpoints. Each endpoint has different traffic patterns and latency requirements. The engineer wants to identify the most cost-effective instance type for each endpoint, based on sample inference payloads, throughput, and latency SLOs. Which tool or workflow should the engineer use?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use AWS Compute Optimizer to generate EC2 instance recommendations and manually map those to SageMaker endpoints.",
      "B": "Use SageMaker Inference Recommender to run profiling jobs with sample payloads and choose the instance types with the lowest cost per inference that meet the SLOs.",
      "C": "Use AWS Trusted Advisor to forecast inference endpoint costs and recommend Reserved Instances.",
      "D": "Use AWS Cost Explorer\u2019s RI purchase recommendations to apply savings to SageMaker endpoint instance types."
    },
    "explanation": "SageMaker Inference Recommender is designed to profile real-world inference workloads and recommend the optimal instance types for cost and performance. Compute Optimizer and Trusted Advisor do not profile SageMaker workloads at the application level."
  },
  {
    "taskStatement": "4.2",
    "stem": "A global team uses SageMaker across 10 AWS accounts under consolidated billing. They must enforce that every SageMaker training job, endpoint, and pipeline carries the tags Project and CostCenter, automatically deny creations without them, and generate a centralized monthly cost dashboard per project. Which solution meets these requirements with the least operational overhead?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy AWS Config rules in each account to audit SageMaker resource tags, use AWS Service Catalog with TagOptions to solicit the tags, and build QuickSight dashboards from Cost Explorer filtered by tags.",
      "B": "Implement AWS Organizations Tag Policies to require Project and CostCenter tags on SageMaker resources, enable AWS Config for compliance evaluation, and use Cost Explorer/AWS Budgets with tag filters for centralized dashboards.",
      "C": "Create Service Control Policies to forbid creation of untagged SageMaker resources, use CloudTrail + Lambda to remediate missing tags, and aggregate costs via Cost Explorer.",
      "D": "Enforce all SageMaker deployments through AWS CloudFormation StackSets with mandatory tags in the templates, and view costs in the AWS Billing console."
    },
    "explanation": "AWS Organizations Tag Policies provide native, centralized enforcement of required tags across accounts with minimal operational effort. Combined with AWS Config compliance checks and Cost Explorer/AWS Budgets, this delivers automated enforcement and centralized cost reporting. Other options require custom code or more operational overhead."
  },
  {
    "taskStatement": "4.3",
    "stem": "An enterprise mandates that all SageMaker training and inference workloads must run within a secured VPC without any public internet access. However, these workloads need to read training data from Amazon S3, pull container images from Amazon ECR, write logs to Amazon CloudWatch Logs, and use a customer-managed AWS KMS key. The security team requires the solution to minimize ongoing maintenance overhead while enforcing least-privilege network connectivity. Which architectural configuration meets these requirements?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable SageMaker network isolation and launch jobs outside any VPC; rely on network isolation to prevent internet access.",
      "B": "Launch SageMaker jobs inside a VPC with no internet gateway, configure interface VPC endpoints for S3, ECR (both API and Docker), CloudWatch Logs, and KMS, and remove any NAT gateways.",
      "C": "Launch SageMaker jobs in the default VPC and attach a security group that blocks 0.0.0.0/0; use public endpoints for AWS services.",
      "D": "Use a network ACL on the private subnet to deny all outbound traffic; allow S3 and ECR access by whitelisting their public IP ranges."
    },
    "explanation": "Enabling interface VPC endpoints for S3, ECR, CloudWatch Logs, and KMS in a VPC without an Internet Gateway ensures workloads have private, least-privilege access to required AWS services and keys, while preventing any public internet access. Network isolation alone (A) doesn\u2019t provide VPC-private access to AWS services. Security groups cannot filter based on AWS service endpoints (C). NACLs cannot reliably allow AWS service traffic by IP (D)."
  },
  {
    "taskStatement": "4.3",
    "stem": "A company\u2019s sensitive training data is stored in an S3 bucket encrypted with a customer-managed KMS key (DataKey). They must run SageMaker training jobs that decrypt the data and write model artifacts to a separate S3 bucket encrypted with another KMS key (OutputKey). The SageMaker execution role must follow the principle of least privilege. Which combination of IAM role policy statements and KMS key policy statements satisfies this requirement?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "IAM role: Grant s3:GetObject and s3:PutObject on both buckets and kms:Decrypt, kms:Encrypt on both keys. KMS key policies: Trust the entire account principal for all operations.",
      "B": "IAM role: Grant s3:GetObject on the data bucket; s3:PutObject on the artifact bucket; kms:Decrypt and kms:GenerateDataKey on DataKey; kms:Encrypt and kms:GenerateDataKey on OutputKey. KMS key policies: Specify the SageMaker execution role as the only principal allowed to use each key.",
      "C": "IAM role: Grant s3:* on both buckets and kms:* on both keys. KMS key policies: No changes needed (account admins manage keys).",
      "D": "Use S3 bucket policies to grant SageMaker service principal full access, and KMS grants to allow any IAM principal in account to decrypt keys."
    },
    "explanation": "Least-privilege requires the IAM role only have s3:GetObject on the data bucket, s3:PutObject on the output bucket, and only the specific KMS operations. The key policies must explicitly allow the SageMaker execution role to use each key. Over-permissive (A, C) or relying on bucket policies alone (D) violates least-privilege."
  },
  {
    "taskStatement": "4.3",
    "stem": "A security team manages multiple AWS accounts using AWS Organizations. They want to ensure that data scientists in member accounts can only create, update, or delete SageMaker endpoints within their own accounts, and prevent any SageMaker endpoint operations in accounts outside their OU. Which mechanism should be implemented at the organization level to enforce this restriction?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use an AWS Organizations service control policy (SCP) at the OU level to Deny all sagemaker:CreateEndpoint, UpdateEndpoint, and DeleteEndpoint actions when the resource\u2019s account ID does not match the requesting account.",
      "B": "Apply IAM permission boundaries to the data scientists\u2019 roles in each member account that restrict sagemaker:* to specific endpoint ARNs.",
      "C": "Attach a resource-based policy to each SageMaker endpoint specifying allowed IAM principals from the same account.",
      "D": "Use the SageMaker service-linked role policy to restrict endpoint operations to certain accounts."
    },
    "explanation": "An AWS Organizations SCP can centrally deny SageMaker endpoint management actions across accounts outside the OU, enforcing the requirement. IAM permission boundaries (B) must be set per role and cannot prevent actions outside the OU. SageMaker endpoints do not support resource-based policies for management operations (C). Service-linked roles cannot enforce cross-account restrictions (D)."
  },
  {
    "taskStatement": "1.1",
    "stem": "A fintech company needs to ingest 1 million financial transaction events per second into Amazon SageMaker Feature Store for real-time fraud detection. The solution must support low latency, horizontal scalability, and minimal data loss. Which ingestion architecture meets these requirements?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use Amazon Kinesis Data Firehose to deliver events to S3 and batch import into SageMaker Feature Store Offline Store.",
      "B": "Use Amazon Kinesis Data Streams with enhanced fan-out consumers and AWS Lambda functions invoking the PutRecord API to ingest into the SageMaker Feature Store Online Store.",
      "C": "Use Amazon MSK with brokers backed by EBS volumes and use a Kafka consumer to push records into the Feature Store offline bucket.",
      "D": "Use AWS IoT Core to route transaction events to SageMaker Feature Store via a custom AWS Lambda integration."
    },
    "explanation": "Real-time, low-latency ingest into the Feature Store Online Store requires Kinesis Data Streams (for horizontal scaling and enhanced fan-out) combined with Lambda invoking the PutRecord API. Firehose and batch imports do not meet real-time SLAs; MSK and IoT Core approaches add unnecessary complexity and latency."
  },
  {
    "taskStatement": "1.1",
    "stem": "An analytics team has 200 GiB of nested JSON log files in Amazon S3. They require interactive profiling and transformation in SageMaker Data Wrangler with minimal cost and latency. Which file format should they convert the data into before ingestion?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "CSV files (flattening nested structures into columns).",
      "B": "Apache Parquet with nested column support and predicate pushdown.",
      "C": "Avro files with JSON serialization.",
      "D": "RecordIO binary format."
    },
    "explanation": "Parquet is a columnar storage format with efficient compression, nested column support, and predicate pushdown, which significantly reduces I/O and speeds interactive profiling in Data Wrangler. CSV lacks nested support, Avro is row-oriented, and RecordIO is optimized for deep learning, not interactive ETL."
  },
  {
    "taskStatement": "1.1",
    "stem": "An ML engineer must merge hourly transaction updates from Amazon RDS and real-time clickstream events from DynamoDB Streams into a single dataset for training in SageMaker Data Wrangler, while automatically handling schema evolution in both sources. Which ingestion solution should the engineer choose?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Schedule an AWS Glue ETL job to export RDS to S3 and join with Lambda-pushed DynamoDB data once per hour.",
      "B": "Use SageMaker Data Wrangler\u2019s built-in connectors for Amazon RDS and for DynamoDB streams to import and join data in a single flow.",
      "C": "Provision an EMR Spark cluster to read from both sources nightly and write merged Parquet to S3.",
      "D": "Use AWS DMS to replicate both RDS and DynamoDB to Redshift and join via Redshift Spectrum in Data Wrangler."
    },
    "explanation": "Data Wrangler connectors natively support incremental read and schema inference for RDS and DynamoDB streams, simplifying merges and automatically handling schema changes. Glue jobs or EMR require more operational overhead, and DMS replication to Redshift adds extra cost and latency."
  },
  {
    "taskStatement": "1.1",
    "stem": "A genomics research team requires sub-millisecond file I/O and high throughput for a 500 GiB NFS-based dataset during preprocessing before model training. Which AWS storage service should they provision to meet performance and POSIX compatibility requirements?",
    "correct": "B",
    "difficulty": "HARD",
    "answers": {
      "A": "Amazon EFS One Zone SSD backed by NFS.",
      "B": "Amazon FSx for Lustre file system with link to S3.",
      "C": "Amazon FSx for NetApp ONTAP with SSD volumes.",
      "D": "Amazon S3 bucket mounted via VPC endpoint."
    },
    "explanation": "FSx for Lustre delivers the lowest POSIX read-latencies (sub-millisecond) and highest throughput for large NFS-based datasets. EFS has higher latencies; FSx ONTAP adds data management features but lower throughput; S3 is object storage, not POSIX."
  },
  {
    "taskStatement": "1.1",
    "stem": "An e-commerce company experiences high startup latency for SageMaker training jobs reading hundreds of small CSV files (~5\u201310 MiB each) from S3. Without modifying the training code, which solution will most reduce startup time?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable Amazon S3 Transfer Acceleration on the bucket.",
      "B": "Use AWS Glue to consolidate small CSV files into larger Parquet files and update the S3 prefix.",
      "C": "Upgrade to a SageMaker instance with higher network throughput.",
      "D": "Change the training input mode to Pipe mode."
    },
    "explanation": "Consolidating small files into fewer, larger Parquet files minimizes S3 list and open calls, dramatically reducing startup latency without code changes. Transfer Acceleration and network upgrades do not address metadata overhead; Pipe mode still requires metadata enumeration."
  },
  {
    "taskStatement": "1.1",
    "stem": "A media streaming platform requires exactly-once processing of real-time events into its ML ingestion pipeline for feature computation. Which combination of services and configurations provides this guarantee?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon Kinesis Data Firehose with a retry buffer.",
      "B": "Amazon Kinesis Data Streams with Enhanced Fan-Out (guarantees at-least-once).",
      "C": "Amazon MSK (Kafka) configured with idempotent producers and transactional writes.",
      "D": "DynamoDB Streams with AWS Lambda and conditional writes to downstream store."
    },
    "explanation": "Kafka with idempotent producers and transactional writes supports exactly-once semantics end-to-end. Kinesis Data Streams and Firehose only guarantee at-least-once; DynamoDB Streams plus Lambda may still result in duplicates without complex idempotency logic."
  },
  {
    "taskStatement": "1.1",
    "stem": "An ML pipeline ingests unvalidated CSV files into Amazon S3, but inconsistent schemas and missing columns cause downstream failures. Which AWS service can enforce schema validation during ingestion and alert on violations?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Glue Schema Registry with schema-validation-enabled data producers.",
      "B": "AWS Config rules for S3 object schemas.",
      "C": "Amazon Macie classification jobs.",
      "D": "AWS Lake Formation schema enforcement."
    },
    "explanation": "AWS Glue Schema Registry can define, register and enforce schemas at ingestion for streaming and batch, and can reject or alert on malformed records. Lake Formation handles data access control, not row-level schema validation."
  },
  {
    "taskStatement": "1.1",
    "stem": "A large oil company must migrate 100 TiB of POSIX file-system data to Amazon S3 within 48 hours, with incremental file changes tracked and minimal management overhead. Which service meets these requirements?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Snowball Edge device shipment.",
      "B": "AWS DataSync configured for incremental sync to S3.",
      "C": "Amazon S3 Transfer Acceleration over the internet.",
      "D": "AWS Storage Gateway file gateway."
    },
    "explanation": "AWS DataSync optimizes incremental transfer of POSIX files to S3 with built-in scheduling and encryption, suitable for large, continuously changing data. Snowball has shipment delays; Transfer Acceleration and Storage Gateway don\u2019t handle incremental POSIX sync as efficiently."
  },
  {
    "taskStatement": "1.1",
    "stem": "An ML engineer wants to profile, clean, and transform streaming IoT telemetry data directly in SageMaker Data Wrangler without intermediate storage. Which ingestion method should the engineer use?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use the Amazon Kinesis Data Streams connector in Data Wrangler to ingest data in real time.",
      "B": "Upload data to S3 and use the S3 connector for batch profiling.",
      "C": "Route data through AWS IoT Analytics to an S3 channel and ingest.",
      "D": "Crawl raw data with AWS Glue and import the Glue table."
    },
    "explanation": "The Kinesis Data Streams connector in Data Wrangler enables real-time profiling and transformation of streaming data. Other options introduce batch windows or extra services, increasing latency and operational overhead."
  },
  {
    "taskStatement": "1.1",
    "stem": "When mounting an Amazon EFS file system to a SageMaker Studio notebook in a VPC, which configuration step ensures secure, low-latency access?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "Mount the EFS file system over the public internet using TLS.",
      "B": "Create EFS mount targets in the same VPC subnets as the SageMaker notebooks and attach security groups allowing NFS traffic (TCP/2049).",
      "C": "Use AWS Direct Connect to mount the EFS file system from on-premises.",
      "D": "Peer the notebook VPC to another VPC containing EFS and mount through a transit gateway."
    },
    "explanation": "To achieve secure, low-latency NFS access from Studio in the same VPC, you must create EFS mount targets in the same subnets and open NFS ports in security groups. Public mounts or cross-VPC peering add latency and complexity."
  },
  {
    "taskStatement": "1.1",
    "stem": "A cross-account pipeline must ingest data from an S3 bucket in Account A into SageMaker Studio in Account B. To minimize privileges and management, which approach should be used?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Add a bucket ACL granting Account B the s3:GetObject permission.",
      "B": "Create an IAM role in Account B with a trust policy for Account A\u2019s principal, and update the bucket policy to allow s3:GetObject for that role.",
      "C": "Use an AWS Organizations SCP to allow cross-account access.",
      "D": "Set up VPC peering between the two accounts and access the bucket over the interface endpoint."
    },
    "explanation": "Creating a cross-account IAM role in Account B with trust from Account A and granting that role permission in the bucket policy provides least-privilege, auditable access. Bucket ACLs are legacy, and Organizations SCP/VPC peering do not directly enable S3 access control."
  },
  {
    "taskStatement": "1.1",
    "stem": "A data ingestion job reading from S3 into SageMaker notebooks is intermittently throttled with HTTP 503 SlowDown errors. Which approach will most effectively reduce these errors while maintaining high throughput?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Implement exponential backoff with jitter in the client\u2019s S3 request retry logic.",
      "B": "Enable S3 Transfer Acceleration to optimize network path.",
      "C": "Configure the bucket as requester-pays.",
      "D": "Increase the IAM request quota for the S3 service."
    },
    "explanation": "503 SlowDown errors indicate S3 throttling; the recommended mitigation is implementing exponential backoff with jitter to retry requests gracefully. Transfer Acceleration and requester-pays do not address throttling, and IAM quotas are unrelated."
  },
  {
    "taskStatement": "1.1",
    "stem": "An Amazon SageMaker training job mounts an Amazon FSx for Lustre file system backed by an 8 TiB S3 data repository. After heavy parallel reads, the engineer observes metadata lookup latencies >100 ms for POSIX operations. How can the engineer optimize metadata performance?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Increase the Lustre file system\u2019s throughput capacity to provision more metadata IOPS.",
      "B": "Switch the workload to Amazon EFS for metadata caching.",
      "C": "Directly mount the underlying S3 bucket instead of Lustre.",
      "D": "Implement a local cache on the training instance\u2019s EBS volume."
    },
    "explanation": "FSx for Lustre provides scalable metadata throughput proportionate to the configured throughput capacity. Increasing capacity raises available metadata IOPS and reduces latency. EFS and direct S3 mounts do not meet the sub-millisecond metadata requirements."
  },
  {
    "taskStatement": "1.1",
    "stem": "A data science team must join millions of small S3 objects with a 50 GiB Redshift table for feature engineering before training. The join must complete in the lowest end-to-end latency. Which ingestion and compute architecture should they choose?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Run an AWS Glue ETL job to merge the data into a Parquet file and reload into SageMaker.",
      "B": "Use Redshift Spectrum to query the S3 objects in place and join directly with the local Redshift table.",
      "C": "Provision an EMR Spark cluster to read both sources and write joined output to S3.",
      "D": "Use Athena CTAS to precompute the join and then read from S3 in SageMaker."
    },
    "explanation": "Redshift Spectrum can directly query external S3 data and join with internal tables, minimizing data movement and achieving the lowest latency. Glue, EMR, and Athena introduce additional data shuffles or write phases, adding latency."
  },
  {
    "taskStatement": "1.1",
    "stem": "When performing offline ingestion into SageMaker Feature Store, which file format and partitioning scheme will maximize batch import throughput and query efficiency?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "A single unpartitioned CSV file containing all records.",
      "B": "Many small gzipped JSON files partitioned by feature group name.",
      "C": "Parquet files partitioned by ingestion date (yyyy/mm/dd) and hour.",
      "D": "Avro files with no partitions."
    },
    "explanation": "Partitioning Parquet files by date and hour enables parallel reads by the batch import process and efficient predicate pushdown, maximizing throughput and query efficiency. Single large CSVs or unpartitioned formats become bottlenecks; Avro lacks columnar benefits."
  },
  {
    "taskStatement": "1.2",
    "stem": "You have a numeric feature in your dataset that is strongly right-skewed. You plan to preprocess the data in SageMaker Data Wrangler and then train a linear regression model. Which sequence of transformations in Data Wrangler will best reduce skewness and satisfy the assumptions of linear regression?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Standardize the feature first, then apply a log transform",
      "B": "Apply a log transform first, then standardize the resulting values",
      "C": "Min\u2013max scale the feature first, then apply a log transform",
      "D": "One-hot encode the feature, then normalize the encoded columns"
    },
    "explanation": "A log transform first reduces skew, and subsequent standardization yields zero mean and unit variance, aligning with linear regression assumptions."
  },
  {
    "taskStatement": "1.2",
    "stem": "Your streaming sensor pipeline ingests data via Kinesis Data Streams. You need to filter out invalid readings and impute missing values in real time with sub-second latency. Which solution provides the lowest operational overhead and meets performance requirements?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use Kinesis Data Analytics SQL to filter and invoke Lambda for imputation",
      "B": "Use a Lambda function to filter and then call SageMaker Data Wrangler batch job for imputation",
      "C": "Use Kinesis Data Analytics for Apache Flink to filter and impute within the streaming application",
      "D": "Use AWS Glue streaming ETL job to filter and impute before writing to S3"
    },
    "explanation": "Kinesis Data Analytics for Apache Flink supports stateful, low-latency streaming transforms including filter and impute within the service, minimizing custom infrastructure."
  },
  {
    "taskStatement": "1.2",
    "stem": "A categorical feature has 5,000 unique values. You intend to use a tree-based algorithm and want to avoid excessive dimensionality. Which encoding technique should you apply using SageMaker Data Wrangler?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "One-hot encoding of all categories",
      "B": "Label encoding (assigning integer codes)",
      "C": "Frequency encoding (replace category with its occurrence frequency)",
      "D": "Hashing trick with a large hash space"
    },
    "explanation": "Frequency encoding reduces cardinality to a single numeric value per category, retaining information without high-dimensional expansion."
  },
  {
    "taskStatement": "1.2",
    "stem": "You need to remove duplicate records from two large S3 datasets in preparation for feature engineering. Which AWS Glue Spark ETL approach ensures schema enforcement and minimal data loss?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use Glue DynamicFrame.drop_duplicates on the combined DynamicFrame",
      "B": "Convert to Spark DataFrame and call DataFrame.distinct()",
      "C": "Use a SageMaker Processing job with custom dedupe code",
      "D": "Use a Glue DataBrew recipe step to drop duplicates"
    },
    "explanation": "Glue DynamicFrame.drop_duplicates preserves schema and metadata, integrates with the Glue catalog, and scales automatically."
  },
  {
    "taskStatement": "1.2",
    "stem": "You need to detect and remove outliers beyond 3 standard deviations for a numeric column using AWS Glue DataBrew. Which recipe step accomplishes this with minimal effort?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "Add a Filter rows step with condition > mean + 3*stddev",
      "B": "Use the built-in Remove outliers step and set the z-score threshold to 3",
      "C": "Add a Cluster rows step and drop the smallest cluster",
      "D": "Use Impute missing step to replace values beyond 3 standard deviations"
    },
    "explanation": "The Remove outliers step in DataBrew natively handles z-score thresholds, detecting and dropping extreme values automatically."
  },
  {
    "taskStatement": "1.2",
    "stem": "Your team needs to implement a custom feature transformation in a visual pipeline that includes Python code (e.g., complex binning logic). Which SageMaker tool supports this requirement and collaborative workflows?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Glue DataBrew",
      "B": "SageMaker Data Wrangler",
      "C": "AWS Glue Python shell job",
      "D": "Spark on Amazon EMR notebook"
    },
    "explanation": "Data Wrangler provides a visual flow with built-in support for custom Python steps, versioning, and collaboration in Studio."
  },
  {
    "taskStatement": "1.2",
    "stem": "You need to compute a 7-day rolling mean on a time-series feature for millions of records. Which approach in an AWS managed service offers the highest throughput with minimal code?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Run a SageMaker Processing job with PySpark window functions",
      "B": "Write a Glue Spark ETL job using Spark SQL window functions",
      "C": "Use SageMaker Data Wrangler\u2019s rolling statistics transform",
      "D": "Use Lambda functions with batched DynamoDB lookups"
    },
    "explanation": "Data Wrangler\u2019s built-in rolling statistic transform executes efficiently in a managed environment without custom code or cluster management."
  },
  {
    "taskStatement": "1.2",
    "stem": "You have a free-text column that needs tokenization into word tokens and conversion into integer IDs for embedding. Which Data Wrangler transformation sequence should you apply?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "Use the Tokenize step (word level) and then Encode step (label encoding)",
      "B": "Use TextVectorization step with TF-IDF output",
      "C": "One-hot encode the text column directly",
      "D": "Write a custom PySpark transform in SageMaker Processing"
    },
    "explanation": "The Tokenize step splits text into words, and Label Encoding maps each token to a unique integer ID, preparing for embeddings."
  },
  {
    "taskStatement": "1.2",
    "stem": "Before training, you must enforce schema constraints (data types, value ranges) programmatically. Which AWS feature will you use?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Glue Data Quality rules leveraging Deequ",
      "B": "SageMaker Data Wrangler profile job",
      "C": "DataBrew column profiling summary",
      "D": "Glue Data Catalog crawler validation"
    },
    "explanation": "Glue Data Quality uses Deequ to define and evaluate table constraints and thresholds in code, enforcing schema at scale."
  },
  {
    "taskStatement": "1.2",
    "stem": "You plan to store engineered features for real-time inference in SageMaker Feature Store. Which Data Wrangler export option supports batching data into a Feature Group?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use a SageMaker Processing job to call PutRecord API",
      "B": "Use a Lambda function to batch and call PutRecordBatch",
      "C": "Export directly from Data Wrangler to SageMaker Feature Store",
      "D": "Upload CSV to S3 and configure offline store only"
    },
    "explanation": "Data Wrangler has a direct export feature to batch-write transformed data into a Feature Store Feature Group."
  },
  {
    "taskStatement": "1.2",
    "stem": "You need to reduce a numeric feature\u2019s cardinality to 100 bins based on equal-frequency intervals using a no-code solution. Which DataBrew step do you choose?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "Group by step with custom quantile aggregation",
      "B": "Bin numeric values step with equal-frequency option",
      "C": "Cluster rows step with K-means clustering",
      "D": "Custom recipe with Python UDF"
    },
    "explanation": "The Bin numeric values step with equal-frequency creates quantile-based bins automatically, reducing cardinality."
  },
  {
    "taskStatement": "1.2",
    "stem": "To impute missing age values by country group using DataBrew, which step sequence is correct?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "Use Partition by country, then Impute missing step with median strategy",
      "B": "Aggregate to compute medians, then perform a join back",
      "C": "Apply global median imputation for the age column",
      "D": "Export data and impute in SageMaker Processing"
    },
    "explanation": "Partitioning by country followed by median imputation uses group-wise statistics directly in DataBrew with minimal extra steps."
  },
  {
    "taskStatement": "1.2",
    "stem": "Two 1 TB CSV files in S3 must be inner-joined on a composite key before feature engineering. You want a serverless, managed service that handles scaling and scripting. Which approach is best?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "Run an AWS Glue ETL job using DynamicFrame.join",
      "B": "Launch an EMR cluster with custom PySpark code",
      "C": "Use a SageMaker Processing PySpark job",
      "D": "Perform a CTAS join in Amazon Athena"
    },
    "explanation": "AWS Glue ETL with DynamicFrame.join provides serverless scaling, schema enforcement, and integration with the Glue Data Catalog."
  },
  {
    "taskStatement": "1.2",
    "stem": "You need to anonymize email addresses in real time within a Kinesis Data Stream, ensuring <200 ms processing per record. Which architecture meets this requirement?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Glue streaming ETL job with built-in masking",
      "B": "Kinesis Data Analytics for Apache Flink with a UDF to hash emails",
      "C": "AWS Lambda subscribed to the stream invoking a hashing library",
      "D": "SageMaker Data Wrangler in streaming mode"
    },
    "explanation": "Kinesis Data Analytics for Flink executes in-stream UDFs with low, consistent latency, meeting sub-200 ms requirements without cold starts."
  },
  {
    "taskStatement": "1.2",
    "stem": "Duplicate events may occur within a 2-minute window in your Kinesis stream. You need to drop duplicates in real time before storing to S3. Which solution is most appropriate?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use Kinesis Data Analytics for Flink, keyBy event ID and apply a 2-minute deduplication window",
      "B": "Configure an AWS Glue streaming job with dedupe enabled",
      "C": "Trigger a Lambda function per record and check DynamoDB for prior IDs",
      "D": "Run an EMR streaming job with custom dedupe code"
    },
    "explanation": "Kinesis Data Analytics for Flink supports stateful windowed deduplication on event keys with minimal infrastructure overhead."
  },
  {
    "taskStatement": "1.3",
    "stem": "An ML engineer needs to set up automated, scheduled data quality checks on an Amazon S3 dataset to validate completeness, uniqueness, and detect numeric outliers over time. Which solution meets these requirements with the LEAST operational overhead?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use AWS Glue DataBrew to author a recipe with transformations and schedule it as a DataBrew job.",
      "B": "Use AWS Glue Data Quality to define data quality rules and configure a schedule to run them.",
      "C": "Use SageMaker Clarify DataQualityCheckConfig in a SageMaker Processing job triggered by EventBridge.",
      "D": "Use Amazon Athena SQL queries inside a Lambda function scheduled by EventBridge."
    },
    "explanation": "AWS Glue Data Quality is designed for automated, rule-based validation and scheduling of data quality checks with minimal operational overhead."
  },
  {
    "taskStatement": "1.3",
    "stem": "A data scientist must detect pre-training label disparity between male and female groups in a binary classification dataset. Which SageMaker Clarify metric should be used?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "pre_training_bias:CI (class imbalance)",
      "B": "pre_training_bias:DPL (difference in proportions of labels)",
      "C": "post_training_bias:CI",
      "D": "post_training_bias:DPL"
    },
    "explanation": "Difference in proportions of labels (DPL) is the appropriate pre-training metric to measure label distribution disparity between protected groups."
  },
  {
    "taskStatement": "1.3",
    "stem": "A dataset for fraud detection has severe class imbalance (0.5% positives). The engineer wants synthetic minority oversampling before training. Which AWS service/plugin should be used to implement SMOTE?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Specify class_weight in the training script and rely on model loss adjustment.",
      "B": "Use AWS Glue DataBrew sampling transform to oversample the minority class.",
      "C": "Use a SageMaker Processing job that implements imbalanced-learn\u2019s SMOTE algorithm.",
      "D": "Use SageMaker Clarify to automatically generate synthetic samples."
    },
    "explanation": "A SageMaker Processing job allows you to run custom code (e.g., imbalanced-learn) to generate SMOTE synthetic samples before training."
  },
  {
    "taskStatement": "1.3",
    "stem": "A tabular dataset containing PII must be anonymized before model training. The engineer wants to mask names, emails, and SSNs in CSV files with minimal coding. Which solution should be implemented?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "Use AWS Glue DataBrew recipe steps with the built-in PII Mask transform on the relevant columns.",
      "B": "Write a Lambda function to scan each file in S3, mask PII, and write back to S3.",
      "C": "Use SageMaker Clarify\u2019s bias analysis and misapply it for PII detection.",
      "D": "Use AWS KMS custom encryption to encrypt only the PII columns at rest."
    },
    "explanation": "AWS Glue DataBrew provides built-in PII Mask transforms that can mask specified columns with minimal code."
  },
  {
    "taskStatement": "1.3",
    "stem": "An ML engineer uses an Amazon EFS file system to store training data. To meet compliance, data must be encrypted at rest and in transit between the SageMaker training instance and EFS. Which configuration meets these requirements?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable only SSE-KMS encryption on the EFS file system.",
      "B": "Configure the EFS mount with NFSv4 and no encryption.",
      "C": "Use Amazon FSx for Lustre with default settings.",
      "D": "Enable EFS encryption at rest (SSE-KMS) and mount using EFS mount options with encryption in transit (TLS)."
    },
    "explanation": "To meet both requirements, enable SSE-KMS on EFS and use the EFS mount option to enforce TLS encryption in transit."
  },
  {
    "taskStatement": "1.3",
    "stem": "A dataset contains multiple records per user_id. To prevent data leakage, how should an ML engineer split the dataset into train and test subsets?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Randomly split 80/20 at the record level.",
      "B": "Use stratified split to preserve label proportions.",
      "C": "Use a group-based split (e.g., scikit-learn\u2019s GroupShuffleSplit) with user_id as the group key.",
      "D": "Split based on time, taking the latest 20% of records as test."
    },
    "explanation": "A group-based split ensures that all records for a given user_id are either in train or test, preventing leakage."
  },
  {
    "taskStatement": "1.3",
    "stem": "A text dataset with PII must be anonymized before training. The engineer wants automatic detection of names and SSNs. Which AWS service should be used in a SageMaker Processing job?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Glue DataBrew PII Masking",
      "B": "Amazon Comprehend PII detection API",
      "C": "SageMaker Clarify bias detection",
      "D": "AWS Lake Formation data labeling"
    },
    "explanation": "Amazon Comprehend\u2019s PII detection API can be called from a Processing job to automatically identify and anonymize PII in text."
  },
  {
    "taskStatement": "1.3",
    "stem": "To detect statistical parity in a numeric target variable across demographic groups before training, which SageMaker Clarify component should be used?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "DataQualityCheckConfig in SageMaker Clarify",
      "B": "PreTrainingBiasCheckConfig in a SageMaker Clarify Processing job",
      "C": "ModelBiasMonitor",
      "D": "BatchTransform with a custom script"
    },
    "explanation": "PreTrainingBiasCheckConfig in a Clarify Processing job enables computation of pre-training bias metrics on the dataset."
  },
  {
    "taskStatement": "1.3",
    "stem": "Before ingesting S3 data into SageMaker, an engineer needs to automatically discover and classify PII fields at scale. Which AWS service should be used?",
    "correct": "C",
    "difficulty": "EASY",
    "answers": {
      "A": "AWS Config",
      "B": "Amazon Athena",
      "C": "Amazon Macie",
      "D": "AWS CloudTrail"
    },
    "explanation": "Amazon Macie automatically discovers and classifies PII in S3 objects at scale."
  },
  {
    "taskStatement": "1.3",
    "stem": "A SageMaker training job must encrypt all EBS volumes with a customer-managed KMS key. How should the engineer configure the training job?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "Specify the KmsKeyId parameter in the CreateTrainingJob API.",
      "B": "Configure the InputDataConfig to include an EncryptionKeyId.",
      "C": "Enable SSE-KMS on the S3 bucket only.",
      "D": "Use a SageMaker Pipeline with a default KMS key."
    },
    "explanation": "The CreateTrainingJob API\u2019s KmsKeyId parameter applies the specified customer-managed KMS key to encrypt all training EBS volumes."
  },
  {
    "taskStatement": "1.3",
    "stem": "A company must enforce fine-grained access control on PII columns in its Data Catalog tables. Which AWS capability enables this?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "S3 bucket policies on the underlying data files.",
      "B": "AWS Lake Formation LF-Tags attached to Data Catalog columns.",
      "C": "IAM identity-based policies only.",
      "D": "AWS KMS key policies on the Data Catalog."
    },
    "explanation": "Lake Formation LF-Tags on Data Catalog columns provide column-level access control for sensitive data."
  },
  {
    "taskStatement": "1.3",
    "stem": "An engineer needs to ensure that a string column contains only unique values before training. Which AWS service and rule type should be used?",
    "correct": "D",
    "difficulty": "EASY",
    "answers": {
      "A": "AWS Glue DataBrew with a completeness rule.",
      "B": "AWS Glue Data Quality with a passing ratio rule.",
      "C": "SageMaker Clarify DataQualityCheckConfig uniqueness check.",
      "D": "AWS Glue Data Quality with a uniqueness rule."
    },
    "explanation": "AWS Glue Data Quality supports a rule to check column uniqueness to enforce that values are unique."
  },
  {
    "taskStatement": "1.3",
    "stem": "To prevent order-based bias in large S3 datasets during training, how can the engineer shuffle data in a SageMaker training job?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use File input mode (default shuffling).",
      "B": "Use RecordIO input mode (shuffles automatically).",
      "C": "Use Pipe input mode with ShuffleConfig set to an appropriate buffer size.",
      "D": "Download and shuffle in the training script only."
    },
    "explanation": "Pipe input mode with ShuffleConfig allows SageMaker to shuffle streaming records before training to avoid order bias."
  },
  {
    "taskStatement": "1.3",
    "stem": "A dataset contains missing numeric values that must be imputed with the median before feature engineering. Which tool provides a built-in transform for this?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "AWS Glue DataBrew recipe step \u201cFill missing values\u201d with median.",
      "B": "SageMaker Debugger preprocessing hook.",
      "C": "SageMaker Feature Store ingestion transform.",
      "D": "AWS Glue Data Quality imputation rule."
    },
    "explanation": "AWS Glue DataBrew includes a \u201cFill missing values\u201d transform that can impute missing entries with statistics like median."
  },
  {
    "taskStatement": "1.3",
    "stem": "An engineer wants to use a consistent, repeatable set of cleaned and validated features for both offline training and real-time inference. Which AWS capability should be used?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon S3 with versioned CSV files.",
      "B": "Amazon DynamoDB table with precomputed features.",
      "C": "SageMaker Feature Store to store and retrieve features.",
      "D": "Amazon Redshift external table."
    },
    "explanation": "SageMaker Feature Store provides a centralized store for features that ensures consistency between offline training and online inference."
  },
  {
    "taskStatement": "2.1",
    "stem": "A credit risk team needs a highly interpretable, low-latency regression model for predicting applicant default probability using 50 numerical and categorical features. They require clear feature coefficients for regulatory reporting. Which SageMaker built-in algorithm should they choose?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "XGBoost built-in algorithm with SHAP explanations",
      "B": "Linear Learner built-in algorithm in regression mode",
      "C": "Factorization Machines built-in algorithm",
      "D": "DeepAR forecasting algorithm"
    },
    "explanation": "Linear Learner in regression mode provides direct feature weights for interpretability and low latency. XGBoost can require SHAP post hoc analysis, and other algorithms aren\u2019t designed for regression interpretability."
  },
  {
    "taskStatement": "2.1",
    "stem": "An online advertising platform must predict click-through rates with hundreds of categorical features of high cardinality. The team wants to capture pairwise interactions between sparse features efficiently. Which built-in SageMaker algorithm is most appropriate?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "XGBoost built-in algorithm",
      "B": "Linear Learner built-in algorithm",
      "C": "Factorization Machines built-in algorithm",
      "D": "K-Means built-in clustering algorithm"
    },
    "explanation": "Factorization Machines are designed to model interactions among high-cardinality categorical features more efficiently than tree-based or linear models."
  },
  {
    "taskStatement": "2.1",
    "stem": "A retail company needs to forecast hourly product demand for 10,000 SKUs with seasonal patterns and occasional promotions. They require a probabilistic forecast of future demand. Which built-in SageMaker algorithm should they select?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "DeepAR forecasting algorithm",
      "B": "XGBoost regression algorithm",
      "C": "Linear Learner regression algorithm",
      "D": "K-Nearest Neighbors built-in algorithm"
    },
    "explanation": "DeepAR provides probabilistic time series forecasts at scale and handles seasonality and promotions. Other algorithms do not directly support probabilistic forecasting."
  },
  {
    "taskStatement": "2.1",
    "stem": "An operations team needs to detect anomalies in streaming server CPU metrics. They require a one-class unsupervised method that adapts to drift. Which SageMaker built-in algorithm meets these requirements?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Isolation Forest built-in algorithm",
      "B": "Random Cut Forest built-in algorithm",
      "C": "One-Class SVM via script mode",
      "D": "K-Means built-in clustering algorithm"
    },
    "explanation": "Random Cut Forest is an unsupervised, streaming-friendly anomaly detection algorithm that adapts to drift; it\u2019s a SageMaker built-in algorithm."
  },
  {
    "taskStatement": "2.1",
    "stem": "A global publisher must classify news articles in 10 languages with minimal training data per language. They need an AWS managed NLP service with built-in support. Which service should they choose?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Custom BERT model on SageMaker",
      "B": "Custom TF-based text classifier in script mode",
      "C": "Amazon Comprehend DetectDominantLanguage and Custom Classification APIs",
      "D": "Amazon Translate to English plus custom classifier"
    },
    "explanation": "Amazon Comprehend offers multi-language classification with minimal training data and managed infrastructure. Custom models require more data and maintenance."
  },
  {
    "taskStatement": "2.1",
    "stem": "A biotech startup wants to identify cell types in microscopy images with minimal ML expertise. They prefer a no-code AWS solution that adapts to new classes. Which service should they use?",
    "correct": "D",
    "difficulty": "EASY",
    "answers": {
      "A": "Custom CNN built in TensorFlow on SageMaker script mode",
      "B": "Deploy a PyTorch model on SageMaker endpoint",
      "C": "Use SageMaker AutoML via built-in algorithms",
      "D": "SageMaker Canvas image classification with Amazon Rekognition Custom Labels integration"
    },
    "explanation": "SageMaker Canvas provides a no-code interface, and integration with Rekognition Custom Labels supports labeling and incremental class adaptation without deep ML expertise."
  },
  {
    "taskStatement": "2.1",
    "stem": "A call-center analytics team needs real-time transcription and sentiment analysis of customer calls. They require a managed service with low operations overhead. Which combination should they use?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "Custom DeepSpeech model on SageMaker",
      "B": "Amazon Transcribe for transcription and Amazon Comprehend for sentiment",
      "C": "Deploy open-source Kaldi on SageMaker",
      "D": "Amazon Lex chatbot for transcription and sentiment"
    },
    "explanation": "Amazon Transcribe and Comprehend are managed services for ASR and sentiment analysis, respectively, minimizing operational overhead compared to custom models."
  },
  {
    "taskStatement": "2.1",
    "stem": "A financial modeling team needs to generate synthetic financial reports using a foundation model. They require a generative text service with minimal training. Which AWS service best fits?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "Amazon Bedrock with a foundation LLM",
      "B": "Custom GPT-2 on SageMaker",
      "C": "Use TensorFlow Sequence-to-Sequence on SageMaker",
      "D": "Amazon Translate with custom glossary"
    },
    "explanation": "Amazon Bedrock provides foundation LLMs for text generation, reducing heavy training and tuning efforts versus custom Seq2Seq models."
  },
  {
    "taskStatement": "2.1",
    "stem": "An edge computing use case requires running an image classifier on IoT cameras with limited compute. They have a trained ResNet model. Which SageMaker feature should they use to optimize the model?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "SageMaker built-in Image Classification algorithm",
      "B": "SageMaker Script Mode with TensorFlow",
      "C": "SageMaker Neo compilation to target edge architecture",
      "D": "Containerize model for SageMaker endpoint"
    },
    "explanation": "SageMaker Neo compiles and optimizes trained models for edge devices, reducing latency and resource usage on IoT cameras."
  },
  {
    "taskStatement": "2.1",
    "stem": "A team needs to quickly prototype a multi-label text classification for internal documents with zero code. They want to experiment with pre-trained models and fine-tune them. Which SageMaker capability should they use?",
    "correct": "D",
    "difficulty": "EASY",
    "answers": {
      "A": "SageMaker Clarify for data bias analysis",
      "B": "SageMaker Model Monitor for drift alerts",
      "C": "Notebook instance with pre-built scripts",
      "D": "SageMaker JumpStart solution templates for multi-label text classification"
    },
    "explanation": "SageMaker JumpStart provides pre-trained model solutions and templates for multi-label classification that can be fine-tuned with minimal code."
  },
  {
    "taskStatement": "2.1",
    "stem": "A startup has a small tabular dataset (5,000 rows) and needs a quick binary classifier with built-in regularization and automated hyperparameter tuning. Which SageMaker built-in algorithm and mode is most appropriate?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "Linear Learner in binary classification mode",
      "B": "XGBoost regression mode",
      "C": "K-Means clustering mode",
      "D": "DeepAR forecasting mode"
    },
    "explanation": "Linear Learner supports binary classification with built-in regularization and integrates with SageMaker Automatic Model Tuning for small datasets efficiently."
  },
  {
    "taskStatement": "2.1",
    "stem": "A fraud detection team requires an algorithm that handles class imbalance and produces probabilistic scores for each transaction. They prefer a tree-based approach. Which built-in algorithm should they select?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Linear Learner with L1 regularization",
      "B": "XGBoost built-in algorithm",
      "C": "Random Cut Forest",
      "D": "K-Nearest Neighbors"
    },
    "explanation": "XGBoost produces probabilistic outputs, handles class imbalance via objective weighting, and is a high-performance tree-based algorithm."
  },
  {
    "taskStatement": "2.1",
    "stem": "A medical imaging project needs semantic segmentation on X-ray images. The team has no pre-built algorithm in SageMaker. They want minimal development overhead. Which approach should they take?",
    "correct": "C",
    "difficulty": "EASY",
    "answers": {
      "A": "Use SageMaker built-in Object Detection algorithm",
      "B": "Use Rekognition Custom Labels",
      "C": "Use JumpStart semantic segmentation pre-trained model in script mode",
      "D": "Develop a U-Net from scratch in a notebook"
    },
    "explanation": "JumpStart offers pre-trained semantic segmentation models that can be fine-tuned in script mode, reducing overhead compared to building models from scratch."
  },
  {
    "taskStatement": "2.1",
    "stem": "A business needs to extract key phrases from customer reviews in Spanish. They want a managed solution that supports custom phrase detection. Which service should they choose?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Custom spaCy model on SageMaker",
      "B": "Custom PyTorch NLP in script mode",
      "C": "Amazon Translate to English plus Comprehend key phrases",
      "D": "Amazon Comprehend with custom entity recognizer for Spanish"
    },
    "explanation": "Amazon Comprehend supports custom entity detection in multiple languages including Spanish, avoiding translation pipelines or heavy custom models."
  },
  {
    "taskStatement": "2.1",
    "stem": "A team must choose between deploying a SageMaker built-in algorithm versus a pre-packaged deep learning framework in script mode. They prioritize faster training on CPU-only instances for a moderate-sized tabular dataset. Which should they choose?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "SageMaker built-in XGBoost algorithm",
      "B": "TensorFlow in script mode",
      "C": "PyTorch in script mode",
      "D": "Bring-Your-Own container with Scikit-learn"
    },
    "explanation": "XGBoost built-in algorithm is optimized for CPU training on tabular data and will train faster with minimal configuration compared to deep learning frameworks."
  },
  {
    "taskStatement": "2.2",
    "stem": "A data scientist has an existing SageMaker automatic model tuning (AMT) job that produced optimal hyperparameter values for a regression model. New data arrives and the scientist wants to reuse the previous tuning results as a starting point for a new hyperparameter tuning job to save compute time. Which warm start configuration type should the scientist choose?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use a warm start tuning job with type IDENTICAL_DATA_AND_ALGORITHM.",
      "B": "Use a warm start tuning job with type TRANSFER_LEARNING.",
      "C": "Use a warm start tuning job with type CURRENT_BEST.",
      "D": "Use a regular hyperparameter tuning job without warm start."
    },
    "explanation": "TRANSFER_LEARNING reuses previous tuning job results to inform new search on similar data or algorithm. IDENTICAL_DATA_AND_ALGORITHM reruns the same search space exactly. CURRENT_BEST and non\u2013warm-start jobs don\u2019t utilize prior results to reduce compute."
  },
  {
    "taskStatement": "2.2",
    "stem": "An ML engineer wants to reduce wasted compute and stop unpromising training jobs early during an AMT hyperparameter tuning job. Which configuration change will achieve this with minimal code changes?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Set EarlyStoppingType to AUTO in the hyperparameter tuning job configuration.",
      "B": "Set MaxRuntimePerTrainingJob to a lower value.",
      "C": "Add a CloudWatch alarm to terminate long-running training jobs.",
      "D": "Wrap each training job in a custom script that kills the process if validation loss stops improving."
    },
    "explanation": "Setting EarlyStoppingType='Auto' enables SageMaker to automatically terminate unpromising training jobs. Lowering MaxRuntime limits total time but doesn\u2019t target unpromising jobs. CloudWatch alarms and custom scripts add operational overhead."
  },
  {
    "taskStatement": "2.2",
    "stem": "A team trains a large PyTorch model on 8 GPU instances, but training is slow and network communication is a bottleneck. Which SageMaker feature will provide an efficient out-of-the-box distributed training solution to accelerate this job?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Configure Horovod for distributed training.",
      "B": "Enable smdistributed.dataparallel in Script Mode.",
      "C": "Use the built-in PyTorch Multi-GPU Estimator.",
      "D": "Use a parameter server architecture implemented in the training script."
    },
    "explanation": "smdistributed DataParallel integrates with Script Mode and optimizes gradient synchronization. Horovod requires extra setup, custom parameter server needs code changes, and there is no separate built-in PyTorch multi-GPU Estimator."
  },
  {
    "taskStatement": "2.2",
    "stem": "During training of a convolutional neural network, an ML engineer observes overfitting: training accuracy far exceeds validation accuracy. Which single change to the training job will increase generalization with the least complexity?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Increase the dropout rate from 0.25 to 0.75.",
      "B": "Reduce the initial learning rate by a factor of ten.",
      "C": "Add L2 weight-decay regularization to the optimizer.",
      "D": "Switch to early stopping and set patience to 3 epochs."
    },
    "explanation": "L2 weight decay penalizes large weights and reduces overfitting without requiring new callbacks. Excessive dropout may underfit; reducing learning rate doesn\u2019t directly address overfitting; early stopping adds extra tuning and monitoring."
  },
  {
    "taskStatement": "2.2",
    "stem": "An ML engineer has trained both a random forest and an XGBoost model for the same classification task and wants to combine them to improve accuracy. Which ensemble approach should the engineer implement to learn an optimal combination of predictions?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Train a meta-learner on the model outputs (stacking).",
      "B": "Average the predictions from both models (bagging).",
      "C": "Train the XGBoost model to correct errors of the random forest (boosting).",
      "D": "Select the model with the higher validation accuracy for each input dynamically (voting)."
    },
    "explanation": "Stacking uses a meta\u00ad-model trained on base-model outputs to learn optimal weights. Bagging pools multiple instances of one algorithm. Boosting uses sequential training, not two distinct models. Voting is a simple unweighted ensemble."
  },
  {
    "taskStatement": "2.2",
    "stem": "A financial services firm needs to track, promote, and audit multiple versions of their ML models in SageMaker. Which feature should they use to centrally manage model versions and stages (e.g., Approved, Pending)?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon S3 object versioning on the model artifacts bucket.",
      "B": "SageMaker Model Registry.",
      "C": "SageMaker Experiments.",
      "D": "AWS CodeCommit repository."
    },
    "explanation": "SageMaker Model Registry is designed to store, version, and annotate model artifacts and their approval lifecycle. S3 versioning tracks raw objects but lacks metadata. Experiments track experiments, not production stages. CodeCommit is source control."
  },
  {
    "taskStatement": "2.2",
    "stem": "When using smdistributed.dataparallel for PyTorch training, the network bandwidth is still limiting training throughput. Which additional configuration can reduce communication overhead?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Switch to Horovod with NCCL backend.",
      "B": "Enable gradient compression (fp16) in smdistributed.dataparallel.",
      "C": "Use MPI and ring-allreduce instead of reduce-scatter.",
      "D": "Increase batch size to amortize communication."
    },
    "explanation": "smdistributed DataParallel supports fp16 gradient compression to reduce bandwidth. Horovod setup is heavier, using MPI doesn\u2019t enable compression, and larger batches may help but don\u2019t directly reduce communication volume."
  },
  {
    "taskStatement": "2.2",
    "stem": "An ML engineer is constrained by budget and can run at most 50 training jobs for hyperparameter tuning. Which search strategy in SageMaker AMT will likely find the best solution within the least number of jobs?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Grid search.",
      "B": "Random search.",
      "C": "Bayesian optimization.",
      "D": "Genetic algorithm search."
    },
    "explanation": "Bayesian optimization balances exploration and exploitation, converging faster. Grid search is exhaustive, random search is less efficient, and genetic algorithms aren\u2019t natively supported in SageMaker AMT."
  },
  {
    "taskStatement": "2.2",
    "stem": "A company must deploy a deep learning model to edge devices that have strict memory limits. Which approach using SageMaker will produce the smallest model artifact with minimal manual optimization?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Apply manual weight pruning in the training script.",
      "B": "Use SageMaker Neo to compile and quantize the model for the target device.",
      "C": "Enable mixed-precision training and save fp16 weights.",
      "D": "Use model distillation to train a smaller student network."
    },
    "explanation": "SageMaker Neo automates compilation and quantization for the target hardware, reducing model size. Manual pruning requires custom code; mixed precision lowers memory at runtime but not artifact size; distillation requires additional training."
  },
  {
    "taskStatement": "2.2",
    "stem": "An ML engineer wants to fine-tune a large pre-trained Hugging Face transformer using SageMaker. Which method requires the least boilerplate code?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Bring your own container with transformers installed.",
      "B": "Use the SageMaker Hugging Face estimator in Script Mode.",
      "C": "Translate the model code to MXNet and use the built-in MXNet Estimator.",
      "D": "Use Amazon SageMaker built-in text classification algorithm."
    },
    "explanation": "The SageMaker Hugging Face estimator simplifies fine-tuning with minimal code. BYOC adds container management; translating to MXNet is error-prone; no built-in algorithm for large transformer fine-tuning exists."
  },
  {
    "taskStatement": "2.2",
    "stem": "A data scientist configures an AMT tuning job but forgot to configure early stopping. Which change should they make to the tuning configuration to enable automated early stopping of poor performing jobs?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Set EarlyStoppingType='Auto' and choose an appropriate WaitInterval.",
      "B": "Lower the MaxJobs parameter to force quicker completion.",
      "C": "Define a CloudWatch rule to terminate jobs with low metrics.",
      "D": "Wrap the training script in a debugger rule to kill unresponsive jobs."
    },
    "explanation": "EarlyStoppingType='Auto' with WaitInterval allows SageMaker to stop jobs whose objective does not improve. Lowering MaxJobs only limits total count. CloudWatch rules and debugger scripts are more operationally complex."
  },
  {
    "taskStatement": "2.2",
    "stem": "A neural network training job shows high training accuracy but validation accuracy plateaus early. The engineer wants an automated mechanism to detect this during training. Which SageMaker Debugger rule should they enable?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "VanishingGradientDetector.",
      "B": "LossNotDecreasing.",
      "C": "OverfitDetector.",
      "D": "WeightUpdateVerifier."
    },
    "explanation": "OverfitDetector monitors training vs. validation metrics to detect early signs of overfitting. VanishingGradientDetector and LossNotDecreasing focus on gradients and loss. WeightUpdateVerifier checks parameter updates."
  },
  {
    "taskStatement": "2.2",
    "stem": "A team wants to track parameters, metrics, and artifacts across multiple training jobs and compare runs in SageMaker. Which feature should they use?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "SageMaker Model Monitor.",
      "B": "SageMaker Experiments.",
      "C": "Amazon CloudWatch metrics.",
      "D": "AWS X-Ray."
    },
    "explanation": "SageMaker Experiments is built to organize, track, and compare training runs. Model Monitor observes deployed models. CloudWatch and X-Ray are for logs and traces, not training experiment management."
  },
  {
    "taskStatement": "2.2",
    "stem": "A neural network trained on tabular data shows many small nonzero weights and generalizes poorly. Which regularization change will encourage sparsity and reduce overfitting?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Increase the L2 (weight\u2010decay) coefficient.",
      "B": "Increase dropout to 0.8.",
      "C": "Switch to L1 regularization on weights.",
      "D": "Use batch normalization after every layer."
    },
    "explanation": "L1 regularization (Lasso) encourages many weights to become exactly zero, producing sparse models. L2 shrinks but doesn\u2019t enforce sparsity. Dropout and batch normalization address generalization but not weight sparsity."
  },
  {
    "taskStatement": "2.3",
    "stem": "You have trained a binary classifier on a dataset where the positive class constitutes only 1% of the data. On a held-out test set, the model achieves an AUC-ROC of 0.90, but its precision at low recall is poor. Which evaluation metric should you use to better assess the model\u2019s ability to identify the minority positive class?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Accuracy",
      "B": "AUC-ROC",
      "C": "Area Under the Precision-Recall Curve (AUC-PR)",
      "D": "Log Loss"
    },
    "explanation": "With extreme class imbalance, the precision-recall curve (AUC-PR) focuses on performance for the positive class and is more informative than AUC-ROC or accuracy."
  },
  {
    "taskStatement": "2.3",
    "stem": "A regression model predicts house prices. Stakeholders are more concerned about a few very large prediction errors than many small ones. Which metric should you minimize?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Mean Absolute Error (MAE)",
      "B": "Root Mean Square Error (RMSE)",
      "C": "R\u00b2 (Coefficient of Determination)",
      "D": "Mean Absolute Percentage Error (MAPE)"
    },
    "explanation": "RMSE penalizes large errors more heavily than MAE, making it appropriate when large deviations are particularly undesirable."
  },
  {
    "taskStatement": "2.3",
    "stem": "An ML engineer wants to run reproducible training experiments that track hyperparameters, metrics, and artifacts across multiple training jobs in Amazon SageMaker. Which AWS service should they use?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Amazon CloudWatch Logs",
      "B": "AWS CodePipeline",
      "C": "Amazon SageMaker Experiments",
      "D": "AWS Config"
    },
    "explanation": "SageMaker Experiments provides managed tracking of experiments, trials, hyperparameters, metrics, and artifacts to ensure reproducibility."
  },
  {
    "taskStatement": "2.3",
    "stem": "During training, you notice that your model\u2019s loss on the training set stops decreasing early and plateaus. Which built-in SageMaker Debugger rule should you enable to detect this convergence issue?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "OverfitDetector",
      "B": "LossNotDecreasing",
      "C": "LearningRateFinder",
      "D": "WeightNormMonitor"
    },
    "explanation": "The LossNotDecreasing rule monitors training loss and raises an alert if it does not decrease sufficiently, indicating convergence problems."
  },
  {
    "taskStatement": "2.3",
    "stem": "You want to generate local feature\u2010level explanations (SHAP values) for your production model using SageMaker Clarify. Which configuration should you use?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "DataBiasConfig in ClarifyProcessingJob",
      "B": "ModelBiasConfig in ClarifyProcessingJob",
      "C": "SHAPConfig in ClarifyProcessingJob",
      "D": "DriftConfig in ClarifyProcessingJob"
    },
    "explanation": "SHAPConfig enables Clarify to compute SHAP feature attributions for local explainability of model predictions."
  },
  {
    "taskStatement": "2.3",
    "stem": "To select an optimal classification threshold that maximizes F1 score, what procedure should you perform on your validation data?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Evaluate F1 at various probability thresholds and choose the threshold yielding the highest F1",
      "B": "Select the threshold where ROC curve slope equals 1",
      "C": "Use the threshold where precision equals recall",
      "D": "Choose the threshold that balances true positive and false positive rates"
    },
    "explanation": "Maximizing F1 requires evaluating F1 at multiple thresholds on validation data and selecting the threshold with the highest F1."
  },
  {
    "taskStatement": "2.3",
    "stem": "Your deep neural network exhibits vanishing gradient issues. Which SageMaker Debugger configuration helps you inspect gradient distributions during training?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable the base and gradient_histogram collections",
      "B": "Use the TorchLrFinder rule",
      "C": "Use the OverfitDetector rule",
      "D": "Configure only the losses collection"
    },
    "explanation": "The gradient_histogram collection captures gradient distributions so you can detect vanishing or exploding gradients."
  },
  {
    "taskStatement": "2.3",
    "stem": "You need to perform A/B testing between two model variants in production with minimal overhead. Which SageMaker feature supports traffic splitting between variants?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "Deploy two separate endpoints and use Route 53 weighted routing",
      "B": "Configure two production variants in a single endpoint and set variant weights",
      "C": "Use an AWS Lambda function to proxy and split traffic",
      "D": "Use AWS CodePipeline for traffic routing"
    },
    "explanation": "SageMaker endpoints support multiple production variants with configurable weights for built-in traffic splitting (A/B testing)."
  },
  {
    "taskStatement": "2.3",
    "stem": "For a multi-class classification problem with imbalanced classes, which evaluation metric gives equal importance to each class regardless of its frequency?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Micro-averaged F1 score",
      "B": "Macro-averaged F1 score",
      "C": "Overall accuracy",
      "D": "Weighted precision"
    },
    "explanation": "Macro-averaged F1 computes the F1 score for each class and averages them equally, treating all classes with equal importance."
  },
  {
    "taskStatement": "2.3",
    "stem": "You compare two regression models: Model A (RMSE = 5.0), Model B (RMSE = 4.8). How can you determine whether the observed difference is statistically significant?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Compare the RMSE values directly",
      "B": "Compute bootstrapped confidence intervals for the RMSE difference",
      "C": "Use one-way ANOVA on prediction residuals",
      "D": "Compare R\u00b2 values"
    },
    "explanation": "Bootstrapping provides confidence intervals on the RMSE difference to determine if the improvement is statistically significant."
  },
  {
    "taskStatement": "2.3",
    "stem": "Which SageMaker Clarify metric measures the difference in the proportion of positive outcomes between two demographic groups?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Class imbalance (CI)",
      "B": "Difference in Proportions of Labels (DPL)",
      "C": "Kolmogorov\u2013Smirnov (KS) statistic",
      "D": "Confusion matrix parity"
    },
    "explanation": "DPL quantifies the difference in label rates (positive outcome proportions) between a sensitive group and the baseline group."
  },
  {
    "taskStatement": "2.3",
    "stem": "Your model\u2019s training loss decreases steadily while validation loss increases after a point. Which SageMaker Debugger rule can detect this behavior automatically?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "OverfitDetector",
      "B": "LossNotDecreasing",
      "C": "LearningRateFinder",
      "D": "GradientHistogram"
    },
    "explanation": "OverfitDetector monitors divergence between training and validation losses to detect overfitting during training."
  },
  {
    "taskStatement": "2.3",
    "stem": "You want to identify a suitable initial learning rate for faster convergence. Which SageMaker Debugger rule should you run?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "LearningRateFinder",
      "B": "LossNotDecreasing",
      "C": "OverfitDetector",
      "D": "EarlyStoppingRule"
    },
    "explanation": "LearningRateFinder systematically varies the learning rate to help identify an optimal learning rate for training convergence."
  },
  {
    "taskStatement": "2.3",
    "stem": "You need to compute evaluation metrics at multiple classification thresholds using SageMaker Clarify. Which configuration option enables this?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Specify multiple thresholds in the ClarifyProcessor\u2019s ModelPredictionsConfig",
      "B": "Use SageMaker Model Monitor\u2019s default job",
      "C": "Run a SageMaker batch transform and manually compute metrics",
      "D": "Use SageMaker Automatic Model Tuning"
    },
    "explanation": "You can configure multiple thresholds in ModelPredictionsConfig for Clarify processing jobs to compute metrics (precision, recall, F1) at those thresholds."
  },
  {
    "taskStatement": "2.3",
    "stem": "During training you observe that both training and validation losses are high and nearly identical, and the model fails to improve. What issue does this indicate?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "Overfitting",
      "B": "Underfitting",
      "C": "Data leakage",
      "D": "Gradient explosion"
    },
    "explanation": "High and similar training/validation losses indicate underfitting, meaning the model is too simplistic to capture the underlying data patterns."
  },
  {
    "taskStatement": "3.1",
    "stem": "A startup has developed an ML model for an internal analytics tool that is invoked fewer than 100 times per day. Each inference must return within 200 ms, and total monthly cost must be minimized. Which SageMaker deployment option best meets these requirements?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "Provision a real-time SageMaker endpoint with minimal instance capacity and auto scaling.",
      "B": "Deploy the model as a SageMaker serverless endpoint.",
      "C": "Use a SageMaker asynchronous endpoint with low concurrency settings.",
      "D": "Schedule a SageMaker batch transform job once per day."
    },
    "explanation": "A serverless endpoint incurs no idle instance cost, supports <200 ms latency for light workloads, and is optimal for very low invocation volume."
  },
  {
    "taskStatement": "3.1",
    "stem": "A machine learning team must host 500 small models (<50 MB each) behind a single API. All models share identical inference logic but have different weights. Which deployment infrastructure should be used to minimize cost and management overhead?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "A multi-model SageMaker endpoint.",
      "B": "500 separate real-time SageMaker endpoints.",
      "C": "A SageMaker batch transform job per model.",
      "D": "Amazon ECS on Fargate with mounted S3 weights."
    },
    "explanation": "Multi-model endpoints load models on demand into a shared container, reducing cost and simplifying management compared to separate endpoints."
  },
  {
    "taskStatement": "3.1",
    "stem": "An automotive OEM wants to run an object-detection model on in-vehicle devices with limited compute and no internet connectivity. The model must start in <50 ms after request. Which deployment approach meets these requirements?",
    "correct": "C",
    "difficulty": "HARD",
    "answers": {
      "A": "Host the model on a SageMaker real-time endpoint and stream data from the vehicle.",
      "B": "Use a SageMaker asynchronous endpoint with cached results on the vehicle gateway.",
      "C": "Compile the model with SageMaker Neo and deploy it to the edge container on the device.",
      "D": "Package the model in a Lambda@Edge function and invoke it from the vehicle."
    },
    "explanation": "SageMaker Neo compiles and optimizes models for specific hardware and enables sub-50 ms local inference without connectivity."
  },
  {
    "taskStatement": "3.1",
    "stem": "A document-processing model accepts 8 MB JSON payloads and may run up to 10 minutes per request. Customers must receive a response per request. Which SageMaker endpoint type is the most cost-effective?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Asynchronous SageMaker endpoint.",
      "B": "Real-time SageMaker endpoint.",
      "C": "Serverless SageMaker endpoint.",
      "D": "SageMaker batch transform job."
    },
    "explanation": "Asynchronous endpoints support large payloads, long processing durations, and return one response per request, avoiding persistent instance costs of real-time endpoints."
  },
  {
    "taskStatement": "3.1",
    "stem": "An e-commerce site needs <100 ms inference latency for its image-classification model at peak traffic. Daily traffic patterns vary widely. Which compute environment should the ML engineer choose?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "CPU-based serverless SageMaker endpoint.",
      "B": "GPU-based serverless SageMaker endpoint.",
      "C": "CPU-based real-time SageMaker endpoint with fixed instance count.",
      "D": "GPU-based real-time SageMaker endpoint with auto scaling."
    },
    "explanation": "GPU real-time endpoints deliver required low latency, and auto scaling adjusts capacity to traffic variation."
  },
  {
    "taskStatement": "3.1",
    "stem": "A custom TensorFlow model requires specific OS libraries and drivers that are not available in SageMaker built-in containers. What is the least operationally intensive way to deploy the model?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Translate the model code to one compatible with a built-in container.",
      "B": "Run a batch transform job instead of hosting a real-time endpoint.",
      "C": "Build a custom Docker container, push to ECR, and use it in a SageMaker endpoint.",
      "D": "Use a Lambda function with layers containing the required libraries."
    },
    "explanation": "Custom containers in SageMaker allow full control over dependencies and integrate seamlessly with endpoint deployment."
  },
  {
    "taskStatement": "3.1",
    "stem": "A regulated enterprise requires all inference traffic to traverse a secured, private network with no public internet access. Which configuration satisfies this requirement with minimal changes?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy a public SageMaker endpoint and block internet via security groups.",
      "B": "Deploy a SageMaker real-time endpoint in the customer VPC with private subnets and no NAT gateway.",
      "C": "Use a serverless SageMaker endpoint and disable outbound access.",
      "D": "Host the model in EKS and restrict Internet at cluster level."
    },
    "explanation": "Launching the endpoint in private subnets of the customer VPC ensures no public internet access without additional NAT configuration."
  },
  {
    "taskStatement": "3.1",
    "stem": "An ML engineer must deploy a new model version and gradually shift 20% of production traffic to it for canary testing, with automatic rollback on errors. Which SageMaker feature accomplishes this?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy a new real-time endpoint and use a Route 53 weighted record.",
      "B": "Create a second endpoint and manually switch after validation.",
      "C": "Use a SageMaker batch transform job for the canary.",
      "D": "Use SageMaker endpoint\u2010update with traffic shifting via endpoint configurations."
    },
    "explanation": "SageMaker\u2019s endpoint configuration supports traffic weights for A/B and canary deployments and automatic rollback on alarms."
  },
  {
    "taskStatement": "3.1",
    "stem": "Your team uses Amazon Managed Workflows for Apache Airflow (MWAA) but wants tighter integration with SageMaker model deployments and lineage tracking. Which orchestrator should you choose?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Continue with MWAA and use custom operators.",
      "B": "SageMaker Pipelines.",
      "C": "AWS Step Functions directly.",
      "D": "AWS CodePipeline."
    },
    "explanation": "SageMaker Pipelines provides built-in integration for training, model registry, and deployment with lineage tracking."
  },
  {
    "taskStatement": "3.1",
    "stem": "A model requires a preprocessing container and a separate inference container on each request. How should you deploy this in SageMaker?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Multi-container real-time endpoint with both containers in the same inference pipeline.",
      "B": "Two separate endpoints chained via Lambda.",
      "C": "Batch transform job with a custom script calling both containers.",
      "D": "ECS service with multiple containers per task."
    },
    "explanation": "SageMaker multi-container endpoints allow a preprocessor and model container to run sequentially in the same endpoint."
  },
  {
    "taskStatement": "3.1",
    "stem": "A lightweight NLP model (<10 MB) must be invoked by other AWS services via API and handle occasional spikes of up to 50 requests per second. You want to avoid managing servers. Which deployment target is best?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Serverless SageMaker endpoint.",
      "B": "Real-time SageMaker endpoint with a single instance.",
      "C": "Amazon Lambda container image with the model packaged and hosted behind an API Gateway.",
      "D": "ECS Fargate service."
    },
    "explanation": "A Lambda container image offers serverless scaling to handle spikes and exposes a simple API gateway endpoint without EC2 management."
  },
  {
    "taskStatement": "3.1",
    "stem": "Your team needs to optimize inference performance on ARM-based instances in AWS. The model currently runs on x86 CPU. Which deployment approach will yield the greatest performance gain?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Switch to a serverless endpoint on ARM.",
      "B": "Compile the model with SageMaker Neo for ARM and host on ARM EC2 instances.",
      "C": "Use a GPU-based real-time endpoint on x86.",
      "D": "Deploy in ECS with ARM container images."
    },
    "explanation": "Neo compiles and optimizes for ARM hardware, delivering significant inference speedups compared to generic CPU execution."
  },
  {
    "taskStatement": "3.1",
    "stem": "A hybrid environment uses on-premises Kubernetes and AWS. You need to deploy an ML model so that it's available to both environments with unified CI/CD. Which deployment infrastructure is most appropriate?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "SageMaker serverless endpoint with VPC peering.",
      "B": "SageMaker real-time endpoint in a public subnet.",
      "C": "ECS with Fargate in a public VPC.",
      "D": "Amazon EKS with GPU node group and a shared Terraform pipeline."
    },
    "explanation": "EKS provides Kubernetes compatibility on-prem and in AWS and integrates with existing CI/CD pipelines."
  },
  {
    "taskStatement": "3.1",
    "stem": "A data-science team must process nightly batches of 10 million records through an ML model. Sub-second latency is not required, but overall runtime must complete within 2 hours. Which deployment strategy is optimal?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "High-capacity real-time SageMaker endpoint with multiple GPU instances.",
      "B": "Serverless SageMaker endpoint with high concurrency.",
      "C": "SageMaker batch transform job with GPU instances.",
      "D": "SageMaker asynchronous endpoint with high timeouts."
    },
    "explanation": "Batch transform jobs are optimized for high-throughput offline inference and can leverage large GPU fleets to meet deadlines without request-based endpoint costs."
  },
  {
    "taskStatement": "3.1",
    "stem": "Your organization uses Kubernetes microservices on Amazon EKS. You must deploy an ML model as a microservice in this architecture with GPU acceleration. Which approach do you choose?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use a SageMaker real-time endpoint and call it from EKS pods.",
      "B": "Deploy the model in a container on EKS with a GPU instance profile.",
      "C": "Package the model in a Lambda function behind an Application Load Balancer.",
      "D": "Use SageMaker multi-model endpoint within the VPC and proxy through EKS."
    },
    "explanation": "Hosting directly on EKS with GPU nodes integrates with existing microservices, avoids network hops, and provides GPU acceleration under Kubernetes control."
  },
  {
    "taskStatement": "3.2",
    "stem": "You have two CloudFormation stacks: one provisioning a VPC with subnets and security groups, and another provisioning a SageMaker real-time endpoint. The endpoint stack needs to reference the VPC subnets and security group ARNs created by the VPC stack. What is the most maintainable way to share these values?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "In the VPC stack, export the subnet IDs and security group ARNs using Outputs with Export names. In the endpoint stack, import them with Fn::ImportValue.",
      "B": "Store the subnet IDs and security group ARNs in an S3 object in the VPC stack and download them in CloudFormation custom resources in the endpoint stack.",
      "C": "Pass the subnet IDs and security group ARNs as parameters manually each time you deploy the endpoint stack.",
      "D": "Use a Lambda-backed custom resource in the endpoint stack to call DescribeStacks on the VPC stack and parse the JSON output."
    },
    "explanation": "Cross-stack references via Outputs and Fn::ImportValue is the recommended, maintainable approach for sharing values between CloudFormation stacks."
  },
  {
    "taskStatement": "3.2",
    "stem": "You need to configure application autoscaling for a SageMaker real-time endpoint variant using CloudFormation. Which CloudFormation resource type must you declare to register the endpoint variant with AWS Application Auto Scaling?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS::SageMaker::Endpoint",
      "B": "AWS::ApplicationAutoScaling::ScalableTarget",
      "C": "AWS::SageMaker::EndpointConfiguration",
      "D": "AWS::ApplicationAutoScaling::ScheduledAction"
    },
    "explanation": "AWS::ApplicationAutoScaling::ScalableTarget is required to register the SageMaker endpoint variant with Application Auto Scaling before you attach scaling policies."
  },
  {
    "taskStatement": "3.2",
    "stem": "Your SageMaker endpoint experiences unpredictable spikes in traffic throughout the day. You want to configure auto scaling to trigger when each instance receives more than 100 requests per minute. Which scaling metric should you choose in your scaling policy?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "CPUUtilization",
      "B": "ModelLatency",
      "C": "Invocation4xxErrors",
      "D": "InvocationsPerInstance"
    },
    "explanation": "InvocationsPerInstance is the supported Application Auto Scaling metric for SageMaker endpoints to scale based on request volume per instance."
  },
  {
    "taskStatement": "3.2",
    "stem": "You deploy a SageMaker endpoint inside a VPC without a NAT gateway to save cost. The endpoint fails to pull the container from ECR and the model artifacts from S3. Which minimum set of VPC endpoints must you script to restore functionality?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "An interface endpoint for com.amazonaws.<region>.s3 only",
      "B": "Interface endpoints for com.amazonaws.<region>.ecr.api and com.amazonaws.<region>.ecr.dkr only",
      "C": "Interface endpoints for com.amazonaws.<region>.ecr.api, com.amazonaws.<region>.ecr.dkr, and a gateway endpoint for com.amazonaws.<region>.s3",
      "D": "Interface endpoints for com.amazonaws.<region>.sagemaker.api and com.amazonaws.<region>.sagemaker.runtime"
    },
    "explanation": "SageMaker endpoints in a private VPC need ECR API and DKR interface endpoints plus the S3 gateway endpoint to pull container images and model artifacts."
  },
  {
    "taskStatement": "3.2",
    "stem": "You want to deploy a multi-model endpoint using CloudFormation to host multiple model artifacts in a single container. Which property must you use when defining AWS::SageMaker::Model to support this use case?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "PrimaryContainer",
      "B": "Containers",
      "C": "InferenceExecutionConfig",
      "D": "ModelPackageName"
    },
    "explanation": "The Containers property (a list) is required to define a multi-model endpoint in CloudFormation, whereas PrimaryContainer supports only a single container."
  },
  {
    "taskStatement": "3.2",
    "stem": "Your inference container is stored in Amazon ECR and your SageMaker model execution role must pull the image. When scripting the IAM role in CloudFormation, which managed policy should you attach to grant the minimum required permissions?",
    "correct": "C",
    "difficulty": "EASY",
    "answers": {
      "A": "AmazonSageMakerFullAccess",
      "B": "AmazonEC2ContainerServiceforEC2Role",
      "C": "AmazonEC2ContainerRegistryReadOnly",
      "D": "AmazonS3ReadOnlyAccess"
    },
    "explanation": "AmazonEC2ContainerRegistryReadOnly grants the least-privilege permissions necessary for SageMaker to pull container images from ECR."
  },
  {
    "taskStatement": "3.2",
    "stem": "Your organization hit the export limit for CloudFormation cross-stack references. You still need to share subnet IDs and security group IDs across stacks. What alternative approach should you use?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use nested stacks instead of separate stacks.",
      "B": "Store the values in SSM Parameter Store and reference them with dynamic references.",
      "C": "Batch all values into a single export by concatenating comma-delimited strings.",
      "D": "Use AWS Organizations to share parameters between accounts."
    },
    "explanation": "Storing shared configuration in SSM Parameter Store avoids export limits and allows multiple stacks to reference values via dynamic references."
  },
  {
    "taskStatement": "3.2",
    "stem": "You maintain several CloudFormation templates that define similar network resources for different teams. You want to reuse and standardize these resource definitions. Which CloudFormation feature is best suited for this purpose?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Custom resources",
      "B": "StackSets",
      "C": "Macros",
      "D": "Nested stacks"
    },
    "explanation": "Nested stacks allow you to factor out common resource definitions into reusable templates and include them in multiple parent stacks."
  },
  {
    "taskStatement": "3.2",
    "stem": "When writing AWS CDK code for your SageMaker endpoint, you need to import an existing VPC by its tags so your endpoint can deploy into it. Which CDK method is most appropriate?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "ec2.Vpc.fromVpcAttributes()",
      "B": "ec2.Vpc.import()",
      "C": "ec2.Vpc.fromLookup()",
      "D": "ec2.Vpc.fromEnv()"
    },
    "explanation": "ec2.Vpc.fromLookup() performs a context lookup by tags or name at synthesis time to import existing VPCs into CDK apps."
  },
  {
    "taskStatement": "3.2",
    "stem": "You are using AWS CDK to build and push a custom Docker container for SageMaker inference. Which CDK construct should you use to define and publish the image asset?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "ecr.Repository",
      "B": "DockerImageAsset",
      "C": "ContainerImage.fromAsset",
      "D": "EcrDockerImage"
    },
    "explanation": "DockerImageAsset (from aws-cdk-lib/aws-ecr-assets) builds a Docker image from a local directory and publishes it to ECR automatically."
  },
  {
    "taskStatement": "3.2",
    "stem": "You want to reduce training costs by using managed Spot Instances for a SageMaker training job defined in CloudFormation. Which property must you add to the AWS::SageMaker::TrainingJob resource?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "EnableManagedSpotTraining: true",
      "B": "UseSpotInstances: true",
      "C": "RuntimeSpotMode: Managed",
      "D": "SpotConfiguration: ManagedSpot"
    },
    "explanation": "EnableManagedSpotTraining set to true enables SageMaker managed Spot training for cost savings."
  },
  {
    "taskStatement": "3.2",
    "stem": "You need to deploy a Lambda function in the same VPC as your SageMaker endpoint so it can invoke the endpoint privately. Which CloudFormation property must you include in the AWS::Lambda::Function resource?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "NetworkConfiguration",
      "B": "SecurityGroupIds",
      "C": "SubnetIds",
      "D": "VpcConfig"
    },
    "explanation": "VpcConfig ({ SubnetIds, SecurityGroupIds }) on AWS::Lambda::Function places the Lambda inside the specified VPC."
  },
  {
    "taskStatement": "3.2",
    "stem": "You configured Application Auto Scaling for your SageMaker endpoint to use CPUUtilization, but you observe that scaling never occurs. Which explanation is correct?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "You must enable detailed monitoring on the endpoint to expose CPU metrics.",
      "B": "SageMaker endpoints only support InvocationsPerInstance as a built-in scaling metric.",
      "C": "CPUUtilization is supported only for asynchronous endpoints.",
      "D": "You must configure a CloudWatch alarm for CPUUtilization even when using Application Auto Scaling."
    },
    "explanation": "Application Auto Scaling for SageMaker real-time endpoints supports only the InvocationsPerInstance metric; CPUUtilization is not supported directly."
  },
  {
    "taskStatement": "3.2",
    "stem": "When you register your SageMaker endpoint variant with AWS Application Auto Scaling in CDK, what is the correct format of the resourceId property?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "endpoint/YourEndpointName/variant/AllTraffic",
      "B": "endpoint/YourEndpointName/variantName/AllTraffic",
      "C": "sagemaker:endpoint:YourEndpointName:variant:AllTraffic",
      "D": "YourEndpointName/AllTraffic"
    },
    "explanation": "The resourceId for a real-time SageMaker endpoint variant must be specified as \"endpoint/<endpointName>/variant/<variantName>\"."
  },
  {
    "taskStatement": "3.2",
    "stem": "You are deploying a new version of your VpcConfig for a SageMaker endpoint in CloudFormation. You modify the Subnets list in the template and redeploy, but the change is not applied. Why?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "CloudFormation cannot update VpcConfig on an existing EndpointConfiguration; you must modify another property.",
      "B": "You must delete the EndpointConfiguration resource manually before CloudFormation can apply changes.",
      "C": "CloudFormation only creates a new AWS::SageMaker::EndpointConfiguration when the Endpoint resource\u2019s EndpointConfigName property is updated; you haven\u2019t changed it.",
      "D": "VpcConfig changes require an update to AWS::SageMaker::Model, not EndpointConfiguration."
    },
    "explanation": "Modifying VpcConfig in the EndpointConfiguration has no effect until you update the Endpoint resource\u2019s EndpointConfigName to reference the new configuration."
  },
  {
    "taskStatement": "3.2",
    "stem": "You have an existing CloudFormation template defining your SageMaker model and endpoint. You decide to adopt AWS CDK but want to reuse the existing template without rewriting it. Which CDK construct allows you to embed and extend the existing template?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "CfnModel",
      "B": "TemplatePart",
      "C": "IncludeTemplate",
      "D": "CfnInclude"
    },
    "explanation": "CfnInclude (from aws-cdk-lib/cloudformation-include) lets you import an existing CloudFormation template into a CDK app for extension."
  },
  {
    "taskStatement": "3.3",
    "stem": "A data science team needs to implement a CI/CD pipeline that automates model training, testing, and deployment for a SageMaker ML model. The pipeline should enforce a manual approval before deploying to production and use AWS CodePipeline with minimal custom code. Which pipeline configuration meets these requirements?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Add a manual approval action between the CodeBuild action that trains the model and the CloudFormation Deploy action that updates the production SageMaker endpoint.",
      "B": "Use a Lambda function as a CodePipeline action to pause for approval between the training and deployment stages.",
      "C": "Configure the SageMaker Model Training action to require manual confirmation before executing the SageMaker Model Deploy action.",
      "D": "Use a CloudWatch Events rule to trigger a manual deployment after the training stage finishes."
    },
    "explanation": "CodePipeline supports manual approval actions natively; inserting an Approval action between the training (CodeBuild) stage and the deployment (CloudFormation Deploy endpoint) stage provides a built-in manual gate with minimal custom code."
  },
  {
    "taskStatement": "3.3",
    "stem": "An ML engineer must trigger a CI/CD pipeline whenever new training data arrives in an S3 bucket. The pipeline uses CodePipeline and CodeBuild to preprocess data and train a SageMaker model. Which configuration best accomplishes this requirement with event-driven automation?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Configure the S3 bucket as the Source stage in CodePipeline and enable change detection polling.",
      "B": "Create a CloudWatch Events rule for s3:ObjectCreated:* that targets the CodePipeline API to start a pipeline execution.",
      "C": "Use an S3 Event Notification to invoke a Lambda function that calls StartPipelineExecution for the CodePipeline.",
      "D": "Configure EventBridge to listen for S3 notifications and invoke the CodeBuild project directly."
    },
    "explanation": "Using an S3 event notification to invoke a Lambda function that calls StartPipelineExecution provides event-driven triggering with fine-grained control and low latency."
  },
  {
    "taskStatement": "3.3",
    "stem": "A team wants to deploy updated SageMaker endpoints in a blue/green deployment fashion as part of their CI/CD pipeline. They need to shift traffic gradually to the new model and enable easy rollback if issues occur. Which approach using AWS native services meets these requirements?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Add a SageMaker CreateModel action in CodePipeline with the 'Blue/Green' deployment type and specify the traffic shifting percentage.",
      "B": "Use CloudFormation Deploy action in CodePipeline configured with CodeDeploy SafeMode for CloudFormation change sets to perform traffic shifting between endpoints.",
      "C": "Invoke the SageMakerUpdateEndpoint API in CodeBuild and script traffic weights in the buildspec.",
      "D": "Configure a Lambda function in a pipeline action that calls UpdateEndpointWeightsAndCapacities for traffic shifting."
    },
    "explanation": "Using a CloudFormation Deploy action with CodeDeploy-managed change sets enables native blue/green deployments and traffic shifting with rollback capabilities without custom scripts."
  },
  {
    "taskStatement": "3.3",
    "stem": "A CodeBuild project in a CI/CD pipeline needs to access resources inside a VPC (private RDS and SageMaker endpoint). Builds are failing because the project cannot reach VPC-only endpoints. How should you modify the CodeBuild configuration to allow access while maintaining least privilege?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Add the CodeBuild project to the same security group as the RDS instance and SageMaker endpoint.",
      "B": "Configure the CodeBuild project with VPC configuration specifying the subnets and security groups that allow access to the private endpoints.",
      "C": "Create a NAT gateway in the VPC and enable public access for the CodeBuild project.",
      "D": "Enable CodeBuild network isolation and whitelist the VPC CIDR block."
    },
    "explanation": "Configuring the CodeBuild project with the correct VPC, subnets, and security groups allows it to access private resources securely and maintain least privilege."
  },
  {
    "taskStatement": "3.3",
    "stem": "You need to add automated testing stages to your ML CI/CD pipeline: unit tests for preprocessing code, integration tests against a development SageMaker endpoint, and performance validation of the new model. Which pipeline actions should you include to satisfy these requirements?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Three CodeBuild actions: one running pytest for code, one invoking the dev endpoint via AWS CLI, and one running a custom performance test script.",
      "B": "One CodeBuild action with sequential buildspec phases for unit, integration, and performance tests.",
      "C": "Unit tests as a CodeBuild action, integration tests as a Lambda invoke action, and performance tests as a SageMaker Batch Transform action.",
      "D": "Integration tests first, then unit tests, then performance validation, all in a single CodeBuild action."
    },
    "explanation": "Separating testing into distinct CodeBuild actions for unit, integration, and performance ensures isolation and clear visibility of failures, and uses the native build environment to invoke tests."
  },
  {
    "taskStatement": "3.3",
    "stem": "An ML engineer has a SageMaker Pipeline defined for data preprocessing, model training, and evaluation. To include this SageMaker Pipeline in a larger CodePipeline CI/CD workflow, which native CodePipeline action type should they use to start and monitor the SageMaker Pipeline execution?",
    "correct": "C",
    "difficulty": "EASY",
    "answers": {
      "A": "AWS CloudFormation action with a custom resource to invoke the SageMaker Pipeline.",
      "B": "AWS Lambda invoke action that calls StartPipelineExecution.",
      "C": "SageMakerPipeline action type provided by AWS CodePipeline.",
      "D": "CodeBuild action using AWS CLI to start the SageMaker Pipeline."
    },
    "explanation": "CodePipeline provides the SageMakerPipeline action to natively integrate SageMaker Pipelines as a stage, handling execution and status monitoring without custom scripts."
  },
  {
    "taskStatement": "3.3",
    "stem": "Your ML CI/CD pipeline uses CodeBuild to package and push Docker images to a private ECR repository encrypted with a customer-managed KMS key. Builds are failing when CodeBuild attempts to push the image. What minimum IAM policy change should you apply to the CodeBuild service role to resolve this issue?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Add kms:Decrypt permission on the KMS key used to encrypt the ECR repository.",
      "B": "Add kms:GenerateDataKey permission on the KMS key.",
      "C": "Add kms:Encrypt and kms:Decrypt permissions on the KMS key.",
      "D": "Add kms:DescribeKey permission on the KMS key."
    },
    "explanation": "CodeBuild needs kms:GenerateDataKey to encrypt the image layers before pushing to ECR. Decrypt is not required for push operations."
  },
  {
    "taskStatement": "3.3",
    "stem": "A team adopts GitFlow branching for ML code and infrastructure definitions. How should branches map to CodePipeline stages to implement dev, test, and prod environments with automated promotion?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Map the 'develop' branch as the Source for the dev pipeline, 'release' for test, and 'master' for prod, each with its own CodePipeline using source triggers.",
      "B": "Use 'feature' branches for dev, 'develop' for test, and 'release' for prod, all in a single pipeline with multiple source actions.",
      "C": "Use 'master' branch for all environments and control deployments with manual approval actions.",
      "D": "Use 'hotfix' branches to promote code directly to production pipeline."
    },
    "explanation": "GitFlow maps develop \u2192 dev pipeline, release \u2192 test pipeline, and master \u2192 production pipeline, enabling automated promotions based on branch."
  },
  {
    "taskStatement": "3.3",
    "stem": "You configured SageMaker Model Monitor to detect data drift for a production endpoint. You want your CI/CD pipeline to automatically retrain the model when drift is detected. Which event pattern and target configuration should you use in EventBridge to integrate drift detection with your pipeline?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Event pattern: SageMaker Model Monitor DataQualityCheckNotification; Target: CodePipeline StartPipelineExecution action.",
      "B": "Event pattern: CloudWatch Alarm for drift metric; Target: Lambda that updates the SageMaker endpoint.",
      "C": "Event pattern: SageMaker TrainingJobStateChange; Target: EventBridge rule that triggers retraining.",
      "D": "Event pattern: S3:ObjectCreated for captured data; Target: CodeBuild to start training."
    },
    "explanation": "Model Monitor emits DataQualityCheckNotification events; capturing these in an EventBridge rule targeting StartPipelineExecution automates retraining when drift is detected."
  },
  {
    "taskStatement": "3.3",
    "stem": "You want to define your entire CI/CD pipeline in AWS CDK, including stages for building, testing, and deploying a SageMaker model. Which CDK construct and patterns should you use to best represent stages and actions?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use pipelines.CodePipeline construct with pipelines.CodeBuildStep and pipelines.ShellStep.",
      "B": "Use aws_codepipeline.Pipeline with aws_codepipeline_actions.CodeBuildAction and aws_codepipeline_actions.CloudFormationCreateUpdateStackAction.",
      "C": "Use aws_sagemaker.CfnPipeline and embed CodePipeline definitions as metadata.",
      "D": "Use a single CodeBuild project in CDK and run all steps in buildspec."
    },
    "explanation": "Using aws_codepipeline.Pipeline with native CodeBuild and CloudFormation actions allows explicit definition of CI/CD stages and is the recommended pattern in CDK for pipelines."
  },
  {
    "taskStatement": "3.3",
    "stem": "During a CodePipeline execution, the CodeBuild step that builds the Docker container for a custom SageMaker algorithm fails due to insufficient privileges for Docker. Which setting in the CodeBuild project should you enable to allow Docker builds?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Set privileged mode to true in the CodeBuild project settings.",
      "B": "Assign the CodeBuild role to the DockerUsers group in IAM.",
      "C": "Enable inbound and outbound network access in CodeBuild.",
      "D": "Grant CodeBuild service role permissions for sagemaker:CreateAlgorithm."
    },
    "explanation": "Privileged mode allows CodeBuild to run Docker commands needed for building and pushing container images."
  },
  {
    "taskStatement": "3.3",
    "stem": "You need to validate model performance metrics generated during training before deploying the model in the CI/CD pipeline. Which CodePipeline action can you use to automatically compare the new metrics against a baseline and fail the pipeline if the model does not meet thresholds?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use a Lambda invoke action that reads metrics from S3 and throws an error if thresholds are not met.",
      "B": "Use a CloudWatch Alarm action in CodePipeline to evaluate metrics.",
      "C": "Use the built-in SageMaker Model Quality check action in CodePipeline.",
      "D": "Use a CodeBuild action with a buildspec that runs a custom validation script."
    },
    "explanation": "CodePipeline does not have a native metric gating action; invoking a Lambda to assert metric thresholds provides a serverless, automated gate."
  },
  {
    "taskStatement": "3.3",
    "stem": "In your pipeline, the output of the model training stage is a model artifact location in S3. You need to pass this dynamic S3 path to the SageMaker CreateModel deployment stage in CodePipeline. How should you configure the deployment action to consume this artifact location?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use CodePipeline artifact variables and parameter overrides in the SageMaker CreateModel action configuration.",
      "B": "Hardcode the S3 path in the CreateModel action ARN.",
      "C": "Write the path to Systems Manager Parameter Store and reference it in the deployment stage.",
      "D": "Use a Lambda function to retrieve the location and call CreateModel."
    },
    "explanation": "Artifact variables allow CodePipeline stages to access outputs from previous stages and dynamically pass them to action parameters without custom code."
  },
  {
    "taskStatement": "3.3",
    "stem": "Your team is evaluating whether to use SageMaker Pipelines or AWS CodePipeline for end-to-end ML workflows. They need automated data preprocessing, hyperparameter tuning, model evaluation, and deployment gates. Which is the most appropriate orchestration tool?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use SageMaker Pipelines for ML steps and embed it as a stage in AWS CodePipeline for approvals and multi-account deployments.",
      "B": "Use AWS CodePipeline exclusively for all ML and deployment tasks.",
      "C": "Use AWS Step Functions to orchestrate both ML and deployment steps.",
      "D": "Use Amazon Managed Workflows for Apache Airflow (MWAA) to orchestrate SageMaker training and deploy."
    },
    "explanation": "SageMaker Pipelines provides first-class support for ML workflows; embedding it in CodePipeline adds enterprise-grade CI/CD features like approvals and cross-account deployments."
  },
  {
    "taskStatement": "3.3",
    "stem": "To implement automated rollback on a SageMaker endpoint if post-deployment smoke tests fail, which deployment pattern should you configure in CodePipeline and CodeDeploy?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "All-at-once deployment with a Lambda test hook in CodeDeploy that triggers rollback on failure.",
      "B": "Canary deployment type in CloudFormation Deploy action with pre-traffic and post-traffic validation Lambda hooks.",
      "C": "Linear deployment with time-based rollout and manual approval for rollback.",
      "D": "In-place deployment with CodeBuild test stage preceding deployment."
    },
    "explanation": "Using a canary deployment with pre- and post-traffic validation hooks in CodeDeploy allows automated testing and rollback if smoke tests fail."
  },
  {
    "taskStatement": "4.1",
    "stem": "An ML engineer has deployed a real-time SageMaker inference endpoint and needs to detect both input feature distribution drift and prediction quality degradation in production with minimal custom code. Which combination of SageMaker services and configurations should the engineer use?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Configure DataCaptureConfig on the endpoint, deploy a DefaultModelMonitor job to detect data drift, and schedule a ModelQualityMonitor job with ground truth to detect prediction drift.",
      "B": "Configure DataCaptureConfig on the endpoint and schedule a Clarify DataBiasMonitor job to detect both data and prediction drift.",
      "C": "Stream inference events to Kinesis Data Firehose and use AWS Glue to analyze drift for both features and predictions.",
      "D": "Use SageMaker Clarify ModelExplainabilityMonitor to detect distribution shifts and model accuracy degradation."
    },
    "explanation": "Use DataCaptureConfig + DefaultModelMonitor for input drift and ModelQualityMonitor with ground truth for prediction/concept drift; other options do not cover both aspects or require more custom work."
  },
  {
    "taskStatement": "4.1",
    "stem": "Before enabling continuous data drift detection on a production SageMaker endpoint, an ML engineer must establish baseline statistics and constraints. Which approach should the engineer use to generate these baselines automatically?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Run a SageMaker Processing job using the DefaultModelMonitor container on a representative historical dataset in S3.",
      "B": "Use SageMaker Clarify DataBiasMonitor to create baseline drift constraints on the training data.",
      "C": "Write custom code to compute statistics and manually author the constraint JSON file.",
      "D": "Use AWS Glue DataBrew to profile the data and export a constraint file to S3."
    },
    "explanation": "The DefaultModelMonitor Processing container provides built-in functionality to compute baseline statistics and constraints; other options either don\u2019t generate constraints in the required format or don\u2019t support SageMaker\u2019s drift detectors."
  },
  {
    "taskStatement": "4.1",
    "stem": "A financial services company must monitor inference data while excluding PII fields from retention. Which configuration in SageMaker Model Monitor allows the engineer to capture inference payloads but filter out PII attributes?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Set DataCaptureConfig sample_percentage to 0 and use encryption to prevent PII capture.",
      "B": "Use Clarify ModelBiasMonitor with an exclude_columns parameter for PII fields.",
      "C": "Configure DataCaptureConfig with a CaptureFilter to exclude PII JSON paths before writing to S3.",
      "D": "Enable a processing container script to mask PII after the monitor job runs."
    },
    "explanation": "DataCaptureConfig\u2019s CaptureFilter lets you specify JSONPath or CSV column filters so only non-PII fields are captured; other methods either capture PII or require post-processing."
  },
  {
    "taskStatement": "4.1",
    "stem": "A Model Monitor violation report shows a numeric feature\u2019s distribution exceeding baseline constraints for variance only. What is the most appropriate next step?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Adjust the variance threshold in the baseline constraint to suppress false positives.",
      "B": "Investigate the production data distribution change, update training data or retrain the model if the shift reflects new valid patterns.",
      "C": "Disable monitoring for that feature to reduce alert noise.",
      "D": "Regenerate the baseline constraints on the current production data without retraining."
    },
    "explanation": "A constraint violation indicates real drift; you should investigate and retrain or augment training data if needed. Changing thresholds or disabling the monitor risks missing true drift."
  },
  {
    "taskStatement": "4.1",
    "stem": "An operations team requires near real-time alerts whenever model input data drift is detected. Which integration provides automated notifications upon Model Monitor constraint violations?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Have a Lambda function poll the S3 violation reports folder every minute.",
      "B": "Create an Amazon EventBridge rule for SageMaker MonitoringExecutionStatus change events and target an SNS topic.",
      "C": "Subscribe an SNS notification directly to the Model Monitor S3 bucket.",
      "D": "Use CloudWatch Logs Insights to search for violations and trigger alarms."
    },
    "explanation": "EventBridge can capture SageMaker monitoring execution status change events and forward them to SNS; polling or log-based solutions introduce delay or complexity."
  },
  {
    "taskStatement": "4.1",
    "stem": "A team wants to detect anomalies in inference latency, error rates, and invoke rates on a SageMaker real-time endpoint. Which approach will meet these requirements with the least operational overhead?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "Use Amazon CloudWatch built-in metrics (Latency, Invocations, 4xx/5xx error counts) and configure CloudWatch Alarms.",
      "B": "Use SageMaker Model Monitor to detect infrastructure anomalies.",
      "C": "Use SageMaker Clarify to monitor model performance metrics.",
      "D": "Enable AWS CloudTrail on the endpoint and analyze logs in S3."
    },
    "explanation": "CloudWatch automatically captures endpoint performance and error metrics; Model Monitor focuses on data quality, and Clarify focuses on bias/explainability."
  },
  {
    "taskStatement": "4.1",
    "stem": "Which statement best describes concept drift in a deployed ML model?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "A change in the input feature distribution compared to baseline data.",
      "B": "A change in the statistical relationship between input features and target labels over time.",
      "C": "An imbalance in class label frequencies in production data.",
      "D": "A bias introduced during model training that only affects edge cases."
    },
    "explanation": "Concept drift refers to changes in P(Y|X), i.e., the relationship between features and labels; data drift is about P(X) changes."
  },
  {
    "taskStatement": "4.1",
    "stem": "An ML engineer needs to gradually shift traffic to a canary variant of a SageMaker endpoint and automatically roll back if error rates exceed a threshold. Which deployment mechanism should they use?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use SageMaker multi\u2010variant endpoints with AWS CodeDeploy canary traffic\u2010shifting and configure a CloudWatch Alarm on 5xx error rate.",
      "B": "Deploy two separate endpoints and manually switch DNS when errors are low.",
      "C": "Use SageMaker asynchronous endpoints with weighted routing.",
      "D": "Use SageMaker batch transform jobs scheduled hourly and compare error rates."
    },
    "explanation": "SageMaker multi\u2010variant endpoints integrated with CodeDeploy support canary traffic shifts and automatic rollback via CloudWatch Alarms."
  },
  {
    "taskStatement": "4.1",
    "stem": "To detect shifts in feature attributions of a production model over time, which SageMaker monitoring job should an ML engineer schedule?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "A Clarify ModelExplainabilityMonitor job with SHAP baseline and monitoring configuration.",
      "B": "A Clarify DataBiasMonitor job on the inference data.",
      "C": "A DefaultModelMonitor job focusing on data quality constraints.",
      "D": "A ModelQualityMonitor job comparing accuracy against ground truth."
    },
    "explanation": "ModelExplainabilityMonitor (SHAP) jobs track how feature attributions change; data bias or quality monitors don\u2019t measure attribution shifts."
  },
  {
    "taskStatement": "4.1",
    "stem": "What is the minimum supported frequency for scheduling a SageMaker MonitoringSchedule to detect production data drift?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "Every 5 minutes",
      "B": "Every 1 minute",
      "C": "Every hour",
      "D": "Every 24 hours"
    },
    "explanation": "SageMaker MonitoringSchedule supports a minimum interval of 5 minutes; shorter intervals are not allowed."
  },
  {
    "taskStatement": "4.1",
    "stem": "An engineering team uses batch transform jobs for asynchronous inference and needs to monitor prediction quality drift against offline ground truth. Which solution requires the least operational overhead?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable DataCaptureConfig on the batch transform endpoint and run DefaultModelMonitor.",
      "B": "Implement a custom Lambda to compare S3 outputs to ground truth and publish metrics.",
      "C": "Schedule a ModelQualityMonitor ProcessingJob using the batch transform output folder and S3 ground truth labels.",
      "D": "Use Clarify DataBiasMonitor on the batch transform results."
    },
    "explanation": "Scheduling a ModelQualityMonitor ProcessingJob directly on transform outputs and labels uses built-in monitoring; other options require custom polling or inappropriate monitors."
  },
  {
    "taskStatement": "4.1",
    "stem": "A production endpoint\u2019s data quality monitor runs but model accuracy has degraded without any data drift reported. What additional monitoring configuration is required?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Add a Clarify DataBiasMonitor to detect label shifts.",
      "B": "Increase the sampling percentage in DataCaptureConfig.",
      "C": "Enable multivariant monitoring on the same monitor.",
      "D": "Configure and schedule a ModelQualityMonitor job with ground truth labels to detect accuracy degradation."
    },
    "explanation": "DataQuality monitors P(X) shifts, not P(Y|X); ModelQualityMonitor with ground truth is required to detect concept or accuracy drift."
  },
  {
    "taskStatement": "4.1",
    "stem": "A company must monitor production inference outputs for fairness drift (e.g., change in demographic parity) over time. Which SageMaker Clarify monitor should they schedule?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Clarify DataBiasMonitor",
      "B": "Clarify ModelBiasMonitor",
      "C": "ModelExplainabilityMonitor",
      "D": "DefaultModelMonitor"
    },
    "explanation": "ModelBiasMonitor detects fairness metrics (demographic parity, equalized odds) on inference data; DataBiasMonitor analyzes training set biases."
  },
  {
    "taskStatement": "4.1",
    "stem": "An ML engineer must filter out sensitive fields from inference data before it reaches the Model Monitor processing container. Which component should they customize?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Provide a custom preprocessing script in the MonitoringSchedule\u2019s ProcessingJobConfig.",
      "B": "Write a post-monitoring ETL job to remove sensitive columns from violation reports.",
      "C": "Modify the DefaultModelMonitor container image to drop PII.",
      "D": "Configure DataCaptureConfig to drop features via sample_percentage."
    },
    "explanation": "A custom preprocessing script in MonitoringSchedule\u2019s ProcessingJobConfig lets you transform or filter data before constraint evaluation; other methods occur after capture or require image modification."
  },
  {
    "taskStatement": "4.1",
    "stem": "An ML engineer wants to integrate drift detection into a SageMaker Pipelines workflow and automatically trigger retraining when drift is detected. Which pipeline step should they include to evaluate drift violations before invoking the retraining branch?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use a MonitoringStep with fail_on_violation=True to stop the pipeline on any drift.",
      "B": "Use a ConditionStep to check if the MonitoringStep status equals 'Failed'.",
      "C": "Use a RegisterModel step to register the model only if no drift is detected.",
      "D": "Use a ConditionStep to inspect the MonitoringStep output property 'BaselineViolations' > 0 and branch accordingly."
    },
    "explanation": "A ConditionStep can examine the MonitoringStep output (e.g., violated constraint count) and route to retraining; this avoids hard failures and enables branching logic."
  },
  {
    "taskStatement": "4.2",
    "stem": "An ML team needs to right-size SageMaker inference endpoints to minimize cost while maintaining performance. They want to benchmark actual model inference performance (latency and under various loads) to choose optimal instance types. Which AWS service should they use?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "AWS Compute Optimizer",
      "B": "AWS SageMaker Inference Recommender",
      "C": "AWS Cost Explorer",
      "D": "AWS Trusted Advisor"
    },
    "explanation": "SageMaker Inference Recommender runs performance benchmarks on your model to recommend optimal instance families and sizes. Compute Optimizer provides general EC2/EBS recommendations, not ML-specific inference benchmarks."
  },
  {
    "taskStatement": "4.2",
    "stem": "A financial organization observes unexpected monthly spikes in SageMaker inference costs due to seasonal usage. They need to receive near real-time alerts when cost anomalies occur in their AWS account. Which solution meets this requirement with minimal operational overhead?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Create a CloudWatch alarm on the AWS/Billing namespace EstimatedCharges metric",
      "B": "Configure an AWS Budget with email notifications when forecasted spend exceeds a threshold",
      "C": "Enable AWS Cost Anomaly Detection and configure alerts for anomaly events",
      "D": "Schedule daily Cost Explorer reports and parse them with Lambda for thresholds"
    },
    "explanation": "AWS Cost Anomaly Detection uses machine learning to detect unusual cost spikes and can send near real-time alerts without manual report parsing or budget forecasting."
  },
  {
    "taskStatement": "4.2",
    "stem": "A deployed SageMaker endpoint is experiencing intermittent increases in tail latency. The ML engineer needs to trace requests through the network stack and service mesh to pinpoint network bottlenecks. Which AWS service or feature should they enable?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Run CloudWatch Logs Insights on the endpoint logs",
      "B": "Monitor EC2 CPUUtilization metrics in CloudWatch",
      "C": "Enable AWS X-Ray integration with SageMaker",
      "D": "Enable VPC Flow Logs on the endpoint\u2019s ENIs"
    },
    "explanation": "AWS X-Ray provides distributed tracing across network and service calls, enabling end-to-end latency analysis. VPC Flow Logs show packet metadata but not distributed service traces."
  },
  {
    "taskStatement": "4.2",
    "stem": "For compliance, the security team wants to audit all Amazon SageMaker CreateEndpoint API calls over the past 30 days and retain logs for 90 days. Which configuration achieves this with the LEAST administrative overhead and ensures immutability?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "Enable CloudTrail management events for SageMaker and send to an S3 bucket with Object Lock enabled",
      "B": "Create a CloudWatch Events rule for CreateEndpoint and log events to CloudWatch Logs",
      "C": "Enable CloudTrail Data events on CreateEndpoint and stream to Kinesis Data Firehose",
      "D": "Enable CloudTrail Insights to capture anomalous CreateEndpoint activity"
    },
    "explanation": "CloudTrail management events capture all CreateEndpoint API calls; delivering them to an S3 bucket with Object Lock provides immutability. Data events and Insights are unnecessary for standard API logging."
  },
  {
    "taskStatement": "4.2",
    "stem": "A director wants a single dashboard that shows per-endpoint invocation count, average 95th percentile latency, and cost per hour for each SageMaker endpoint in the account. Which solution meets this requirement with minimal development effort?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Build a custom web app that calls CloudWatch metrics API and Cost Explorer API",
      "B": "Use Amazon QuickSight to visualize a dataset combining AWS Cost and Usage Reports and CloudWatch metrics",
      "C": "Use CloudWatch Dashboards with metric math combining performance and billing metrics",
      "D": "Use the AWS Pricing API to fetch rates and combine with CloudWatch metrics in dashboards"
    },
    "explanation": "QuickSight can natively ingest both Cost and Usage Report data (cost per resource) and CloudWatch metrics to build a unified dashboard with minimal custom code. CloudWatch Dashboards cannot display cost per resource granularity."
  },
  {
    "taskStatement": "4.2",
    "stem": "To reduce off-peak costs, an ML engineer wants to automatically update SageMaker endpoint instance types to smaller ones every night and revert to original sizes each morning. Which solution requires the LEAST operational overhead?",
    "correct": "B",
    "difficulty": "EASY",
    "answers": {
      "A": "Use SageMaker Pipelines with a scheduled pipeline to call UpdateEndpointConfig",
      "B": "Create EventBridge cron rules that trigger Lambda functions invoking UpdateEndpointConfig",
      "C": "Configure AWS Step Functions with Wait states and Lambda tasks to update endpoints",
      "D": "Use Systems Manager Automation documents scheduled via State Manager"
    },
    "explanation": "Using EventBridge with cron schedules triggering lightweight Lambda functions to call UpdateEndpointConfig is the simplest and lowest-overhead scheduling solution."
  },
  {
    "taskStatement": "4.2",
    "stem": "A SageMaker real-time endpoint is exhibiting memory pressure, but memory utilization is not visible in CloudWatch by default. To monitor container-level memory for this endpoint, what should the ML engineer do?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable SageMaker Debugger profiling to collect memory metrics",
      "B": "Deploy the endpoint on EC2 instances where memory metrics are published by default",
      "C": "Install and configure the CloudWatch agent via a container lifecycle configuration",
      "D": "Use CloudWatch metric filters on container logs to estimate memory usage"
    },
    "explanation": "The CloudWatch agent must be installed inside the container via a lifecycle configuration script to collect OS-level metrics such as memory usage. Debugger profiles model internals, not OS memory."
  },
  {
    "taskStatement": "4.2",
    "stem": "An ML application experiences periodic bursts of inference requests that exceed the 70% CPU utilization threshold. The ML engineer wants to add step scaling to the existing auto scaling policy to provision two additional instances when InvocationsPerInstance exceeds 100 for 2 minutes, and remove one instance when it drops below 50 for 5 minutes. Which configuration meets these requirements?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Define two CloudWatch alarms on the SageMakerVariantInvocationsPerInstance metric with thresholds 100 (2-minute evaluation) and 50 (5-minute evaluation), and attach a step scaling policy with +2 and -1 adjustments",
      "B": "Use CPUUtilization alarms instead of InvocationsPerInstance and a target-tracking policy",
      "C": "Use a single target-tracking policy on InvocationsPerInstance with a target value of 75",
      "D": "Configure two AWS Budgets for usage and link them to auto scaling actions"
    },
    "explanation": "Step scaling requires separate CloudWatch alarms on the SageMakerVariantInvocationsPerInstance metric with specified evaluation periods and corresponding step adjustments (+2, -1). Using CPUUtilization or budgets would not meet the specified invocation-based requirements."
  },
  {
    "taskStatement": "4.2",
    "stem": "A financial ML endpoint must maintain 99th percentile latency under 200 ms. To automate scaling to achieve this SLO, which Application Auto Scaling policy should be configured?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Target tracking policy on CPUUtilization at 70%",
      "B": "Target tracking policy on SageMakerVariantInvocationLatency at the p99 200 ms target",
      "C": "Step scaling policy on InvocationsPerInstance thresholds",
      "D": "Step scaling policy on ModelLatencyAvg metric"
    },
    "explanation": "A target-tracking policy on the p99 lifecycle metric of SageMakerVariantInvocationLatency targeting a 200 ms threshold will automatically adjust capacity to maintain the latency SLO. CPUUtilization or average latency would be less precise for the p99 requirement."
  },
  {
    "taskStatement": "4.2",
    "stem": "After deploying a model, the team wants to trigger a retraining SageMaker pipeline whenever a new training dataset file is uploaded to S3. They also want to log all such retraining triggers for audit. Which combination of AWS services should they use?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Configure an S3 EventBridge notification on object upload to start the pipeline, and rely on CloudTrail to log the pipeline StartPipelineExecution API call",
      "B": "Use a CloudWatch scheduled rule to scan S3 daily and start the pipeline if new files exist, logging via CloudWatch Logs",
      "C": "Deploy a Lambda function to poll S3 every hour, invoke the pipeline, and log to DynamoDB",
      "D": "Send S3 events to SNS and have the pipeline poll SNS, with audit in CloudWatch Metrics"
    },
    "explanation": "Using an S3 EventBridge notification provides immediate trigger of the pipeline on new data. CloudTrail automatically logs the StartPipelineExecution API call for auditing."
  },
  {
    "taskStatement": "4.2",
    "stem": "Which AWS service provides generalized compute resource recommendations, including SageMaker endpoints and EC2 instances, based on historical utilization metrics and can be applied across accounts with minimal configuration?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "SageMaker Inference Recommender",
      "B": "AWS Compute Optimizer",
      "C": "AWS Cost Explorer rightsizing recommendations",
      "D": "AWS Trusted Advisor"
    },
    "explanation": "AWS Compute Optimizer analyzes historical utilization across EC2, SageMaker endpoints, and other resources to recommend optimal instance types, whereas Inference Recommender focuses specifically on ML inference benchmarking."
  },
  {
    "taskStatement": "4.2",
    "stem": "An engineering team needs to break down monthly SageMaker spend by project. They require cost allocation by tagging endpoints and jobs, and reporting at tag granularity. Which steps should they take?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "Tag SageMaker endpoints and training jobs with project identifiers, activate those tags in AWS Billing Cost Allocation Tags, and use Cost Explorer with tag filters",
      "B": "Create separate AWS accounts per project and use consolidated billing",
      "C": "Use CloudWatch metric dimensions to filter cost metrics",
      "D": "Group SageMaker resources into separate CloudFormation stacks and view stack costs"
    },
    "explanation": "Activating resource tags for cost allocation and filtering in Cost Explorer is the standard way to break down costs by project without needing separate accounts."
  },
  {
    "taskStatement": "4.2",
    "stem": "To optimize inference costs for stable production workloads with predictable traffic, which purchasing option should an ML engineer choose?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "On-Demand SageMaker Instances",
      "B": "SageMaker Savings Plans",
      "C": "EC2 Reserved Instances attached to SageMaker endpoints",
      "D": "SageMaker Spot Instances"
    },
    "explanation": "SageMaker Savings Plans offer a commitment discount on SageMaker compute usage for stable workloads. Spot Instances are not supported for real-time endpoints and Reserved Instances apply only to EC2, not SageMaker directly."
  },
  {
    "taskStatement": "4.2",
    "stem": "A model training workflow uses Amazon FSx for Lustre as input storage. The ML engineer notices frequent I/O throttling. To monitor FSx performance and identify bottlenecks, which CloudWatch metrics should they add to their dashboard?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "BurstCreditBalance and DataReadIOBytes",
      "B": "FreeStorageCapacity and NumberOfConnections",
      "C": "DataWriteIOPS and MetadataOperations",
      "D": "PercentIOPSUtilization and NetworkThroughput"
    },
    "explanation": "BurstCreditBalance shows available throughput credits and DataReadIOBytes shows actual read throughput, key metrics for diagnosing FSx for Lustre I/O throttling issues."
  },
  {
    "taskStatement": "4.2",
    "stem": "An ML engineer is troubleshooting intermittent 5XX errors from inference endpoints. The engineer has enabled data capture to S3. To quickly identify patterns in the errors, which approach provides the fastest operational insight?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Configure a CloudWatch Logs subscription filter to Lambda to parse S3 logs",
      "B": "Use CloudWatch Logs Insights with a query on the /aws/sagemaker/Endpoints log group to count HTTPStatus5XX occurrences",
      "C": "Download the S3 logs locally and run custom scripts",
      "D": "Use AWS X-Ray traces to calculate error percentages"
    },
    "explanation": "CloudWatch Logs Insights can rapidly query large volumes of log data in the /aws/sagemaker/Endpoints log group to identify and aggregate 5XX errors without moving data."
  },
  {
    "taskStatement": "4.3",
    "stem": "An ML engineer has deployed a SageMaker inference endpoint that writes inference results and debug logs to an S3 bucket encrypted with a customer-managed KMS key. The security team requires that only this endpoint can write to the bucket and decrypt the objects. Which configuration meets these requirements with the least administrative effort?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Attach an IAM policy to the SageMaker execution role allowing s3:PutObject on the bucket and kms:Decrypt on the CMK.",
      "B": "Configure the S3 bucket policy to allow s3:PutObject only from the VPC endpoint used by SageMaker.",
      "C": "Configure the S3 bucket policy with a condition aws:SourceArn equal to the SageMaker endpoint ARN, and update the KMS key policy to grant only the SageMaker execution role decrypt permissions.",
      "D": "Create an S3 ACL that grants the SageMaker service principal write access and rely on the IAM role for decryption."
    },
    "explanation": "A resource-based S3 bucket policy using aws:SourceArn ensures only that SageMaker endpoint can write objects, and the CMK key policy must explicitly grant the SageMaker execution role kms:Decrypt. IAM identity policies alone or ACLs cannot enforce both write and decrypt at the resource level as simply."
  },
  {
    "taskStatement": "4.3",
    "stem": "A security audit finds that any IAM user in the account can create SageMaker Studio user profiles, but the security team wants only members of the IAM group ProdMLUsers to be allowed. Which approach enforces this requirement at the SageMaker domain level?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Add an identity-based IAM policy to the ProdMLUsers group allowing sagemaker:CreateUserProfile.",
      "B": "Attach a Service Control Policy in AWS Organizations denying sagemaker:CreateUserProfile unless the user is in ProdMLUsers.",
      "C": "Attach a resource-based policy to the SageMaker Domain that allows CreateUserProfile only when aws:PrincipalIsInGroup equals ProdMLUsers.",
      "D": "Use an S3 bucket policy to block studio creation from principals not in the group."
    },
    "explanation": "A SageMaker Domain resource policy can restrict CreateUserProfile to principals in a specific IAM group via aws:PrincipalIsInGroup. SCPs or identity policies alone cannot enforce at the domain resource level."
  },
  {
    "taskStatement": "4.3",
    "stem": "An organization wants to run SageMaker training jobs in a VPC with no internet egress, but the training data resides in S3. Which network configuration meets these requirements while minimizing cost and operational overhead?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Provision a NAT Gateway in the private subnet to access S3.",
      "B": "Attach an Internet Gateway to the VPC and allow routing to S3.",
      "C": "Create a VPC Gateway endpoint for S3 and update the private route table to direct S3 traffic through it.",
      "D": "Create an Interface VPC endpoint for SageMaker in the VPC and rely on AWS private networking for S3 access."
    },
    "explanation": "A Gateway VPC endpoint for S3 allows private, cost-effective access to S3 from a VPC with no internet egress. An interface endpoint for SageMaker does not enable S3 data access, and a NAT Gateway adds cost."
  },
  {
    "taskStatement": "4.3",
    "stem": "A data science team wants to share a SageMaker Model Registry package with a partner AWS account. The model artifacts are encrypted by a customer-managed CMK. The partner must be able to deploy the model from their account. Which combination of steps is required?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "In the CMK console, add the partner account as a key administrator, and update the model package resource policy to grant DescribeModelPackage.",
      "B": "Add the partner AWS account principal to the CMK key policy with decrypt permissions, and attach a resource policy to the model package allowing that account DescribeModelPackage and CreateModel.",
      "C": "Enable cross-account sharing in SageMaker Model Registry settings and share the CMK ARN.",
      "D": "Create a cross-account IAM role in the partner account with sagemaker:CreateModel permission and trust the partner\u2019s account; no changes to CMK."
    },
    "explanation": "Both the CMK and the model package need resource policies. The key policy must allow the partner account to decrypt, and the model package policy must allow DescribeModelPackage and CreateModel so they can register and deploy it."
  },
  {
    "taskStatement": "4.3",
    "stem": "A centralized CodePipeline in Account A builds ML packages and needs to deploy a trained model to a SageMaker endpoint in Account B. The security team requires least privilege. How should the cross-account permissions be configured?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "In Account A, grant the CodePipeline role sagemaker:* across all resources in Account B and trust Account B\u2019s principals.",
      "B": "Use CloudFormation StackSets from Account A to provision SageMaker resources in Account B without IAM role assumption.",
      "C": "In Account B, create an IAM role with sagemaker:CreateEndpoint and related actions, trust policy allowing assumption by the CodePipeline role\u2019s ARN in Account A, and configure the pipeline to assume that role.",
      "D": "In Account B, add the CodePipeline service principal from Account A to an IAM group with full SageMaker privileges."
    },
    "explanation": "The pipeline in Account A should assume a dedicated IAM role in Account B that has only the permissions needed to deploy the SageMaker endpoint. This follows least-privilege and standard cross-account role assumption practices."
  },
  {
    "taskStatement": "4.3",
    "stem": "The security team requires that all SageMaker data-plane API calls (for example, CreateModel, InvokeEndpoint) be logged in CloudTrail. By default, only management events are recorded. What must the ML engineer do to capture these data-plane operations?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable CloudTrail management events in all regions.",
      "B": "In the CloudTrail console, enable data events for Amazon SageMaker to record data-plane API calls.",
      "C": "Enable AWS Config recording for SageMaker resource types.",
      "D": "Create CloudWatch Logs metric filters for SageMaker API calls."
    },
    "explanation": "To log data-plane API operations such as CreateModel and InvokeEndpoint, you must enable CloudTrail data events specifically for the SageMaker service. Management events alone do not capture these."
  },
  {
    "taskStatement": "4.3",
    "stem": "An enterprise wants to expose a private SageMaker inference endpoint to on-premises clients over their VPN without using the internet. Which architecture meets this requirement securely with minimal overhead?",
    "correct": "A",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Deploy an Amazon NLB in front of the SageMaker endpoint and configure an Interface VPC endpoint (AWS PrivateLink) for the NLB; route on-prem VPN traffic to it.",
      "B": "Create an Internet-facing Application Load Balancer in front of the endpoint and restrict access via CIDR.",
      "C": "Peer the SageMaker VPC with the on-premises network and access the endpoint via peering.",
      "D": "Use AWS Transit Gateway to route to a public-facing endpoint with strong security groups."
    },
    "explanation": "Using a Network Load Balancer with a PrivateLink interface endpoint allows on-premises VPN clients to connect privately without exposing the endpoint to the internet, and with minimal additional components."
  },
  {
    "taskStatement": "4.3",
    "stem": "A security policy requires that every SageMaker training job include a CostCenter tag and use the execution role arn:aws:iam::123456789012:role/MLExecRole. Which feature can the ML engineer use to enforce both requirements at job creation?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use an IAM permissions boundary on ML users to restrict tag values.",
      "B": "Deploy an AWS Organizations SCP that denies sagemaker:CreateTrainingJob when tags or role do not match.",
      "C": "Enable an AWS Config rule for SageMaker jobs to require tags and roles.",
      "D": "Attach an IAM policy to users with a condition on sagemaker:RequestTag/CostCenter and sagemaker:ResourceTag/CostCenter and a condition requiring the UseServiceRole parameter equals MLExecRole."
    },
    "explanation": "An IAM identity policy with sagemaker:RequestTag and sagemaker:ResourceTag conditions can prevent job creation if the CostCenter tag is missing or if the specified ServiceRole is not MLExecRole. SCPs cannot inspect request tags."
  },
  {
    "taskStatement": "4.3",
    "stem": "A processing job running in SageMaker needs to mount an Amazon EFS file system for intermediate data. The security team requires encryption at rest and in transit for EFS, and only the processing job\u2019s subnets should be able to mount it. Which configuration meets these requirements?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Create an unencrypted EFS, rely on encryption in transit only, and restrict mount via security group.",
      "B": "Create an encrypted EFS with SSE-KMS, mount it in the processing job with encryption in transit disabled.",
      "C": "Use FSx for Lustre with default encryption, and mount via a VPN.",
      "D": "Create an EFS file system encrypted at rest with a CMK, enable encryption in transit (TLS) on the mount target, and restrict the EFS security group to only allow mount traffic from the processing job\u2019s security group."
    },
    "explanation": "An Amazon EFS file system can be encrypted at rest using a CMK and can enforce TLS encryption in transit. Security groups can restrict mount access so that only SageMaker processing job instances can connect."
  },
  {
    "taskStatement": "4.3",
    "stem": "The security team wants only members of the SecurityAudit role to read SageMaker logs in CloudWatch Logs. Other users must be denied. How can this be implemented?",
    "correct": "A",
    "difficulty": "EASY",
    "answers": {
      "A": "Attach a resource-based policy to the specific CloudWatch Log Group that allows only the SecurityAudit role to GetLogEvents and FilterLogEvents.",
      "B": "Encrypt the log group with a CMK and grant decrypt only to the SecurityAudit role.",
      "C": "Use an IAM identity policy denying CloudWatch Logs actions unless aws:PrincipalArn equals the SecurityAudit role.",
      "D": "Move the log group to a different AWS account used by security."
    },
    "explanation": "CloudWatch Log Groups support resource-based policies that can explicitly allow only a principal to perform log-reading actions. This is the most direct way to restrict access at the log-group level."
  },
  {
    "taskStatement": "4.3",
    "stem": "A CI/CD pipeline in CodePipeline uses an ECR repository for custom container images. The security team requires that only this pipeline can pull images and no other IAM principals. Which configuration enforces this?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Attach an IAM policy to the pipeline\u2019s role allowing ecr:BatchGetImage on the repo.",
      "B": "Add an ECR repository resource policy that allows ecr:BatchGetImage for the CodePipeline service role ARN and denies all others.",
      "C": "Use SCP to deny ecr:BatchGetImage globally for all principals except the pipeline.",
      "D": "Rely on IAM identity policies on all users to not allow ECR actions."
    },
    "explanation": "An ECR repository policy can directly specify which principals (the pipeline role) are allowed to pull images and deny everyone else, enforcing container image access at the resource level."
  },
  {
    "taskStatement": "4.3",
    "stem": "The security team wants to prevent developers from creating any SageMaker notebook instances or Studio domains that are internet-facing. Which control can achieve this across the organization?",
    "correct": "B",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Use an IAM permissions boundary for all developers disallowing sagemaker:CreateDomain.",
      "B": "Apply an AWS Organizations Service Control Policy that denies sagemaker:CreateDomain or CreateNotebookInstance when NetworkIsolation is false.",
      "C": "Attach an identity policy to each developer denying notebook creation.",
      "D": "Use AWS Config to detect and remediate non-VPC notebooks."
    },
    "explanation": "A Service Control Policy can centrally deny creation of SageMaker notebooks or domains unless the NetworkIsolation parameter is set to true, preventing internet access organization-wide."
  },
  {
    "taskStatement": "4.3",
    "stem": "An automated retraining workflow triggers a Lambda function via EventBridge. The function needs only permissions to DescribeEndpoint and CreateTrainingJob for a specific endpoint and training job prefix. How should the IAM role be defined to follow least privilege?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Grant sagemaker:* on all resources in the account.",
      "B": "Grant sagemaker:DescribeEndpoint and sagemaker:CreateTrainingJob on all SageMaker ARNs.",
      "C": "Grant sagemaker:DescribeEndpoint on the specific endpoint ARN and sagemaker:CreateTrainingJob with a resource ARN pattern matching the training-job-prefix*, and no other actions.",
      "D": "Attach AWS managed SageMaker full-access policy."
    },
    "explanation": "Defining resource-level permissions for only the specific endpoint and a wildcard training job prefix ensures the Lambda role has the minimum permissions required for its function."
  },
  {
    "taskStatement": "4.3",
    "stem": "Security requirements dictate that SageMaker notebook instances access internal services only on port 443 and cannot initiate outbound traffic to the internet. Which combination of controls enforces this?",
    "correct": "C",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Configure the notebook instance\u2019s security group to allow outbound 443 to specific subnets and attach an Internet Gateway to the VPC.",
      "B": "Use a NAT Gateway with a route table restricting to internal CIDR.",
      "C": "Configure the SG to allow outbound TCP 443 to internal subnet CIDR, set the route table for the private subnet with no internet gateway, and use a VPC Endpoint for required AWS service calls.",
      "D": "Deploy a firewall appliance in the VPC to filter outbound traffic."
    },
    "explanation": "Removing an internet gateway and not configuring a NAT Gateway prevents internet egress. A security group can allow only TCP 443 to internal subnets. VPC endpoints enable needed AWS service access without the internet."
  },
  {
    "taskStatement": "4.3",
    "stem": "An ML engineer needs to capture inference requests and responses in a SageMaker endpoint. The security team requires that the data capture archive in S3 be encrypted at rest with a CMK and that all data in transit use TLS. Which configuration achieves this?",
    "correct": "D",
    "difficulty": "MEDIUM",
    "answers": {
      "A": "Enable S3 default encryption on the bucket and configure DataCaptureConfig without specifying KMS.",
      "B": "Specify a KMS key in the SageMaker ModelRegistry settings and enable DataCaptureConfig.",
      "C": "Use an S3 bucket policy to require server-side encryption and rely on endpoint defaults.",
      "D": "In the endpoint\u2019s DataCaptureConfig, set EnableCapture true and specify the CMK KmsKeyId, and ensure the endpoint uses HTTPS (TLS) invocations."
    },
    "explanation": "DataCaptureConfig allows specifying a customer-managed KMS key for server-side encryption of captured data. SageMaker endpoints always use HTTPS for traffic, ensuring TLS in transit."
  }
]